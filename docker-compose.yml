version: '2.3'

services:
  nlp:
    build:
      context: .
      dockerfile: Dockerfile
      # args: # abandoning this for now, transfomers needs to be able to mkdir /.cache
      #   - user_id=${USER_ID}
      #   - group_id=${GROUP_ID}
    image: smtag
    depends_on:
    - tensorboard
    - celery
    - flower
#    runtime: nvidia
    volumes: &volumes
    - .:/app
    - ./data:/data
    - ./lm_models:${LM_MODEL_PATH}
    - ./tokcl_models:${TOKCL_MODEL_PATH}
    - ./cache:${CACHE}
    - ./runs:${RUNS_DIR}
    - ./dummy:${DUMMY_DIR}
    env_file:
    - ./.env
    ports:
      - 8888:8888  # this allows to run jupyter notebook --port=8888 --ip=0.0.0.0 --allow-root
    working_dir: /app
    command: ["jupyter", "notebook", "--port=8888", "--ip=0.0.0.0", "--allow-root"]


  tensorboard:
    image: smtag
#    runtime: nvidia
    ports:
    - 6007:6007
    volumes:
    - ./runs:/runs
    working_dir: /app
    command: tensorboard --logdir /runs --port 6007 --bind_all

  celery:
    image: smtag
    depends_on:
    - rabbitmq
    env_file:
    - ./.env
    volumes: *volumes
    working_dir: /app
    command: celery --app=smtag worker --loglevel=info

  flower:
    image: smtag
    depends_on:
    - celery
    volumes: *volumes
    working_dir: /app
    ports:
      - "5555:5555"
    command: flower --app=smtag --port=5555 --broker=rabbitmq

  rabbitmq:
    image: rabbitmq:3-management
    working_dir: /app
    ports:
      # The standard AMQP protocol port
      - '5672:5672'
      # HTTP management UI at http://localhost:15672/
      - '15672:15672'
