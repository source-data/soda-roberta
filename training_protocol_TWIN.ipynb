{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98ec562",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883e6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b546cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e49ac579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from smtag.config import config\n",
    "assert config.max_length==[256, 256]\n",
    "assert config.from_pretrained=='facebook/bart-base'\n",
    "assert config.model_type=='Twin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69335725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(max_length=[256, 256], truncation=True, min_char_length=80, celery_batch_size=1000, from_pretrained='facebook/bart-base', model_type='Twin', nlp=<spacy.lang.en.English object at 0x7fe97c48b280>, fast=True, asynchr=True, twin_delimiter='###tt9HHSlkWoUM###')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4bca7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.20.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f4f76",
   "metadata": {},
   "source": [
    "## Extracting examples for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035a6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.extract import ExtractorXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a23ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/text/oapmc_twin\n",
    "! rm -fr /data/text/emboj_twin\n",
    "# ! rm -fr /data/text/mini_twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d010582",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"/data/xml/emboj_all\"\n",
    "text_examples = \"/data/text/emboj_twin\"\n",
    "xpath = [\".//article-meta/title-group/article-title\", \".//abstract\"]\n",
    "sentence_level = False\n",
    "keep_xml = False\n",
    "inclusion_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a814341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/text/emboj_twin created\n"
     ]
    }
   ],
   "source": [
    "extractor_lm = ExtractorXML(\n",
    "    corpus,\n",
    "    destination_dir=text_examples,\n",
    "    sentence_level=sentence_level,\n",
    "    xpath=xpath,\n",
    "    keep_xml=keep_xml,\n",
    "    inclusion_probability=inclusion_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8ad33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:49<00:00,  9.14s/it]\n",
      "100%|██████████| 4/4 [00:26<00:00,  6.73s/it]\n",
      "100%|██████████| 4/4 [00:24<00:00,  6.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/data/text/emboj_twin/train.txt'): 7991,\n",
       " PosixPath('/data/text/emboj_twin/eval.txt'): 2651,\n",
       " PosixPath('/data/text/emboj_twin/test.txt'): 2659}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_lm.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af205c1",
   "metadata": {},
   "source": [
    "same via CLI:\n",
    "\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/emboj_all /data/text/emboj_twin --xpath \".//article-meta/title-group/article-title\" \".//abstract\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/oapmc_articles /data/text/oapmc_twin --xpath \".//article-meta/title-group/article-title\" \".//abstract\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/emboj_all /data/text/emboj_trivial --xpath \".//article-meta/title-group/article-title\" \".//article-meta/title-group/article-title\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d46fec",
   "metadata": {},
   "source": [
    "## Preparing tokenized dataset for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "55adc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.dataprep import PreparatorLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "485cbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examples = \"/data/json/emboj_twin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8495693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/json/oapmc_twin\n",
    "! rm -fr /data/json/emboj_twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8325107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/json/emboj_twin created\n"
     ]
    }
   ],
   "source": [
    "prep_lm = PreparatorLM(\n",
    "    text_examples,\n",
    "    tokenized_examples,\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5122d4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7991/7991 [00:15<00:00, 501.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2651/2651 [00:04<00:00, 609.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2659/2659 [00:04<00:00, 607.77it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_lm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87695c7",
   "metadata": {},
   "source": [
    "same vie CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/oapmc_twin /data/json/oapmc_twin\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/emboj_twin /data/json/emboj_twin\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/emboj_trivial /data/json/emboj_trivial\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53dfa7",
   "metadata": {},
   "source": [
    "## Train LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c191d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "603758ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.train.train_lm import (\n",
    "    train as train_lm,\n",
    "    TrainingArgumentsLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "91aa7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cache = True  # ALWAYS CHECK THIS IN CASE OF PROBLEMS!!!\n",
    "loader_path = \"./smtag/loader/loader_twin.py\"\n",
    "data_config_name = \"SEQ2SEQ\" # \"NOLM\" for a no-language model training # \"SEQ2SEQ\" to have also a language model\n",
    "tokenizer = config.tokenizer  # tokenizer has to be the same application-wide\n",
    "model_type = \"Twin\"\n",
    "from_pretrained = config.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6d27bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.mask_token = '<mask>'  # why is this here? maybe because in case of character-level tokenizer\n",
    "# tokenizer.unk_token = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d987c634",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsLM(output_dir='/lm_models', overwrite_output_dir=True, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, eval_delay=0, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/lm_models/runs/Feb26_19-19-54_8c68f5127e92', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=100, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, data_seed=None, jit_mode_eval=False, use_ipex=False, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name='/lm_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], fsdp=[], fsdp_min_num_params=0, deepspeed=None, label_smoothing_factor=0.0, optim=<OptimizerNames.ADAMW_HF: 'adamw_hf'>, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, hub_private_repo=False, gradient_checkpointing=False, include_inputs_for_metrics=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', auto_find_batch_size=False, full_determinism=False, torchdynamo=None, ray_scope='last')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_tokcl = TrainingArgumentsLM(\n",
    "    num_train_epochs = 1,\n",
    "    logging_steps = 100,  # 100 or 1000 for large oapmc_twin\n",
    "    save_steps=500, \n",
    "    per_device_train_batch_size=4,\n",
    "    per_device_eval_batch_size=4,\n",
    ")\n",
    "training_args_tokcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef60c95a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_lm(\n",
    "    training_args_tokcl,\n",
    "    loader_path,\n",
    "    data_config_name,\n",
    "    tokenized_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ae6c8",
   "metadata": {},
   "source": [
    "#### With CLI:\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py NOLM --data_dir /data/json/oapmc_twin --per_device_train_batch_size=64 --per_device_eval_batch_size=64 --logging_steps=100 --num_train_epochs=100 --save_steps=12000\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py SEQ2SEQ --data_dir /data/json/emboj_twin --per_device_train_batch_size=16 --per_device_eval_batch_size=16 --logging_steps=100 --save_steps=500 --num_train_epochs=1 --no_cache \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44faba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d10d1189",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
