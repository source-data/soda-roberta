{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98ec562",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883e6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b546cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc05b",
   "metadata": {},
   "source": [
    "In `config`:\n",
    "\n",
    "    config = Config(\n",
    "        max_length = [512, 512]  # in tokens, list for title vs abstract\n",
    "        from_pretrained = \"facebook/bart-base\"\n",
    "        model_type = \"Twin\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49ac579",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.config import config\n",
    "assert config.max_length==[512, 512]\n",
    "assert config.from_pretrained=='facebook/bart-base'\n",
    "assert config.model_type=='Twin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69335725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(max_length=[512, 512], truncation=True, min_char_length=80, celery_batch_size=1000, from_pretrained='facebook/bart-base', model_type='Twin', nlp=<spacy.lang.en.English object at 0x7f7168e3f160>, asynchr=True, twin_delimiter='###tt9HHSlkWoUM###')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4bca7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f4f76",
   "metadata": {},
   "source": [
    "## Extracting examples for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035a6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.extract import ExtractorXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3a23ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/text/oapmc_twin\n",
    "# ! rm -fr /data/text/emboj_twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0d010582",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"/data/xml/emboj_all\"\n",
    "text_examples = \"/data/text/emboj_twin\"\n",
    "xpath = [\".//article-meta/title-group/article-title\", \".//abstract\"]\n",
    "sentence_level = False\n",
    "keep_xml = False\n",
    "inclusion_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5a814341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/text/emboj_twin created\n"
     ]
    }
   ],
   "source": [
    "extractor_lm = ExtractorXML(\n",
    "    corpus,\n",
    "    destination_dir=text_examples,\n",
    "    sentence_level=sentence_level,\n",
    "    xpath=xpath,\n",
    "    keep_xml=keep_xml,\n",
    "    inclusion_probability=inclusion_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4c8ad33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [00:23<00:00,  1.94s/it]\n",
      "100%|██████████| 4/4 [00:07<00:00,  1.93s/it]\n",
      "100%|██████████| 4/4 [00:08<00:00,  2.01s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/data/text/emboj_twin/train.txt'): 7991,\n",
       " PosixPath('/data/text/emboj_twin/eval.txt'): 2651,\n",
       " PosixPath('/data/text/emboj_twin/test.txt'): 2659}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_lm.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af205c1",
   "metadata": {},
   "source": [
    "same via CLI:\n",
    "\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/emboj_all /data/text/emboj_twin --xpath \".//article-meta/title-group/article-title\" \".//abstract\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/oapmc_articles /data/text/oapmc_twin --xpath \".//article-meta/title-group/article-title\" \".//abstract\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/emboj_all /data/text/emboj_trivial --xpath \".//article-meta/title-group/article-title\" \".//article-meta/title-group/article-title\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d46fec",
   "metadata": {},
   "source": [
    "## Preparing tokenized dataset for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "55adc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.dataprep import PreparatorLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "485cbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examples = \"/data/json/emboj_twin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8495693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/json/oapmc_twin\n",
    "! rm -fr /data/json/emboj_twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8325107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/json/emboj_twin created\n"
     ]
    }
   ],
   "source": [
    "prep_lm = PreparatorLM(\n",
    "    text_examples,\n",
    "    tokenized_examples,\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5122d4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7991/7991 [00:16<00:00, 488.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2651/2651 [00:04<00:00, 605.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2659/2659 [00:04<00:00, 612.81it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_lm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87695c7",
   "metadata": {},
   "source": [
    "same vie CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/oapmc_twin /data/json/oapmc_twin\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/emboj_twin /data/json/emboj_twin\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/emboj_trivial /data/json/emboj_trivial\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53dfa7",
   "metadata": {},
   "source": [
    "## Train LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "61c191d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "603758ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.train.train_lm import (\n",
    "    train as train_lm,\n",
    "    TrainingArgumentsLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "91aa7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cache = False  # ALWAYS CHECK THIS IN CASE OF PROBLEMS!!!\n",
    "loader_path = \"./smtag/loader/loader_twin.py\"\n",
    "data_config_name = \"NOLM\"  # \"SEQ2SEQ\" ot have also a language model\n",
    "tokenizer = config.tokenizer  # tokenizer has to be the same application-wide\n",
    "model_type = \"Twin\"\n",
    "from_pretrained = config.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f6d27bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.mask_token = '<mask>'  # why is this here? maybe because in case of character-level tokenizer\n",
    "# tokenizer.unk_token = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d987c634",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "using `logging_steps` to initialize `eval_steps` to 100\n",
      "PyTorch: setting up devices\n",
      "The default value for the training argument `--report_to` will change in v5 (from all installed integrations to none). In v5, you will need to use `--report_to all` to get the same behavior as now. You should start updating your code and make this info disappear :-).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsLM(output_dir='/lm_models', overwrite_output_dir=True, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=4, per_device_eval_batch_size=4, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=3, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/lm_models/runs/Apr12_13-42-48_ea25f0d9a7eb', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=100, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name='/lm_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='')"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_tokcl = TrainingArgumentsLM(\n",
    "    num_train_epochs = 3,\n",
    "    logging_steps = 10,\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    ")\n",
    "training_args_tokcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "ef60c95a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Using custom data configuration SEQ2SEQ-7e8ee5936246c13c\n",
      "WARNING:Reusing dataset bio_lang (/cache/bio_lang/SEQ2SEQ-7e8ee5936246c13c/0.0.1/a448e44422f8de0edf7cba459390b981c0de141dd3a4a3586da4e10ab8427d00)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading datasets found in /data/json/emboj_twin.\n",
      "using ./smtag/loader/loader_twin.py as dataset loader.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e75c27355ae64ea797f80ab70e7bd396",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 7991 examples.\n",
      "Evaluating on 2651 examples.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n",
      "loading configuration file https://huggingface.co/facebook/bart-base/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/f5310d276a6d1648d00c32fadc8bf7b4607e0fbd5b404fc4a0045960aa2bdfdb.a243ed957122436adb0b8d8e9d20f896f45c174b6324d625ca0a20a84f72a910\n",
      "Model config BartConfig {\n",
      "  \"_name_or_path\": \"facebook/bart-base\",\n",
      "  \"activation_dropout\": 0.1,\n",
      "  \"activation_function\": \"gelu\",\n",
      "  \"add_bias_logits\": false,\n",
      "  \"add_final_layer_norm\": false,\n",
      "  \"architectures\": [\n",
      "    \"BartModel\"\n",
      "  ],\n",
      "  \"attention_dropout\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classif_dropout\": 0.1,\n",
      "  \"classifier_dropout\": 0.0,\n",
      "  \"d_model\": 768,\n",
      "  \"decoder_attention_heads\": 12,\n",
      "  \"decoder_ffn_dim\": 3072,\n",
      "  \"decoder_layerdrop\": 0.0,\n",
      "  \"decoder_layers\": 6,\n",
      "  \"decoder_start_token_id\": 2,\n",
      "  \"dropout\": 0.1,\n",
      "  \"early_stopping\": true,\n",
      "  \"encoder_attention_heads\": 12,\n",
      "  \"encoder_ffn_dim\": 3072,\n",
      "  \"encoder_layerdrop\": 0.0,\n",
      "  \"encoder_layers\": 6,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"forced_bos_token_id\": 0,\n",
      "  \"forced_eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\"\n",
      "  },\n",
      "  \"init_std\": 0.02,\n",
      "  \"is_encoder_decoder\": true,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2\n",
      "  },\n",
      "  \"max_position_embeddings\": 1024,\n",
      "  \"model_type\": \"bart\",\n",
      "  \"no_repeat_ngram_size\": 3,\n",
      "  \"normalize_before\": false,\n",
      "  \"normalize_embedding\": true,\n",
      "  \"num_beams\": 4,\n",
      "  \"num_hidden_layers\": 6,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"scale_embedding\": false,\n",
      "  \"task_specific_params\": {\n",
      "    \"summarization\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 128,\n",
      "      \"min_length\": 12,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_cnn\": {\n",
      "      \"length_penalty\": 2.0,\n",
      "      \"max_length\": 142,\n",
      "      \"min_length\": 56,\n",
      "      \"num_beams\": 4\n",
      "    },\n",
      "    \"summarization_xsum\": {\n",
      "      \"length_penalty\": 1.0,\n",
      "      \"max_length\": 62,\n",
      "      \"min_length\": 11,\n",
      "      \"num_beams\": 6\n",
      "    }\n",
      "  },\n",
      "  \"torch_dtype\": \"float32\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/facebook/bart-base/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/486355ec722ef05fd480e999d4c763be56549ae930f6a3742ee721a5d2a05647.f2f355ad2775769afc60592b43a46d72ca548375e3a1d65f381a751e711cbadd\n",
      "All model checkpoint weights were used when initializing BartForConditionalGeneration.\n",
      "\n",
      "All the weights of BartForConditionalGeneration were initialized from the model checkpoint at facebook/bart-base.\n",
      "If your task is similar to the task the model of the checkpoint was trained on, you can already use BartForConditionalGeneration for predictions without further training.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training arguments:\n",
      "TrainingArgumentsLM(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=100,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/runs/lm-SEQ2SEQ-2022-04-12T13-42-49.073967,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=3,\n",
      "output_dir=/lm_models,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=4,\n",
      "per_device_train_batch_size=4,\n",
      "prediction_loss_only=True,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=False,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/lm_models,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 7991\n",
      "  Num Epochs = 3\n",
      "  Instantaneous batch size per device = 4\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 16\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 1500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Available devices  4\n",
      "Current cuda device  0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='401' max='1500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 401/1500 06:43 < 18:32, 0.99 it/s, Epoch 0.80/3]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Supp Data Loss Twin Z</th>\n",
       "      <th>Supp Data Loss Z 1</th>\n",
       "      <th>Supp Data Loss Z 2</th>\n",
       "      <th>Supp Data Loss Lm 1</th>\n",
       "      <th>Supp Data Loss Lm 2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>4488.519700</td>\n",
       "      <td>5055.629395</td>\n",
       "      <td>5062.214355</td>\n",
       "      <td>0.014479</td>\n",
       "      <td>0.004867</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>4742.273400</td>\n",
       "      <td>4618.874512</td>\n",
       "      <td>4624.652832</td>\n",
       "      <td>0.012485</td>\n",
       "      <td>0.004473</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>4524.045600</td>\n",
       "      <td>4698.956055</td>\n",
       "      <td>4702.703125</td>\n",
       "      <td>0.011706</td>\n",
       "      <td>0.004596</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>\n",
       "    <div>\n",
       "      \n",
       "      <progress value='45' max='166' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [ 45/166 00:14 < 00:38, 3.12 it/s]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2651\n",
      "INFO:  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[31;1martments[<s>]\u001b[0m\u001b[31;1mnamed[Effects]\u001b[0m\u001b[31;1m Stri[of]\u001b[0m\u001b[31;1mBLIC[DNA]\u001b[0m\u001b[31;1m privile[strand]\u001b[0m\u001b[31;1m �[breaks]\u001b[0m\u001b[31;1m abolition[on]\u001b[0m\u001b[31;1m �[transcription]\u001b[0m\u001b[31;1m estate[by]\u001b[0m\u001b[31;1m compan[RNA]\u001b[0m\u001b[31;1m �[polymer]\u001b[0m\u001b[31;1m �[ase]\u001b[0m\u001b[31;1m �[III]\u001b[0m\u001b[31;1m estate[:]\u001b[0m\u001b[31;1m estate[insights]\u001b[0m\u001b[31;1m compan[into]\u001b[0m\u001b[31;1m blame[the]\u001b[0m\u001b[31;1m compan[role]\u001b[0m\u001b[31;1mographers[of]\u001b[0m\u001b[31;1mBLIC[TF]\u001b[0m\u001b[31;1m privile[II]\u001b[0m\u001b[31;1m estate[IB]\u001b[0m\u001b[31;1m estate[and]\u001b[0m\u001b[31;1m estate[the]\u001b[0m\u001b[31;1m stable[pol]\u001b[0m\u001b[31;1m privile[arity]\u001b[0m\u001b[31;1m estate[of]\u001b[0m\u001b[31;1m estate[promoter]\u001b[0m\u001b[31;1m estate[opening]\u001b[0m\u001b[31;1m blame[</s>]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[31;1m extinction[<s>]\u001b[0m\u001b[31;1myle[Certain]\u001b[0m\u001b[31;1m seated[deletion]\u001b[0m\u001b[31;1memption[mutants]\u001b[0m\u001b[31;1memption[of]\u001b[0m\u001b[31;1myle[the]\u001b[0m\u001b[31;1m Governors[Br]\u001b[0m\u001b[31;1memption[f]\u001b[0m\u001b[31;1m seated[1]\u001b[0m\u001b[31;1memption[and]\u001b[0m\u001b[31;1myle[B]\u001b[0m\u001b[31;1memption[dp]\u001b[0m\u001b[31;1m seated[1]\u001b[0m\u001b[31;1m seated[sub]\u001b[0m\u001b[31;1memption[units]\u001b[0m\u001b[31;1mendars[of]\u001b[0m\u001b[31;1mendars[transcription]\u001b[0m\u001b[31;1mendars[factor]\u001b[0m\u001b[31;1mendars[(]\u001b[0m\u001b[31;1mFer[TF]\u001b[0m\u001b[31;1mendars[)]\u001b[0m\u001b[31;1mwright[III]\u001b[0m\u001b[31;1myle[B]\u001b[0m\u001b[31;1m 410[retain]\u001b[0m\u001b[31;1m seated[the]\u001b[0m\u001b[31;1m entrepreneurs[ability]\u001b[0m\u001b[31;1mendars[to]\u001b[0m\u001b[31;1m seated[recruit]\u001b[0m\u001b[31;1mfemale[RNA]\u001b[0m\u001b[31;1m unchecked[polymer]\u001b[0m\u001b[31;1mendars[ase]\u001b[0m\u001b[31;1m unchecked[(]\u001b[0m\u001b[31;1mendars[pol]\u001b[0m\u001b[31;1m Arabia[)]\u001b[0m\u001b[31;1mwright[III]\u001b[0m\u001b[31;1m unchecked[to]\u001b[0m\u001b[31;1m unchecked[its]\u001b[0m\u001b[31;1m entrepreneurs[promoters]\u001b[0m\u001b[31;1mfemale[,]\u001b[0m\u001b[31;1m PROV[but]\u001b[0m\u001b[31;1m destination[fail]\u001b[0m\u001b[31;1mud[to]\u001b[0m\u001b[31;1m Liberal[support]\u001b[0m\u001b[31;1m loaded[promoter]\u001b[0m\u001b[31;1mfemale[opening]\u001b[0m\u001b[31;1mfemale[:]\u001b[0m\u001b[31;1myle[delet]\u001b[0m\u001b[31;1m eye[ions]\u001b[0m\u001b[31;1mwright[within]\u001b[0m\u001b[31;1m entrepreneurs[an]\u001b[0m\u001b[31;1m entrepreneurs[internal]\u001b[0m\u001b[31;1mfemale[B]\u001b[0m\u001b[31;1m SQU[dp]\u001b[0m\u001b[31;1mendars[1]\u001b[0m\u001b[31;1mendars[segment]\u001b[0m\u001b[31;1m seated[interfere]\u001b[0m\u001b[31;1mfemale[with]\u001b[0m\u001b[31;1m generously[initiation]\u001b[0m\u001b[31;1mfemale[of]\u001b[0m\u001b[31;1m entrepreneurs[DNA]\u001b[0m\u001b[31;1m Arabia[strand]\u001b[0m\u001b[31;1m 101[separation]\u001b[0m\u001b[31;1m 101[,]\u001b[0m\u001b[31;1m seated[and]\u001b[0m\u001b[31;1m variable[an]\u001b[0m\u001b[31;1m entrepreneurs[N]\u001b[0m\u001b[31;1memption[-]\u001b[0m\u001b[31;1mendars[termin]\u001b[0m\u001b[31;1memption[al]\u001b[0m\u001b[31;1m 101[Br]\u001b[0m\u001b[31;1m unchecked[f]\u001b[0m\u001b[31;1m seated[1]\u001b[0m\u001b[31;1mendars[deletion]\u001b[0m\u001b[31;1mendars[blocks]\u001b[0m\u001b[31;1m destination[propagation]\u001b[0m\u001b[31;1m 101[of]\u001b[0m\u001b[31;1m Arabia[promoter]\u001b[0m\u001b[31;1mendars[opening]\u001b[0m\u001b[31;1mfemale[past]\u001b[0m\u001b[31;1m defended[the]\u001b[0m\u001b[31;1m entrepreneurs[transcription]\u001b[0m\u001b[31;1mendars[al]\u001b[0m\u001b[31;1m seated[start]\u001b[0m\u001b[31;1memption[site]\u001b[0m\u001b[31;1mendars[.]\u001b[0m\u001b[31;1m seated[The]\u001b[0m\u001b[31;1m Governors[ability]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m seated[DNA]\u001b[0m\u001b[31;1m Arabia[strand]\u001b[0m\u001b[31;1m seated[breaks]\u001b[0m\u001b[31;1m loaded[to]\u001b[0m\u001b[31;1m seated[restore]\u001b[0m\u001b[31;1m loaded[pol]\u001b[0m\u001b[31;1m Insurance[III]\u001b[0m\u001b[31;1m Arabia[transcription]\u001b[0m\u001b[31;1m loaded[activity]\u001b[0m\u001b[31;1m Governors[to]\u001b[0m\u001b[31;1m seated[these]\u001b[0m\u001b[31;1m entrepreneurs[defective]\u001b[0m\u001b[31;1m entrepreneurs[TF]\u001b[0m\u001b[31;1mendars[II]\u001b[0m\u001b[31;1m seated[IB]\u001b[0m\u001b[31;1m seated[assemblies]\u001b[0m\u001b[31;1mendars[has]\u001b[0m\u001b[31;1m unchecked[been]\u001b[0m\u001b[31;1m unchecked[analyzed]\u001b[0m\u001b[31;1mfemale[using]\u001b[0m\u001b[31;1m propriet[U]\u001b[0m\u001b[31;1memption[6]\u001b[0m\u001b[31;1m seated[sn]\u001b[0m\u001b[31;1m seated[RNA]\u001b[0m\u001b[31;1m seated[gene]\u001b[0m\u001b[31;1m seated[constructs]\u001b[0m\u001b[31;1mendars[.]\u001b[0m\u001b[31;1m seated[Bre]\u001b[0m\u001b[31;1m seated[aks]\u001b[0m\u001b[31;1m seated[in]\u001b[0m\u001b[31;1m seated[a]\u001b[0m\u001b[31;1m seated[21]\u001b[0m\u001b[31;1m seated[]\u001b[0m\u001b[31;1memption[bp]\u001b[0m\u001b[31;1memption[segment]\u001b[0m\u001b[31;1m propriet[spanning]\u001b[0m\u001b[31;1m propriet[the]\u001b[0m\u001b[31;1m entrepreneurs[transcription]\u001b[0m\u001b[31;1m propriet[al]\u001b[0m\u001b[31;1m seated[start]\u001b[0m\u001b[31;1m propriet[rescue]\u001b[0m\u001b[31;1m unchecked[transcription]\u001b[0m\u001b[31;1m propriet[in]\u001b[0m\u001b[31;1m unchecked[DNA]\u001b[0m\u001b[31;1m unchecked[strand]\u001b[0m\u001b[31;1m unchecked[-]\u001b[0m\u001b[31;1mendars[specific]\u001b[0m\u001b[31;1m propriet[and]\u001b[0m\u001b[31;1m propriet[sub]\u001b[0m\u001b[31;1m unchecked[unit]\u001b[0m\u001b[31;1mendars[/]\u001b[0m\u001b[31;1mendars[m]\u001b[0m\u001b[31;1m eye[utation]\u001b[0m\u001b[31;1mendars[-]\u001b[0m\u001b[31;1mendars[specific]\u001b[0m\u001b[31;1m propriet[patterns]\u001b[0m\u001b[31;1mendars[.]\u001b[0m\u001b[31;1m generously[A]\u001b[0m\u001b[31;1m unchecked[cluster]\u001b[0m\u001b[31;1m entrepreneurs[of]\u001b[0m\u001b[31;1m propriet[B]\u001b[0m\u001b[31;1m Arabia[dp]\u001b[0m\u001b[31;1m Arabia[1]\u001b[0m\u001b[31;1m unchecked[internal]\u001b[0m\u001b[31;1m McMahon[delet]\u001b[0m\u001b[31;1m unchecked[ions]\u001b[0m\u001b[31;1m seated[also]\u001b[0m\u001b[31;1m unchecked[revers]\u001b[0m\u001b[31;1m unchecked[es]\u001b[0m\u001b[31;1m Governors[the]\u001b[0m\u001b[31;1m Governors[in]\u001b[0m\u001b[31;1micial[activation]\u001b[0m\u001b[31;1m Governors[of]\u001b[0m\u001b[31;1m entrepreneurs[transcription]\u001b[0m\u001b[31;1m Governors[with]\u001b[0m\u001b[31;1m entrepreneurs[wild]\u001b[0m\u001b[31;1m unchecked[-]\u001b[0m\u001b[31;1mendars[type]\u001b[0m\u001b[31;1mendars[TF]\u001b[0m\u001b[31;1mendars[II]\u001b[0m\u001b[31;1mendars[IB]\u001b[0m\u001b[31;1mendars[generated]\u001b[0m\u001b[31;1m entrepreneurs[by]\u001b[0m\u001b[31;1m entrepreneurs[certain]\u001b[0m\u001b[31;1m entrepreneurs[transc]\u001b[0m\u001b[31;1m eye[ribed]\u001b[0m\u001b[31;1m entrepreneurs[(]\u001b[0m\u001b[31;1mFer[template]\u001b[0m\u001b[31;1m eye[)]\u001b[0m\u001b[31;1m Governors[strand]\u001b[0m\u001b[31;1m unchecked[breaks]\u001b[0m\u001b[31;1memption[near]\u001b[0m\u001b[31;1m entrepreneurs[the]\u001b[0m\u001b[31;1m entrepreneurs[transcription]\u001b[0m\u001b[31;1m Governors[al]\u001b[0m\u001b[31;1m entrepreneurs[start]\u001b[0m\u001b[31;1m eye[site]\u001b[0m\u001b[31;1mendars[.]\u001b[0m\u001b[31;1m Governors[A]\u001b[0m\u001b[31;1mpolitics[structure]\u001b[0m\u001b[31;1m seated[-]\u001b[0m\u001b[31;1mendars[based]\u001b[0m\u001b[31;1m Governors[model]\u001b[0m\u001b[31;1mendars[and]\u001b[0m\u001b[31;1m Governors[top]\u001b[0m\u001b[31;1m entrepreneurs[ological]\u001b[0m\u001b[31;1m AES[considerations]\u001b[0m\u001b[31;1m 101[interpret]\u001b[0m\u001b[31;1m unchecked[these]\u001b[0m\u001b[31;1mlimited[observations]\u001b[0m\u001b[31;1m unchecked[,]\u001b[0m\u001b[31;1m seated[explain]\u001b[0m\u001b[31;1m unchecked[how]\u001b[0m\u001b[31;1m seated[B]\u001b[0m\u001b[31;1m seated[dp]\u001b[0m\u001b[31;1m Arabia[1]\u001b[0m\u001b[31;1m Arabia[and]\u001b[0m\u001b[31;1m Governors[Br]\u001b[0m\u001b[31;1m unchecked[f]\u001b[0m\u001b[31;1m seated[1]\u001b[0m\u001b[31;1mendars[help]\u001b[0m\u001b[31;1m seated[to]\u001b[0m\u001b[31;1m seated[enforce]\u001b[0m\u001b[31;1m seated[the]\u001b[0m\u001b[31;1m Governors[general]\u001b[0m\u001b[31;1m seated[upstream]\u001b[0m\u001b[31;1mendars[→]\u001b[0m\u001b[31;1m seated[downstream]\u001b[0m\u001b[31;1mendars[pol]\u001b[0m\u001b[31;1mendars[arity]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m loaded[promoter]\u001b[0m\u001b[31;1m seated[opening]\u001b[0m\u001b[31;1m seated[and]\u001b[0m\u001b[31;1m variable[specify]\u001b[0m\u001b[31;1m seated[requirements]\u001b[0m\u001b[31;1m loaded[for]\u001b[0m\u001b[31;1m loaded[pol]\u001b[0m\u001b[31;1memption[arity]\u001b[0m\u001b[31;1m seated[reversal]\u001b[0m\u001b[31;1m 101[.]\u001b[0m\u001b[31;1m seated[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2651\n",
      "INFO:  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[31;1m sinks[<s>]\u001b[0m\u001b[31;1m performed[ZE]\u001b[0m\u001b[31;1m reunited[B]\u001b[0m\u001b[31;1m reunited[,]\u001b[0m\u001b[31;1mtd[a]\u001b[0m\u001b[31;1m Equip[verte]\u001b[0m\u001b[31;1mappiness[brate]\u001b[0m\u001b[31;1mappiness[hom]\u001b[0m\u001b[31;1mappiness[olog]\u001b[0m\u001b[31;1mappiness[of]\u001b[0m\u001b[31;1m abolition[D]\u001b[0m\u001b[31;1mtd[ros]\u001b[0m\u001b[31;1mSPONSORED[oph]\u001b[0m\u001b[31;1mappiness[ila]\u001b[0m\u001b[31;1mappiness[Z]\u001b[0m\u001b[31;1m Radiant[f]\u001b[0m\u001b[31;1m compan[h]\u001b[0m\u001b[31;1m writer[-]\u001b[0m\u001b[31;1mappiness[1]\u001b[0m\u001b[31;1mappiness[,]\u001b[0m\u001b[31;1mtd[is]\u001b[0m\u001b[31;1mappiness[a]\u001b[0m\u001b[31;1m grandparents[negative]\u001b[0m\u001b[31;1m compan[regulator]\u001b[0m\u001b[31;1mappiness[of]\u001b[0m\u001b[31;1meu[muscle]\u001b[0m\u001b[31;1mappiness[differentiation]\u001b[0m\u001b[31;1mappiness[.]\u001b[0m\u001b[31;1mappiness[</s>]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[31;1m panels[<s>]\u001b[0m\u001b[31;1mlimited[A]\u001b[0m\u001b[31;1memption[number]\u001b[0m\u001b[31;1midge[of]\u001b[0m\u001b[31;1midge[genes]\u001b[0m\u001b[31;1memption[,]\u001b[0m\u001b[31;1memption[spanning]\u001b[0m\u001b[31;1memption[the]\u001b[0m\u001b[31;1m slee[evolutionary]\u001b[0m\u001b[31;1midge[scale]\u001b[0m\u001b[31;1memption[from]\u001b[0m\u001b[31;1m slee[yeast]\u001b[0m\u001b[31;1m slee[to]\u001b[0m\u001b[31;1m slee[mammals]\u001b[0m\u001b[31;1m seated[,]\u001b[0m\u001b[31;1m slee[that]\u001b[0m\u001b[31;1m seated[are]\u001b[0m\u001b[31;1memption[involved]\u001b[0m\u001b[31;1memption[in]\u001b[0m\u001b[31;1memption[spatial]\u001b[0m\u001b[31;1midge[and]\u001b[0m\u001b[31;1midge[temporal]\u001b[0m\u001b[31;1m Catholics[pattern]\u001b[0m\u001b[31;1memption[ing]\u001b[0m\u001b[31;1memption[during]\u001b[0m\u001b[31;1memption[development]\u001b[0m\u001b[31;1m slee[contain]\u001b[0m\u001b[31;1m slee[zinc]\u001b[0m\u001b[31;1memption[finger]\u001b[0m\u001b[31;1memption[and]\u001b[0m\u001b[31;1midge[home]\u001b[0m\u001b[31;1memption[od]\u001b[0m\u001b[31;1memption[om]\u001b[0m\u001b[31;1memption[ain]\u001b[0m\u001b[31;1memption[motif]\u001b[0m\u001b[31;1memption[s]\u001b[0m\u001b[31;1memption[.]\u001b[0m\u001b[31;1memption[One]\u001b[0m\u001b[31;1m seated[such]\u001b[0m\u001b[31;1memption[zinc]\u001b[0m\u001b[31;1midge[finger]\u001b[0m\u001b[31;1memption[/]\u001b[0m\u001b[31;1memption[home]\u001b[0m\u001b[31;1m seated[od]\u001b[0m\u001b[31;1memption[om]\u001b[0m\u001b[31;1memption[ain]\u001b[0m\u001b[31;1memption[protein]\u001b[0m\u001b[31;1memption[is]\u001b[0m\u001b[31;1memption[D]\u001b[0m\u001b[31;1memption[ros]\u001b[0m\u001b[31;1memption[oph]\u001b[0m\u001b[31;1memption[ila]\u001b[0m\u001b[31;1m seated[Z]\u001b[0m\u001b[31;1memption[f]\u001b[0m\u001b[31;1memption[h]\u001b[0m\u001b[31;1memption[-]\u001b[0m\u001b[31;1memption[1]\u001b[0m\u001b[31;1m seated[,]\u001b[0m\u001b[31;1m seated[a]\u001b[0m\u001b[31;1m seated[member]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1midge[the]\u001b[0m\u001b[31;1mItemImage[z]\u001b[0m\u001b[31;1m seated[f]\u001b[0m\u001b[31;1memption[h]\u001b[0m\u001b[31;1memption[family]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1midge[D]\u001b[0m\u001b[31;1memption[ros]\u001b[0m\u001b[31;1memption[oph]\u001b[0m\u001b[31;1memption[ila]\u001b[0m\u001b[31;1m seated[genes]\u001b[0m\u001b[31;1memption[,]\u001b[0m\u001b[31;1m seated[which]\u001b[0m\u001b[31;1m seated[is]\u001b[0m\u001b[31;1memption[expressed]\u001b[0m\u001b[31;1m slee[in]\u001b[0m\u001b[31;1midge[muscle]\u001b[0m\u001b[31;1midge[prec]\u001b[0m\u001b[31;1mina[urs]\u001b[0m\u001b[31;1memption[ors]\u001b[0m\u001b[31;1memption[and]\u001b[0m\u001b[31;1midge[is]\u001b[0m\u001b[31;1memption[critical]\u001b[0m\u001b[31;1memption[for]\u001b[0m\u001b[31;1memption[the]\u001b[0m\u001b[31;1memption[proper]\u001b[0m\u001b[31;1m Corona[development]\u001b[0m\u001b[31;1m 101[of]\u001b[0m\u001b[31;1midge[muscle]\u001b[0m\u001b[31;1midge[.]\u001b[0m\u001b[31;1memption[Here]\u001b[0m\u001b[31;1m seated[we]\u001b[0m\u001b[31;1m seated[demonstrate]\u001b[0m\u001b[31;1memption[that]\u001b[0m\u001b[31;1memption[a]\u001b[0m\u001b[31;1m seated[verte]\u001b[0m\u001b[31;1memption[brate]\u001b[0m\u001b[31;1m Recently[hom]\u001b[0m\u001b[31;1memption[olog]\u001b[0m\u001b[31;1memption[of]\u001b[0m\u001b[31;1memption[Z]\u001b[0m\u001b[31;1m seated[f]\u001b[0m\u001b[31;1memption[h]\u001b[0m\u001b[31;1memption[-]\u001b[0m\u001b[31;1m seated[1]\u001b[0m\u001b[31;1m seated[(]\u001b[0m\u001b[31;1memption[ZE]\u001b[0m\u001b[31;1memption[B]\u001b[0m\u001b[31;1m seated[)]\u001b[0m\u001b[31;1m seated[is]\u001b[0m\u001b[31;1memption[a]\u001b[0m\u001b[31;1m seated[negative]\u001b[0m\u001b[31;1m seated[regulator]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m seated[muscle]\u001b[0m\u001b[31;1m seated[differentiation]\u001b[0m\u001b[31;1m slee[.]\u001b[0m\u001b[31;1m seated[We]\u001b[0m\u001b[31;1m seated[show]\u001b[0m\u001b[31;1m seated[that]\u001b[0m\u001b[31;1m seated[Z]\u001b[0m\u001b[31;1memption[EB]\u001b[0m\u001b[31;1memption[binds]\u001b[0m\u001b[31;1memption[to]\u001b[0m\u001b[31;1m seated[a]\u001b[0m\u001b[31;1m Catholics[subset]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1midge[E]\u001b[0m\u001b[31;1memption[boxes]\u001b[0m\u001b[31;1memption[in]\u001b[0m\u001b[31;1m seated[muscle]\u001b[0m\u001b[31;1m seated[genes]\u001b[0m\u001b[31;1memption[and]\u001b[0m\u001b[31;1midge[functions]\u001b[0m\u001b[31;1m seated[by]\u001b[0m\u001b[31;1midge[actively]\u001b[0m\u001b[31;1m insulated[rep]\u001b[0m\u001b[31;1memption[ressing]\u001b[0m\u001b[31;1memption[transcription]\u001b[0m\u001b[31;1m 101[.]\u001b[0m\u001b[31;1m seated[One]\u001b[0m\u001b[31;1m seated[target]\u001b[0m\u001b[31;1m 101[of]\u001b[0m\u001b[31;1midge[this]\u001b[0m\u001b[31;1m seated[repression]\u001b[0m\u001b[31;1m 101[is]\u001b[0m\u001b[31;1m seated[the]\u001b[0m\u001b[31;1m seated[members]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1midge[the]\u001b[0m\u001b[31;1m********[ME]\u001b[0m\u001b[31;1memption[F]\u001b[0m\u001b[31;1memption[-]\u001b[0m\u001b[31;1mendars[2]\u001b[0m\u001b[31;1m Corona[family]\u001b[0m\u001b[31;1myle[,]\u001b[0m\u001b[31;1m seated[which]\u001b[0m\u001b[31;1m seated[synerg]\u001b[0m\u001b[31;1memption[ize]\u001b[0m\u001b[31;1memption[with]\u001b[0m\u001b[31;1midge[proteins]\u001b[0m\u001b[31;1memption[of]\u001b[0m\u001b[31;1midge[the]\u001b[0m\u001b[31;1m Zy[my]\u001b[0m\u001b[31;1m seated[ogenic]\u001b[0m\u001b[31;1m seated[basic]\u001b[0m\u001b[31;1midge[hel]\u001b[0m\u001b[31;1memption[ix]\u001b[0m\u001b[31;1m seated[-]\u001b[0m\u001b[31;1m seated[loop]\u001b[0m\u001b[31;1m merry[-]\u001b[0m\u001b[31;1m Clarke[hel]\u001b[0m\u001b[31;1m seated[ix]\u001b[0m\u001b[31;1m seated[family]\u001b[0m\u001b[31;1mendars[(]\u001b[0m\u001b[31;1memption[b]\u001b[0m\u001b[31;1m seated[HL]\u001b[0m\u001b[31;1m seated[H]\u001b[0m\u001b[31;1memption[)]\u001b[0m\u001b[31;1mendars[(]\u001b[0m\u001b[31;1memption[my]\u001b[0m\u001b[31;1m seated[o]\u001b[0m\u001b[31;1m Corona[D]\u001b[0m\u001b[31;1m seated[,]\u001b[0m\u001b[31;1m seated[my]\u001b[0m\u001b[31;1m seated[f]\u001b[0m\u001b[31;1memption[-]\u001b[0m\u001b[31;1memption[5]\u001b[0m\u001b[31;1m seated[,]\u001b[0m\u001b[31;1m seated[my]\u001b[0m\u001b[31;1m seated[ogen]\u001b[0m\u001b[31;1memption[in]\u001b[0m\u001b[31;1memption[and]\u001b[0m\u001b[31;1m Harding[MR]\u001b[0m\u001b[31;1memption[F]\u001b[0m\u001b[31;1memption[-]\u001b[0m\u001b[31;1memption[4]\u001b[0m\u001b[31;1m merry[)]\u001b[0m\u001b[31;1m seated[to]\u001b[0m\u001b[31;1m seated[induce]\u001b[0m\u001b[31;1m seated[my]\u001b[0m\u001b[31;1m Corona[ogenic]\u001b[0m\u001b[31;1m Corona[differentiation]\u001b[0m\u001b[31;1m Corona[.]\u001b[0m\u001b[31;1memption[As]\u001b[0m\u001b[31;1m seated[muscle]\u001b[0m\u001b[31;1m seated[differentiation]\u001b[0m\u001b[31;1m 101[proceeds]\u001b[0m\u001b[31;1m merry[,]\u001b[0m\u001b[31;1m seated[my]\u001b[0m\u001b[31;1m seated[ogenic]\u001b[0m\u001b[31;1m seated[b]\u001b[0m\u001b[31;1m insulated[HL]\u001b[0m\u001b[31;1m seated[H]\u001b[0m\u001b[31;1m seated[proteins]\u001b[0m\u001b[31;1memption[accumulate]\u001b[0m\u001b[31;1m seated[to]\u001b[0m\u001b[31;1m seated[levels]\u001b[0m\u001b[31;1m seated[sufficient]\u001b[0m\u001b[31;1m seated[to]\u001b[0m\u001b[31;1m seated[dis]\u001b[0m\u001b[31;1memption[place]\u001b[0m\u001b[31;1m insulated[Z]\u001b[0m\u001b[31;1memption[EB]\u001b[0m\u001b[31;1m seated[from]\u001b[0m\u001b[31;1m entrepreneurs[the]\u001b[0m\u001b[31;1m slee[E]\u001b[0m\u001b[31;1m revolutionaries[boxes]\u001b[0m\u001b[31;1m seated[,]\u001b[0m\u001b[31;1m seated[releasing]\u001b[0m\u001b[31;1m seated[the]\u001b[0m\u001b[31;1m entrepreneurs[repression]\u001b[0m\u001b[31;1m seated[and]\u001b[0m\u001b[31;1m seated[allowing]\u001b[0m\u001b[31;1m seated[b]\u001b[0m\u001b[31;1m seated[HL]\u001b[0m\u001b[31;1m seated[H]\u001b[0m\u001b[31;1m seated[proteins]\u001b[0m\u001b[31;1memption[to]\u001b[0m\u001b[31;1m seated[further]\u001b[0m\u001b[31;1m seated[activate]\u001b[0m\u001b[31;1m entrepreneurs[transcription]\u001b[0m\u001b[31;1m seated[.]\u001b[0m\u001b[31;1m seated[This]\u001b[0m\u001b[31;1m seated[mechanism]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m entrepreneurs[active]\u001b[0m\u001b[31;1m entrepreneurs[transcription]\u001b[0m\u001b[31;1m 101[al]\u001b[0m\u001b[31;1m seated[repression]\u001b[0m\u001b[31;1m 101[distinguishes]\u001b[0m\u001b[31;1mRIP[Z]\u001b[0m\u001b[31;1m seated[EB]\u001b[0m\u001b[31;1m seated[from]\u001b[0m\u001b[31;1midge[other]\u001b[0m\u001b[31;1m seated[negative]\u001b[0m\u001b[31;1m Thou[regulators]\u001b[0m\u001b[31;1memption[of]\u001b[0m\u001b[31;1m insulated[my]\u001b[0m\u001b[31;1m seated[ogenesis]\u001b[0m\u001b[31;1memption[(]\u001b[0m\u001b[31;1memption[Id]\u001b[0m\u001b[31;1m seated[,]\u001b[0m\u001b[31;1m seated[Twist]\u001b[0m\u001b[31;1memption[and]\u001b[0m\u001b[31;1m seated[I]\u001b[0m\u001b[31;1m seated[-]\u001b[0m\u001b[31;1m seated[m]\u001b[0m\u001b[31;1m seated[fa]\u001b[0m\u001b[31;1m seated[)]\u001b[0m\u001b[31;1m seated[that]\u001b[0m\u001b[31;1m seated[inhibit]\u001b[0m\u001b[31;1m seated[muscle]\u001b[0m\u001b[31;1m seated[differentiation]\u001b[0m\u001b[31;1mFer[by]\u001b[0m\u001b[31;1m seated[simply]\u001b[0m\u001b[31;1m Harding[binding]\u001b[0m\u001b[31;1m seated[and]\u001b[0m\u001b[31;1mlimited[in]\u001b[0m\u001b[31;1m seated[activ]\u001b[0m\u001b[31;1memption[ating]\u001b[0m\u001b[31;1m seated[my]\u001b[0m\u001b[31;1m AES[ogenic]\u001b[0m\u001b[31;1m Harding[factors]\u001b[0m\u001b[31;1m seated[.]\u001b[0m\u001b[31;1m seated[The]\u001b[0m\u001b[31;1m seated[relative]\u001b[0m\u001b[31;1m entrepreneurs[affinity]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m********[Z]\u001b[0m\u001b[31;1m seated[EB]\u001b[0m\u001b[31;1m seated[versus]\u001b[0m\u001b[31;1m seated[my]\u001b[0m\u001b[31;1m seated[ogenic]\u001b[0m\u001b[31;1m seated[b]\u001b[0m\u001b[31;1mFer[HL]\u001b[0m\u001b[31;1m seated[H]\u001b[0m\u001b[31;1m seated[proteins]\u001b[0m\u001b[31;1m seated[varies]\u001b[0m\u001b[31;1m Thou[for]\u001b[0m\u001b[31;1midge[E]\u001b[0m\u001b[31;1m seated[boxes]\u001b[0m\u001b[31;1m seated[in]\u001b[0m\u001b[31;1m seated[different]\u001b[0m\u001b[31;1m seated[genes]\u001b[0m\u001b[31;1m seated[such]\u001b[0m\u001b[31;1m seated[that]\u001b[0m\u001b[31;1m seated[Z]\u001b[0m\u001b[31;1m seated[EB]\u001b[0m\u001b[31;1m seated[would]\u001b[0m\u001b[31;1m seated[be]\u001b[0m\u001b[31;1m seated[displaced]\u001b[0m\u001b[31;1m seated[from]\u001b[0m\u001b[31;1m seated[different]\u001b[0m\u001b[31;1m seated[genes]\u001b[0m\u001b[31;1m seated[at]\u001b[0m\u001b[31;1m seated[distinct]\u001b[0m\u001b[31;1m seated[times]\u001b[0m\u001b[31;1mendars[as]\u001b[0m\u001b[31;1m seated[my]\u001b[0m\u001b[31;1m seated[ogenic]\u001b[0m\u001b[31;1m seated[b]\u001b[0m\u001b[31;1m seated[HL]\u001b[0m\u001b[31;1m seated[H]\u001b[0m\u001b[31;1m seated[proteins]\u001b[0m\u001b[31;1memption[accumulate]\u001b[0m\u001b[31;1m seated[during]\u001b[0m\u001b[31;1m Harding[my]\u001b[0m\u001b[31;1m seated[ogenesis]\u001b[0m\u001b[31;1m seated[,]\u001b[0m\u001b[31;1m seated[thus]\u001b[0m\u001b[31;1m seated[providing]\u001b[0m\u001b[31;1m seated[a]\u001b[0m\u001b[31;1m Harding[mechanism]\u001b[0m\u001b[31;1m seated[to]\u001b[0m\u001b[31;1m seated[regulate]\u001b[0m\u001b[31;1m seated[temporal]\u001b[0m\u001b[31;1m seated[order]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1mendars[gene]\u001b[0m\u001b[31;1m seated[expression]\u001b[0m\u001b[31;1m seated[.]\u001b[0m\u001b[31;1m seated[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2651\n",
      "INFO:  Batch size = 16\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[31;1m revival[<s>]\u001b[0m\u001b[31;1m Replace[Mess]\u001b[0m\u001b[31;1mSPONSORED[ages]\u001b[0m\u001b[31;1mnear[from]\u001b[0m\u001b[31;1mSPONSORED[forgotten]\u001b[0m\u001b[31;1m contraction[friends]\u001b[0m\u001b[31;1meu[:]\u001b[0m\u001b[31;1meu[classic]\u001b[0m\u001b[31;1meu[cell]\u001b[0m\u001b[31;1mSPONSORED[ad]\u001b[0m\u001b[31;1mSPONSORED[hesion]\u001b[0m\u001b[31;1m contraction[molecules]\u001b[0m\u001b[31;1m contraction[inhibit]\u001b[0m\u001b[31;1m contraction[regeneration]\u001b[0m\u001b[31;1m contraction[too]\u001b[0m\u001b[31;1m contraction[</s>]\u001b[0m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[31;1m extinction[<s>]\u001b[0m\u001b[31;1myle[A]\u001b[0m\u001b[31;1m seated[necessary]\u001b[0m\u001b[31;1m seated[step]\u001b[0m\u001b[31;1m seated[toward]\u001b[0m\u001b[31;1m entrepreneurs[complete]\u001b[0m\u001b[31;1m entrepreneurs[functional]\u001b[0m\u001b[31;1m entrepreneurs[recovery]\u001b[0m\u001b[31;1m seated[after]\u001b[0m\u001b[31;1m entrepreneurs[spinal]\u001b[0m\u001b[31;1m seated[cord]\u001b[0m\u001b[31;1m seated[injury]\u001b[0m\u001b[31;1m seated[is]\u001b[0m\u001b[31;1memption[the]\u001b[0m\u001b[31;1m Governors[regeneration]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m seated[ax]\u001b[0m\u001b[31;1m seated[ons]\u001b[0m\u001b[31;1m seated[.]\u001b[0m\u001b[31;1memption[Ax]\u001b[0m\u001b[31;1m seated[on]\u001b[0m\u001b[31;1m seated[reg]\u001b[0m\u001b[31;1memption[rowth]\u001b[0m\u001b[31;1m seated[after]\u001b[0m\u001b[31;1m entrepreneurs[injury]\u001b[0m\u001b[31;1m seated[is]\u001b[0m\u001b[31;1memption[prevented]\u001b[0m\u001b[31;1memption[by]\u001b[0m\u001b[31;1m seated[a]\u001b[0m\u001b[31;1m entrepreneurs[myriad]\u001b[0m\u001b[31;1m entrepreneurs[of]\u001b[0m\u001b[31;1m entrepreneurs[intrinsic]\u001b[0m\u001b[31;1m Veteran[and]\u001b[0m\u001b[31;1m Veteran[extr]\u001b[0m\u001b[31;1memption[ins]\u001b[0m\u001b[31;1memption[ic]\u001b[0m\u001b[31;1m Veteran[factors]\u001b[0m\u001b[31;1m trou[.]\u001b[0m\u001b[31;1memption[In]\u001b[0m\u001b[31;1m entrepreneurs[this]\u001b[0m\u001b[31;1m entrepreneurs[issue]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m Governors[The]\u001b[0m\u001b[31;1m Governors[EM]\u001b[0m\u001b[31;1memption[BO]\u001b[0m\u001b[31;1memption[Journal]\u001b[0m\u001b[31;1memption[,]\u001b[0m\u001b[31;1m seated[Huang]\u001b[0m\u001b[31;1m seated[et]\u001b[0m\u001b[31;1memption[]\u001b[0m\u001b[31;1memption[al]\u001b[0m\u001b[31;1m seated[(]\u001b[0m\u001b[31;1m trou[2016]\u001b[0m\u001b[31;1memption[)]\u001b[0m\u001b[31;1m trou[demonstrate]\u001b[0m\u001b[31;1memption[that]\u001b[0m\u001b[31;1m seated[the]\u001b[0m\u001b[31;1m unchecked[cell]\u001b[0m\u001b[31;1m seated[ad]\u001b[0m\u001b[31;1memption[hesion]\u001b[0m\u001b[31;1m seated[molecule]\u001b[0m\u001b[31;1m 101[NB]\u001b[0m\u001b[31;1m seated[-]\u001b[0m\u001b[31;1m seated[3]\u001b[0m\u001b[31;1m merry[(]\u001b[0m\u001b[31;1memption[C]\u001b[0m\u001b[31;1m seated[NT]\u001b[0m\u001b[31;1m seated[N]\u001b[0m\u001b[31;1m seated[6]\u001b[0m\u001b[31;1m seated[)]\u001b[0m\u001b[31;1m PROV[functions]\u001b[0m\u001b[31;1mwright[as]\u001b[0m\u001b[31;1micial[a]\u001b[0m\u001b[31;1mwright[major]\u001b[0m\u001b[31;1m entrepreneurs[brake]\u001b[0m\u001b[31;1memption[on]\u001b[0m\u001b[31;1m seated[ax]\u001b[0m\u001b[31;1memption[on]\u001b[0m\u001b[31;1mendars[reg]\u001b[0m\u001b[31;1memption[rowth]\u001b[0m\u001b[31;1m merry[when]\u001b[0m\u001b[31;1m PROV[it]\u001b[0m\u001b[31;1m seated[is]\u001b[0m\u001b[31;1memption[activated]\u001b[0m\u001b[31;1m seated[by]\u001b[0m\u001b[31;1m entrepreneurs[NB]\u001b[0m\u001b[31;1m seated[-]\u001b[0m\u001b[31;1m seated[3]\u001b[0m\u001b[31;1m seated[from]\u001b[0m\u001b[31;1m Governors[scar]\u001b[0m\u001b[31;1m seated[-]\u001b[0m\u001b[31;1memption[forming]\u001b[0m\u001b[31;1m seated[cells]\u001b[0m\u001b[31;1m seated[at]\u001b[0m\u001b[31;1m Romanian[the]\u001b[0m\u001b[31;1mItemImage[injury]\u001b[0m\u001b[31;1m seated[site]\u001b[0m\u001b[31;1m seated[.]\u001b[0m\u001b[31;1m Harding[Dis]\u001b[0m\u001b[31;1memption[ruption]\u001b[0m\u001b[31;1m seated[of]\u001b[0m\u001b[31;1m seated[this]\u001b[0m\u001b[31;1m seated[NB]\u001b[0m\u001b[31;1m seated[-]\u001b[0m\u001b[31;1m seated[3]\u001b[0m\u001b[31;1memption[trans]\u001b[0m\u001b[31;1memption[-]\u001b[0m\u001b[31;1m seated[cell]\u001b[0m\u001b[31;1m seated[ular]\u001b[0m\u001b[31;1m seated[signaling]\u001b[0m\u001b[31;1m seated[led]\u001b[0m\u001b[31;1m seated[to]\u001b[0m\u001b[31;1m unchecked[impressive]\u001b[0m\u001b[31;1m entrepreneurs[ax]\u001b[0m\u001b[31;1m unchecked[on]\u001b[0m\u001b[31;1m Insurance[reg]\u001b[0m\u001b[31;1memption[rowth]\u001b[0m\u001b[31;1m 101[after]\u001b[0m\u001b[31;1m PROV[spinal]\u001b[0m\u001b[31;1m entrepreneurs[cord]\u001b[0m\u001b[31;1m seated[tr]\u001b[0m\u001b[31;1m seated[an]\u001b[0m\u001b[31;1m seated[section]\u001b[0m\u001b[31;1m seated[.]\u001b[0m\u001b[31;1m seated[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2651\n",
      "INFO:  Batch size = 16\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_751/2922908302.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_lm(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtraining_args_tokcl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloader_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_config_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;34m\"/data/json/emboj_twin\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# tokenized_examples,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/train/train_lm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_args, loader_path, data_config_name, data_dir, no_cache, tokenizer, model_type, from_pretrained)\u001b[0m\n\u001b[1;32m    256\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current cuda device '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 258\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    259\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    260\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1397\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_step_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1398\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1399\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_log_save_evaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtr_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1400\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1401\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcallback_handler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_substep_end\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36m_maybe_log_save_evaluate\u001b[0;34m(self, tr_loss, model, trial, epoch, ignore_keys_for_eval)\u001b[0m\n\u001b[1;32m   1519\u001b[0m         \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1520\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontrol\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshould_evaluate\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1521\u001b[0;31m             \u001b[0mmetrics\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys_for_eval\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1522\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_report_to_hp_search\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1523\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/trainer.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, eval_dataset, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    168\u001b[0m         \u001b[0mstart_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m         output = self.evaluation_loop(\n\u001b[0m\u001b[1;32m    171\u001b[0m             \u001b[0meval_dataloader\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m             \u001b[0mdescription\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Evaluation\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/trainer.py\u001b[0m in \u001b[0;36mevaluation_loop\u001b[0;34m(self, dataloader, description, prediction_loss_only, ignore_keys, metric_key_prefix)\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0;31m# Prediction step\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m             \u001b[0;31m# MODIFICATION OF BASE CLASS\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlogits\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msupp_data_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprediction_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprediction_loss_only\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mignore_keys\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mignore_keys\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;31m##############################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/trainer.py\u001b[0m in \u001b[0;36mprediction_step\u001b[0;34m(self, model, inputs, prediction_loss_only, ignore_keys)\u001b[0m\n\u001b[1;32m    483\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhas_labels\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    484\u001b[0m                 \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 485\u001b[0;31m                     \u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_outputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    486\u001b[0m                 \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdetach\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    487\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    547\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    548\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 549\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    550\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    551\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_lm(\n",
    "    training_args_tokcl,\n",
    "    loader_path,\n",
    "    data_config_name,\n",
    "    tokenized_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ae6c8",
   "metadata": {},
   "source": [
    "#### With CLI:\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py SEQ2SEQ --data_dir /data/json/oapmc_twin --per_device_train_batch_size=6 --per_device_eval_batch_size=6 --logging_steps=4000 --num_train_epochs=1 --no_cache --save_steps=12000\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py SEQ2SEQ --data_dir /data/json/emboj_twin --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --logging_steps=100 --num_train_epochs=1 --no_cache \n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py SEQ2SEQ --data_dir /data/json/emboj_trivial --per_device_train_batch_size=4 --per_device_eval_batch_size=4 --logging_steps=100 --num_train_epochs=1 --no_cache \n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py NOLM --data_dir /data/json/oapmc_twin --per_device_train_batch_size=64 --per_device_eval_batch_size=64 --logging_steps=50 --num_train_epochs=100   --save_steps=12000\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44faba",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
