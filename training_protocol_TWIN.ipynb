{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98ec562",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883e6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b546cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc05b",
   "metadata": {},
   "source": [
    "In `config`:\n",
    "\n",
    "    config = Config(\n",
    "        max_length = [256, 256]  # in tokens, list for title vs abstract\n",
    "        from_pretrained = \"facebook/bart-base\"\n",
    "        model_type = \"Twin\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49ac579",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-12 06:51:11.835896: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcudart.so.11.0'; dlerror: libcudart.so.11.0: cannot open shared object file: No such file or directory\n",
      "2022-08-12 06:51:11.835950: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2022-08-12 06:51:13.914962: I tensorflow/compiler/jit/xla_cpu_device.cc:41] Not creating XLA devices, tf_xla_enable_xla_devices not set\n",
      "2022-08-12 06:51:13.915133: W tensorflow/stream_executor/platform/default/dso_loader.cc:60] Could not load dynamic library 'libcuda.so.1'; dlerror: libcuda.so.1: cannot open shared object file: No such file or directory\n",
      "2022-08-12 06:51:13.915157: W tensorflow/stream_executor/cuda/cuda_driver.cc:326] failed call to cuInit: UNKNOWN ERROR (303)\n",
      "2022-08-12 06:51:13.915186: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (0051b612e94f): /proc/driver/nvidia/version does not exist\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cb88e13411e74b5c81a49cf21fda3009",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ef302f75f0ac4609b253e58791fc1a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3a15af2dc9b54c3796d007aff09dcecc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "94dc6a7ef67e46ceb677d37bbf276838",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from smtag.config import config\n",
    "assert config.max_length==[256, 256]\n",
    "assert config.from_pretrained=='facebook/bart-base'\n",
    "assert config.model_type=='Twin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "69335725",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(max_length=[256, 256], truncation=True, min_char_length=80, celery_batch_size=1000, from_pretrained='facebook/bart-base', model_type='Twin', nlp=<spacy.lang.en.English object at 0x7f712f288410>, fast=True, asynchr=True, twin_delimiter='###tt9HHSlkWoUM###')"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9f4bca7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f4f76",
   "metadata": {},
   "source": [
    "## Extracting examples for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "035a6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.extract import ExtractorXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a23ef15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/text/oapmc_twin\n",
    "! rm -fr /data/text/emboj_twin\n",
    "# ! rm -fr /data/text/mini_twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0d010582",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"/data/xml/emboj_all\"\n",
    "text_examples = \"/data/text/emboj_twin\"\n",
    "xpath = [\".//article-meta/title-group/article-title\", \".//abstract\"]\n",
    "sentence_level = False\n",
    "keep_xml = False\n",
    "inclusion_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5a814341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/text/emboj_twin created\n"
     ]
    }
   ],
   "source": [
    "extractor_lm = ExtractorXML(\n",
    "    corpus,\n",
    "    destination_dir=text_examples,\n",
    "    sentence_level=sentence_level,\n",
    "    xpath=xpath,\n",
    "    keep_xml=keep_xml,\n",
    "    inclusion_probability=inclusion_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4c8ad33f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12/12 [01:49<00:00,  9.14s/it]\n",
      "100%|██████████| 4/4 [00:26<00:00,  6.73s/it]\n",
      "100%|██████████| 4/4 [00:24<00:00,  6.24s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/data/text/emboj_twin/train.txt'): 7991,\n",
       " PosixPath('/data/text/emboj_twin/eval.txt'): 2651,\n",
       " PosixPath('/data/text/emboj_twin/test.txt'): 2659}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_lm.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af205c1",
   "metadata": {},
   "source": [
    "same via CLI:\n",
    "\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/emboj_all /data/text/emboj_twin --xpath \".//article-meta/title-group/article-title\" \".//abstract\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/oapmc_articles /data/text/oapmc_twin --xpath \".//article-meta/title-group/article-title\" \".//abstract\"\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/emboj_all /data/text/emboj_trivial --xpath \".//article-meta/title-group/article-title\" \".//article-meta/title-group/article-title\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d46fec",
   "metadata": {},
   "source": [
    "## Preparing tokenized dataset for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "55adc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.dataprep import PreparatorLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "485cbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examples = \"/data/json/emboj_twin\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8495693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/json/oapmc_twin\n",
    "! rm -fr /data/json/emboj_twin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8325107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/json/emboj_twin created\n"
     ]
    }
   ],
   "source": [
    "prep_lm = PreparatorLM(\n",
    "    text_examples,\n",
    "    tokenized_examples,\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5122d4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7991/7991 [01:49<00:00, 72.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2651/2651 [00:30<00:00, 86.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2659/2659 [00:31<00:00, 85.23it/s]\n"
     ]
    }
   ],
   "source": [
    "prep_lm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87695c7",
   "metadata": {},
   "source": [
    "same vie CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/oapmc_twin /data/json/oapmc_twin\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/emboj_twin /data/json/emboj_twin\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/emboj_trivial /data/json/emboj_trivial\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53dfa7",
   "metadata": {},
   "source": [
    "## Train LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61c191d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "603758ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.train.train_lm import (\n",
    "    train as train_lm,\n",
    "    TrainingArgumentsLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "91aa7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cache = True  # ALWAYS CHECK THIS IN CASE OF PROBLEMS!!!\n",
    "loader_path = \"./smtag/loader/loader_twin.py\"\n",
    "data_config_name = \"NOLM\"  # \"SEQ2SEQ\" to have also a language model\n",
    "tokenizer = config.tokenizer  # tokenizer has to be the same application-wide\n",
    "model_type = \"Twin\"\n",
    "from_pretrained = config.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f6d27bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.mask_token = '<mask>'  # why is this here? maybe because in case of character-level tokenizer\n",
    "# tokenizer.unk_token = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d987c634",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsLM(output_dir='/lm_models', overwrite_output_dir=True, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=64, per_device_eval_batch_size=64, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/lm_models/runs/Aug12_07-30-45_0051b612e94f', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=10, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=10, dataloader_num_workers=0, past_index=-1, run_name='/lm_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_tokcl = TrainingArgumentsLM(\n",
    "    num_train_epochs = 1,\n",
    "    logging_steps = 10,  # 100 or 1000 for large oapmc_twin\n",
    "    per_device_train_batch_size=64,\n",
    "    per_device_eval_batch_size=64,\n",
    ")\n",
    "training_args_tokcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ef60c95a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Using custom data configuration NOLM-d40dc6d59518e719\n",
      "WARNING:Reusing dataset bio_lang (/cache/bio_lang/NOLM-d40dc6d59518e719/0.0.1/6d4ea8ff1ed118944eaa482dd097846394ccbde298fe36dd174a0bb9fe648924)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading datasets found in /data/json/emboj_twin.\n",
      "using ./smtag/loader/loader_twin.py as dataset loader.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d908baf7d976457d90d7a5e2b439aedc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 7991 examples.\n",
      "Evaluating on 2651 examples.\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'Twin' object has no attribute 'models'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_21/742420827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mmodel_type\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m     \u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m )\n",
      "\u001b[0;32m/app/smtag/train/train_lm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_args, loader_path, data_config_name, data_dir, no_cache, tokenizer, model_type, from_pretrained)\u001b[0m\n\u001b[1;32m    286\u001b[0m                 model = Twin(\n\u001b[1;32m    287\u001b[0m                     \u001b[0mencoders\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 288\u001b[0;31m                     \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_config\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    289\u001b[0m                 )\n\u001b[1;32m    290\u001b[0m             \u001b[0;32melif\u001b[0m \u001b[0mdata_config_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"SEQ2SEQ\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"MLM\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/models/vae.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, encoders, config)\u001b[0m\n\u001b[1;32m    789\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoders\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModuleList\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoders\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 791\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dims\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz_dim\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mm\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    792\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmu\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    793\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd_a\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlambd_a\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.7/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, name)\u001b[0m\n\u001b[1;32m   1176\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1177\u001b[0m         raise AttributeError(\"'{}' object has no attribute '{}'\".format(\n\u001b[0;32m-> 1178\u001b[0;31m             type(self).__name__, name))\n\u001b[0m\u001b[1;32m   1179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__setattr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mUnion\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'Module'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'Twin' object has no attribute 'models'"
     ]
    }
   ],
   "source": [
    "train_lm(\n",
    "    training_args_tokcl,\n",
    "    loader_path,\n",
    "    data_config_name,\n",
    "    tokenized_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c48ae6c8",
   "metadata": {},
   "source": [
    "#### With CLI:\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py NOLM --data_dir /data/json/oapmc_twin --per_device_train_batch_size=64 --per_device_eval_batch_size=64 --logging_steps=100 --num_train_epochs=100 --save_steps=12000\n",
    "```\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_twin.py SEQ2SEQ --data_dir /data/json/emboj_twin --per_device_train_batch_size=16 --per_device_eval_batch_size=16 --logging_steps=100 --num_train_epochs=1 --no_cache \n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e44faba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d10d1189",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
