{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f670bc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8519d7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c366411",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11417d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.config import config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce329805",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdbf0303",
   "metadata": {},
   "outputs": [],
   "source": [
    "config.tokenizer.mask_token"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47de7036",
   "metadata": {},
   "source": [
    "## Extracting examples for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "483aa797",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.extract import ExtractorXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab4b2a72",
   "metadata": {},
   "outputs": [],
   "source": [
    "! dir /data/xml/emboj_all"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "120e0d7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr /data/text/emboj_abstract_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d829a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"/data/xml/emboj_all\"\n",
    "text_examples = \"/data/text/emboj_abstract_test\"\n",
    "xpath = \".//abstract\"\n",
    "sentence_level = False\n",
    "keep_xml = False\n",
    "inclusion_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5225c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_lm = ExtractorXML(\n",
    "    corpus,\n",
    "    destination_dir=text_examples,\n",
    "    sentence_level=sentence_level,\n",
    "    xpath=xpath,\n",
    "    keep_xml=keep_xml,\n",
    "    inclusion_probability=inclusion_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d244651b",
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor_lm.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7903e1b8",
   "metadata": {},
   "source": [
    "same via CLI:\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/mini/ /data/text/mini --xpath \".//abstract\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32b17596",
   "metadata": {},
   "source": [
    "## Preparing tokenized dataset for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a055aae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.dataprep import PreparatorLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4db0546",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examples = \"/data/json/emboj_abstract_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678d301a",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr /data/json/emboj_abstract_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71046558",
   "metadata": {},
   "outputs": [],
   "source": [
    "prep_lm = PreparatorLM(\n",
    "    text_examples,\n",
    "    tokenized_examples,\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c64b44b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "prep_lm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf8a97a",
   "metadata": {},
   "source": [
    "same vie CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/mini /data/json/mini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13c0fff1",
   "metadata": {},
   "source": [
    "## Train LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "998324b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.train.train_lm import (\n",
    "    train as train_lm,\n",
    "    TrainingArgumentsLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46fcf7ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cache = False\n",
    "loader_path = \"./smtag/loader/loader_lm.py\"  # includes a loading script with the same name ./lm/lm.py\n",
    "data_config_name = \"DET\"\n",
    "tokenizer = config.tokenizer  # tokenizer has to be the same application-wide\n",
    "model_type = \"Autoencoder\"\n",
    "from_pretrained = config.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e542b76",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.mask_token = '<mask>'\n",
    "# tokenizer.unk_token = '<unk>'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85e54aae",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "training_args_tokcl = TrainingArgumentsLM(\n",
    "    num_train_epochs = 30,\n",
    "    logging_steps = 10,\n",
    "    per_device_train_batch_size=4, #32,\n",
    "    per_device_eval_batch_size=3, #32,\n",
    ")\n",
    "training_args_tokcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad68f4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_lm(\n",
    "    training_args_tokcl,\n",
    "    loader_path,\n",
    "    data_config_name,\n",
    "    tokenized_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "095b26ff",
   "metadata": {},
   "source": [
    "train with command line:\n",
    "\n",
    "    python -m smtag.cli.lm.train \"./smtag/loader/loader_lm.py\" DET --data_dir /data/json/emboj_abstract_test --no_cache --per_device_train_batch_size=4 --per_device_eval_batch_size=4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c63676d4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
