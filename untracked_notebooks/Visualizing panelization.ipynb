{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2daa7b89",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from transformers import AutoModelForTokenClassification, AutoTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ea4d11f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78c81f733d6840bdba34a237e3043443",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/877 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "03cc1f55d1d8464eafbb4bb1560b72b5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.24G [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "208b09c2582643ddbd2a4c6e7dc81119",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/379 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8702529d88124029924d0c0de962d6d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/220k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "56a285afc93f4dd7b5271b6e3c4cb4f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/436k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model = AutoModelForTokenClassification.from_pretrained(\"EMBO/sd-panelization-v2\")\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EMBO/sd-panelization-v2\",\n",
    "                                         add_prefix_space=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7fcf4b06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5acff0454db548578c03fce4adc88880",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/10.3k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading and preparing dataset source_data_nlp/PANELIZATION to /root/.cache/huggingface/datasets/EMBO___source_data_nlp/PANELIZATION/2.0.0/697847190b4f17eb8b2bf15419fdd4e8cacc32bc57734ea9909016d809b4eb55...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "182bdc41eab942d8a9998a1398577eb9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/3.78M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset source_data_nlp downloaded and prepared to /root/.cache/huggingface/datasets/EMBO___source_data_nlp/PANELIZATION/2.0.0/697847190b4f17eb8b2bf15419fdd4e8cacc32bc57734ea9909016d809b4eb55. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0eedd1ae94a4d4b95e2e6a1569dbd31",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "\n",
    "ds = load_dataset(\"EMBO/sd-nlp-v2\", \"PANELIZATION\")[\"train\"]\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"EMBO/sd-panelization-v2\", model_max_length=512)\n",
    "\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"EMBO/sd-panelization-v2\")\n",
    "\n",
    "tagger = pipeline(task=\"token-classification\", \n",
    "                     model=model, \n",
    "                     tokenizer=tokenizer,\n",
    "                     device=0,\n",
    "                     aggregation_strategy=\"none\")\n",
    "\n",
    "tokenizer_kwargs = {'padding':True,'truncation':True,'max_length':512,'return_tensors':'pt'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f8e52263",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Logging before flag parsing goes to stderr.\n",
      "W1004 13:14:50.943357 139662323529536 builder.py:532] Reusing dataset source_data_nlp (/root/.cache/huggingface/datasets/EMBO___source_data_nlp/PANELIZATION/2.0.0/697847190b4f17eb8b2bf15419fdd4e8cacc32bc57734ea9909016d809b4eb55)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c962453cf9ec480a8e23fe9bfea0cb9e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['words', 'text', 'labels', 'tag_mask'],\n",
       "        num_rows: 2648\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['words', 'text', 'labels', 'tag_mask'],\n",
       "        num_rows: 307\n",
       "    })\n",
       "    validation: Dataset({\n",
       "        features: ['words', 'text', 'labels', 'tag_mask'],\n",
       "        num_rows: 312\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dataset(\"EMBO/sd-nlp-v2\", \"PANELIZATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7958b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML as html_print\n",
    "\n",
    "def color_string(s, color='black'):\n",
    "    return \"<text style=background-color:{};weight:b>{}</text>\".format(color, s)\n",
    "def normal_string(s, color='black'):\n",
    "    return \"<text style=color:{};weight:b>{}</text>\".format(color, s)\n",
    "\n",
    "def get_predicted_panels(example):\n",
    "    generation = tagger(\" \".join(example[\"words\"]))\n",
    "    list_ = []\n",
    "    for item in generation:\n",
    "        if item[\"entity\"] == \"B-PANEL_START\":\n",
    "            list_.append(item)\n",
    "    return list_\n",
    "\n",
    "def get_labeled_panels(example):\n",
    "    chars = 0\n",
    "    list_ = []\n",
    "    for idx, i in enumerate(example[\"labels\"]):\n",
    "        word = example[\"words\"][idx]\n",
    "        if i == 1:\n",
    "            list_.append({\n",
    "                \"index\": idx,\n",
    "                \"start\": chars\n",
    "            })\n",
    "        chars += len(word) + 1\n",
    "    return list_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ff48fc0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_example(idx):\n",
    "    example = ds[idx]\n",
    "\n",
    "    predictions = get_predicted_panels(example)\n",
    "    labels = get_labeled_panels(example)\n",
    "    text = \" \".join(example[\"words\"])\n",
    "\n",
    "    chars = 0\n",
    "    text = \"\"\n",
    "    for word in example[\"words\"]:\n",
    "        if chars in [d['start'] for d in predictions if 'start' in d] and chars not in [d['start'] for d in labels if 'start' in d]:\n",
    "            text += color_string(word, color='cyan')\n",
    "        elif chars in [d['start'] for d in predictions if 'start' in d] and chars in [d['start'] for d in labels if 'start' in d]:\n",
    "            text += color_string(word, color='lime')\n",
    "        elif chars not in [d['start'] for d in predictions if 'start' in d] and chars in [d['start'] for d in labels if 'start' in d]:\n",
    "            text += color_string(word, color='red')\n",
    "        else:\n",
    "            text += normal_string(word, color='black')\n",
    "        text += \" \"\n",
    "        chars += len(word) + 1\n",
    "        \n",
    "    return text, predictions, labels\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d39b52f",
   "metadata": {},
   "source": [
    "## Visualizing the panelization task\n",
    "\n",
    "Below can be shown the prediction of our machine learning model on the figure legend when the panelization task is applied. Color codes are as following:\n",
    "\n",
    "* <font color='lime'>Green (True positive)</font> - Correct prediction\n",
    "* <font color='red'>Red (False negative)</font>   - The prediction missed a panel start present in the labelled data\n",
    "* <font color='cyan'>Cyan (False positive or bad labelling)</font>  - The prediction shows a positive panel not shown in the labelled data\n",
    "* Black - true negatives :-)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b599a1e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1004 13:17:57.846580 139662323529536 builder.py:532] Reusing dataset source_data_nlp (/root/.cache/huggingface/datasets/EMBO___source_data_nlp/PANELIZATION/2.0.0/697847190b4f17eb8b2bf15419fdd4e8cacc32bc57734ea9909016d809b4eb55)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32a30e24c93d47aa80befc5f5f3bda80",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "ds = load_dataset(\"EMBO/sd-nlp-v2\", \"PANELIZATION\")\n",
    "temp_train_ds = ds[\"train\"].to_pandas()\n",
    "temp_test_ds = ds[\"test\"].to_pandas()\n",
    "temp_eval_ds = ds[\"validation\"].to_pandas()\n",
    "ds = ds[\"test\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ac4bae63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "ds = Dataset.from_pandas(temp_train_ds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "f184b4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "EXAMPLE = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75c09518",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'IP3R1 silencing favors frequent changes in direction in immature DCs migrating in micro‐channelsAnalysis of shScramble (gray)‐, shIP3R(1,3)A (blue)‐, shIP3R(2,3)B (red)‐, and shIP3R(1,3)C (green)‐expressing DCs migrating in micro‐channels (n\\xa0>\\xa0100 cells per condition from 3 independent experiments for shIP3R(1,3)A and shIP3R(1,3)C and two independent experiments for shIP3R(2,3)B).Figure 3Analysis of shScramble (gray)‐, shIP3R(1,3) A (blue)‐, shIP3R(2,3) B (red)‐, and shIP3R(1,3) C (green)‐expressing DCs migrating in micro‐channels (n > 100 cells per condition from 3 independent experiments for shIP3R(1,3) A and shIP3R(1,3) C and two independent experiments for shIP3R(2,3) B).A Velocity fluctuations (ΔV/V0) of immature DCs migrating in micro‐channels. Boxes illustrate 10-90 percentiles of values, and whiskers represent the range of values. P‐values were calculated using a Kruskal-Wallis test. Analysis of shScramble (gray)‐, shIP3R(1,3) A (blue)‐, shIP3R(2,3) B (red)‐, and shIP3R(1,3) C (green)‐expressing DCs migrating in micro‐channels (n > 100 cells per condition from 3 independent experiments for shIP3R(1,3) A and shIP3R(1,3) C and two independent experiments for shIP3R(2,3) B).B Dot plot showing velocity fluctuations and migration speeds of shScramble (gray)‐ and shIP3R(1,3) C (green)‐expressing DCs. Analysis of shScramble (gray)‐, shIP3R(1,3) A (blue)‐, shIP3R(2,3) B (red)‐, and shIP3R(1,3) C (green)‐expressing DCs migrating in micro‐channels (n > 100 cells per condition from 3 independent experiments for shIP3R(1,3) A and shIP3R(1,3) C and two independent experiments for shIP3R(2,3) B).C Inverted sequential epifluorescence images (20×) of a representative control DC (left) and an immature shIP3R(1,3) C‐silenced DC (right) migrating in micro‐channels. DCs were differentiated from LifeAct‐GFP transgenic mice and imaged every 2.2 min. Analysis of shScramble (gray)‐, shIP3R(1,3) A (blue)‐, shIP3R(2,3) B (red)‐, and shIP3R(1,3) C (green)‐expressing DCs migrating in micro‐channels (n > 100 cells per condition from 3 independent experiments for shIP3R(1,3) A and shIP3R(1,3) C and two independent experiments for shIP3R(2,3) B).D Percentage of DCs changing their direction of locomotion while migrating in micro‐channels. P‐values were calculated with a paired test with respect to the shScramble condition. Analysis of shScramble (gray)‐, shIP3R(1,3) A (blue)‐, shIP3R(2,3) B (red)‐, and shIP3R(1,3) C (green)‐expressing DCs migrating in micro‐channels (n > 100 cells per condition from 3 independent experiments for shIP3R(1,3) A and shIP3R(1,3) C and two independent experiments for shIP3R(2,3) B).E Dot plot showing the frequency of changes in direction of immature DCs while migrating in micro‐channels. Bars show the mean plus the standard deviation. A Kruskal-Wallis test was applied for statistical analysis. '"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds[EXAMPLE]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "cb0d9755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "883\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<text style=color:black;weight:b>IP3R1</text> <text style=color:black;weight:b>silencing</text> <text style=color:black;weight:b>favors</text> <text style=color:black;weight:b>frequent</text> <text style=color:black;weight:b>changes</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>direction</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>immature</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channelsAnalysis</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>gray</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>blue</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>red</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>green</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>expressing</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>n</text> <text style=color:black;weight:b> </text> <text style=color:black;weight:b>></text> <text style=color:black;weight:b> </text> <text style=color:black;weight:b>100</text> <text style=color:black;weight:b>cells</text> <text style=color:black;weight:b>per</text> <text style=color:black;weight:b>condition</text> <text style=color:black;weight:b>from</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>two</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>Figure</text> <text style=background-color:lime;weight:b>3Analysis</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>gray</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>blue</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>red</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>green</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>expressing</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>n</text> <text style=color:black;weight:b>></text> <text style=color:black;weight:b>100</text> <text style=color:black;weight:b>cells</text> <text style=color:black;weight:b>per</text> <text style=color:black;weight:b>condition</text> <text style=color:black;weight:b>from</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>two</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>Velocity</text> <text style=color:black;weight:b>fluctuations</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>ΔV</text> <text style=color:black;weight:b>/</text> <text style=color:black;weight:b>V0</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>immature</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>Boxes</text> <text style=color:black;weight:b>illustrate</text> <text style=color:black;weight:b>10</text> <text style=color:black;weight:b>-</text> <text style=color:black;weight:b>90</text> <text style=color:black;weight:b>percentiles</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>values</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>whiskers</text> <text style=color:black;weight:b>represent</text> <text style=color:black;weight:b>the</text> <text style=color:black;weight:b>range</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>values</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>P</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>values</text> <text style=color:black;weight:b>were</text> <text style=color:black;weight:b>calculated</text> <text style=color:black;weight:b>using</text> <text style=color:black;weight:b>a</text> <text style=color:black;weight:b>Kruskal</text> <text style=color:black;weight:b>-</text> <text style=color:black;weight:b>Wallis</text> <text style=color:black;weight:b>test</text> <text style=color:black;weight:b>.</text> <text style=background-color:lime;weight:b>Analysis</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>gray</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>blue</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>red</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>green</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>expressing</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>n</text> <text style=color:black;weight:b>></text> <text style=color:black;weight:b>100</text> <text style=color:black;weight:b>cells</text> <text style=color:black;weight:b>per</text> <text style=color:black;weight:b>condition</text> <text style=color:black;weight:b>from</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>two</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>Dot</text> <text style=color:black;weight:b>plot</text> <text style=color:black;weight:b>showing</text> <text style=color:black;weight:b>velocity</text> <text style=color:black;weight:b>fluctuations</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>migration</text> <text style=color:black;weight:b>speeds</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>gray</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>green</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>expressing</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>.</text> <text style=background-color:lime;weight:b>Analysis</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>gray</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>blue</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>red</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>green</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>expressing</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>n</text> <text style=color:black;weight:b>></text> <text style=color:black;weight:b>100</text> <text style=color:black;weight:b>cells</text> <text style=color:black;weight:b>per</text> <text style=color:black;weight:b>condition</text> <text style=color:black;weight:b>from</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>two</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>Inverted</text> <text style=color:black;weight:b>sequential</text> <text style=color:black;weight:b>epifluorescence</text> <text style=color:black;weight:b>images</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>20</text> <text style=color:black;weight:b>×</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>a</text> <text style=color:black;weight:b>representative</text> <text style=color:black;weight:b>control</text> <text style=color:black;weight:b>DC</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>left</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>an</text> <text style=color:black;weight:b>immature</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>silenced</text> <text style=color:black;weight:b>DC</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>right</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>were</text> <text style=color:black;weight:b>differentiated</text> <text style=color:black;weight:b>from</text> <text style=color:black;weight:b>LifeAct</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>GFP</text> <text style=color:black;weight:b>transgenic</text> <text style=color:black;weight:b>mice</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>imaged</text> <text style=color:black;weight:b>every</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>min</text> <text style=color:black;weight:b>.</text> <text style=background-color:red;weight:b>Analysis</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>gray</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>blue</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>red</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>green</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>expressing</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>n</text> <text style=color:black;weight:b>></text> <text style=color:black;weight:b>100</text> <text style=color:black;weight:b>cells</text> <text style=color:black;weight:b>per</text> <text style=color:black;weight:b>condition</text> <text style=color:black;weight:b>from</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>two</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>D</text> <text style=color:black;weight:b>Percentage</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>changing</text> <text style=color:black;weight:b>their</text> <text style=color:black;weight:b>direction</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>locomotion</text> <text style=color:black;weight:b>while</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>P</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>values</text> <text style=color:black;weight:b>were</text> <text style=color:black;weight:b>calculated</text> <text style=color:black;weight:b>with</text> <text style=color:black;weight:b>a</text> <text style=color:black;weight:b>paired</text> <text style=color:black;weight:b>test</text> <text style=color:black;weight:b>with</text> <text style=color:black;weight:b>respect</text> <text style=color:black;weight:b>to</text> <text style=color:black;weight:b>the</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>condition</text> <text style=color:black;weight:b>.</text> <text style=background-color:red;weight:b>Analysis</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>shScramble</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>gray</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>blue</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>red</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>green</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>expressing</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>n</text> <text style=color:black;weight:b>></text> <text style=color:black;weight:b>100</text> <text style=color:black;weight:b>cells</text> <text style=color:black;weight:b>per</text> <text style=color:black;weight:b>condition</text> <text style=color:black;weight:b>from</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>1</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>C</text> <text style=color:black;weight:b>and</text> <text style=color:black;weight:b>two</text> <text style=color:black;weight:b>independent</text> <text style=color:black;weight:b>experiments</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>shIP3R</text> <text style=color:black;weight:b>(</text> <text style=color:black;weight:b>2</text> <text style=color:black;weight:b>,</text> <text style=color:black;weight:b>3</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>B</text> <text style=color:black;weight:b>)</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>E</text> <text style=color:black;weight:b>Dot</text> <text style=color:black;weight:b>plot</text> <text style=color:black;weight:b>showing</text> <text style=color:black;weight:b>the</text> <text style=color:black;weight:b>frequency</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>changes</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>direction</text> <text style=color:black;weight:b>of</text> <text style=color:black;weight:b>immature</text> <text style=color:black;weight:b>DCs</text> <text style=color:black;weight:b>while</text> <text style=color:black;weight:b>migrating</text> <text style=color:black;weight:b>in</text> <text style=color:black;weight:b>micro</text> <text style=color:black;weight:b>‐</text> <text style=color:black;weight:b>channels</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>Bars</text> <text style=color:black;weight:b>show</text> <text style=color:black;weight:b>the</text> <text style=color:black;weight:b>mean</text> <text style=color:black;weight:b>plus</text> <text style=color:black;weight:b>the</text> <text style=color:black;weight:b>standard</text> <text style=color:black;weight:b>deviation</text> <text style=color:black;weight:b>.</text> <text style=color:black;weight:b>A</text> <text style=color:black;weight:b>Kruskal</text> <text style=color:black;weight:b>-</text> <text style=color:black;weight:b>Wallis</text> <text style=color:black;weight:b>test</text> <text style=color:black;weight:b>was</text> <text style=color:black;weight:b>applied</text> <text style=color:black;weight:b>for</text> <text style=color:black;weight:b>statistical</text> <text style=color:black;weight:b>analysis</text> <text style=color:black;weight:b>.</text> "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text, predictions_transformer, labels = show_example(EXAMPLE)\n",
    "print(len(tokenizer(ds[EXAMPLE][\"words\"], is_split_into_words=True)[\"input_ids\"]))\n",
    "html_print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51b4f9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.decode(tokenizer(ds[EXAMPLE][\"text\"])[\"input_ids\"][512:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1576,
   "id": "06f20fa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 1576,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagger(tokenizer.decode(tokenizer(ds[EXAMPLE][\"text\"])[\"input_ids\"][512:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1577,
   "id": "5e4de1d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ed, wi'"
      ]
     },
     "execution_count": 1577,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(tokenizer(ds[EXAMPLE][\"text\"])[\"input_ids\"][512:])[114:120]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1578,
   "id": "8b2e1628",
   "metadata": {},
   "outputs": [],
   "source": [
    "panel_types = {0: \"(a)_and_(a,b)\",\n",
    "               1: \"(A)\",\n",
    "               2: \"Figure XA_and_B\",\n",
    "               3: \"(left)_(right)_labels_at_end\",\n",
    "               4: \"(A)_labels_at_end\",\n",
    "               5: \"Not clear for humans\",\n",
    "               6: \"A or A,B\",\n",
    "               7: \"No panels\",\n",
    "               8: \"a, and a,b\",\n",
    "               9: \"A)\"}\n",
    "panel_type_list = [0,0,0,1,2,2,0,1,0,3,0,0,1,4,5,6,2,7,1,1,\n",
    "                   0,6,0,6,0,1,1,0,0,1,0,7,6,8,0,0,7,6,1,0,\n",
    "                   7,8,8,1,0,1,0,8,8,9,4,6,7,7,0,7,7,6,9,0,\n",
    "                   7,6,0,7,0,0,6,6,1,6,7,7,0,1,0,1,0,6,6,0,\n",
    "                  0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1579,
   "id": "954a756b",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_good_labels = [5,6,2,4,7,5,6,3,3,1,8,3,2,7,2,7,5,1,2,2,\n",
    "                     2,1,2,3,3,6,2,4,5,1,2,2,7,5,3,2,1,12,2,6,\n",
    "                     1,3,4,2,0,2,2,7,4,7,3,2,4,4,4,4,1,5,5,4,\n",
    "                     1,2,2,1,2,2,8,6,3,6,1,1,3,3,2,7,2,6,3,3,\n",
    "                    9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1580,
   "id": "06d973f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "total_labelled_panels = [5,6,2,4,4,5,5,5,3,1,8,3,2,7,3,8,5,1,2,0,\n",
    "                         2,2,2,3,3,6,2,4,5,1,2,2,7,5,4,2,1,12,3,6,\n",
    "                         1,2,4,2,0,2,2,4,4,7,3,2,4,4,4,4,1,4,5,4,\n",
    "                        1,2,2,1,3,2,8,6,3,6,1,1,4,3,2,6,2,6,2,3,\n",
    "                        7,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1581,
   "id": "2b277f2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_panel_separations = [5,7,2,4,8,5,6,5,3,2,8,3,2,8,3,8,5,1,2,5,\n",
    "                            2,2,3,3,3,6,2,4,5,4,2,2,7,5,4,2,1,12,3,6,\n",
    "                            1,5,4,2,6,2,3,7,8,8,3,2,4,4,2,4,1,8,5,4,\n",
    "                           1,2,3,3,2,2,8,6,3,5,1,1,6,3,2,7,5,6,3,3,\n",
    "                           9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1582,
   "id": "f5d1f8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "wrong_defined_labels = [0,1,0,0,3,0,1,0,0,2,0,0,1,0,3,0,0,0,0,6,\n",
    "                        0,1,3,0,0,0,0,0,0,4,0,0,0,0,0,0,0,0,0,0,\n",
    "                        0,4,0,0,0,0,1,3,4,1,0,0,0,0,2,0,0,4,0,0,\n",
    "                        0,0,1,0,1,0,0,0,3,1,0,0,1,0,0,0,3,0,1,0,\n",
    "                       2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1583,
   "id": "650e4ae9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(81, 81, 81, 81, 81)"
      ]
     },
     "execution_count": 1583,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(panel_type_list), len(total_good_labels),len(total_labelled_panels),len(actual_panel_separations),len(wrong_defined_labels),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1584,
   "id": "a2b59693",
   "metadata": {},
   "outputs": [],
   "source": [
    "special_examples = [9,13,14,29,38,46,54,74]\n",
    "for idx in special_examples[::-1]:\n",
    "    total_good_labels.pop(idx)\n",
    "    total_labelled_panels.pop(idx)\n",
    "    actual_panel_separations.pop(idx)\n",
    "    wrong_defined_labels.pop(idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1585,
   "id": "15adbb30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(73, 73, 73, 73)"
      ]
     },
     "execution_count": 1585,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(total_good_labels),len(total_labelled_panels),len(actual_panel_separations),len(wrong_defined_labels),"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1586,
   "id": "6450f8dd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(272, 264, 307, 45)"
      ]
     },
     "execution_count": 1586,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(total_good_labels), sum(total_labelled_panels), sum(actual_panel_separations), sum(wrong_defined_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1587,
   "id": "a175578c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "% success with labeled data 103.03030303030303\n",
      "% success with actual number of panels 88.59934853420195\n",
      "% wrong defined labels from total panels 14.657980456026058\n",
      "% wrong defined labels from labels 16.544117647058822\n"
     ]
    }
   ],
   "source": [
    "print(f\"% success with labeled data {100*sum(total_good_labels)/sum(total_labelled_panels)}\")\n",
    "print(f\"% success with actual number of panels {100*sum(total_good_labels)/sum(actual_panel_separations)}\")\n",
    "print(f\"% wrong defined labels from total panels {100*sum(wrong_defined_labels)/sum(actual_panel_separations)}\")\n",
    "print(f\"% wrong defined labels from labels {100*sum(wrong_defined_labels)/sum(total_good_labels)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1588,
   "id": "097a0e9b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(229, 232), (316, 319)]"
      ]
     },
     "execution_count": 1588,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = [[\"F\",\"Immunofluorescence\"],[\"H\", \"Bar\"],[\"J\",\",\",\"K\"]] # Repeat this one\n",
    "pattern = [[\"(\",\"d\", \")\"],[\"(\",\"e\",\")\"]] \n",
    "#pattern = [[\"figf2Stable\"]]\n",
    "a = ds[EXAMPLE][\"words\"]\n",
    "offsets = []\n",
    "for b in pattern:\n",
    "    offsets.append([(i, i+len(b)) for i in range(len(a)) if a[i:i+len(b)] == b][0])\n",
    "offsets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1589,
   "id": "8e06f45e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "9\n"
     ]
    }
   ],
   "source": [
    "label_list = ds[EXAMPLE][\"labels\"]\n",
    "print(sum(label_list))\n",
    "for offset in offsets:\n",
    "    label_list[offset[0]] = 1\n",
    "# label_list[371] = 0\n",
    "print(sum(label_list))\n",
    "temp_train_ds.iloc[EXAMPLE][\"labels\"] = np.array(label_list)\n",
    "temp_train_ds.to_pickle(\"/app/data/modified_panelization_v2_labels_train.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "64372844",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting tensorflow\n",
      "  Downloading tensorflow-2.10.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (578.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m578.1/578.1 MB\u001b[0m \u001b[31m99.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting astunparse>=1.6.0\n",
      "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.43.0)\n",
      "Collecting libclang>=13.0.0\n",
      "  Downloading libclang-14.0.6-py2.py3-none-manylinux2010_x86_64.whl (14.1 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.1/14.1 MB\u001b[0m \u001b[31m33.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: protobuf<3.20,>=3.9.2 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (3.19.3)\n",
      "Collecting wrapt>=1.11.0\n",
      "  Downloading wrapt-1.14.1-cp38-cp38-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (81 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m81.0/81.0 kB\u001b[0m \u001b[31m70.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting tensorboard<2.11,>=2.10\n",
      "  Downloading tensorboard-2.10.1-py3-none-any.whl (5.9 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.9/5.9 MB\u001b[0m \u001b[31m36.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hCollecting keras<2.11,>=2.10.0\n",
      "  Downloading keras-2.10.0-py2.py3-none-any.whl (1.7 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m53.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting keras-preprocessing>=1.1.1\n",
      "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m58.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting google-pasta>=0.1.1\n",
      "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m66.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting opt-einsum>=2.3.2\n",
      "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m80.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: packaging in /opt/conda/lib/python3.8/site-packages (from tensorflow) (21.3)\n",
      "Collecting flatbuffers>=2.0\n",
      "  Downloading flatbuffers-22.9.24-py2.py3-none-any.whl (26 kB)\n",
      "Requirement already satisfied: numpy>=1.20 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.22.2)\n",
      "Collecting termcolor>=1.1.0\n",
      "  Downloading termcolor-2.0.1-py3-none-any.whl (5.4 kB)\n",
      "Collecting h5py>=2.9.0\n",
      "  Downloading h5py-3.7.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (4.5 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.5/4.5 MB\u001b[0m \u001b[31m47.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: absl-py>=1.0.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.0.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (4.0.1)\n",
      "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
      "  Downloading tensorflow_io_gcs_filesystem-0.27.0-cp38-cp38-manylinux_2_12_x86_64.manylinux2010_x86_64.whl (2.4 MB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.4/2.4 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hCollecting tensorflow-estimator<2.11,>=2.10.0\n",
      "  Downloading tensorflow_estimator-2.10.0-py2.py3-none-any.whl (438 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m438.7/438.7 kB\u001b[0m \u001b[31m70.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting gast<=0.4.0,>=0.2.1\n",
      "  Downloading gast-0.4.0-py3-none-any.whl (9.8 kB)\n",
      "Requirement already satisfied: setuptools in /opt/conda/lib/python3.8/site-packages (from tensorflow) (64.0.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /opt/conda/lib/python3.8/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /opt/conda/lib/python3.8/site-packages (from astunparse>=1.6.0->tensorflow) (0.37.0)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.0.2)\n",
      "Requirement already satisfied: google-auth<3,>=1.6.3 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.6.1)\n",
      "Requirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (0.4.6)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (3.3.6)\n",
      "Requirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (1.8.1)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /opt/conda/lib/python3.8/site-packages (from tensorboard<2.11,>=2.10->tensorflow) (2.26.0)\n",
      "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.8/site-packages (from packaging->tensorflow) (3.0.6)\n",
      "Requirement already satisfied: rsa<5,>=3.1.4 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (4.8)\n",
      "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (5.0.0)\n",
      "Requirement already satisfied: pyasn1-modules>=0.2.1 in /opt/conda/lib/python3.8/site-packages (from google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.2.8)\n",
      "Requirement already satisfied: requests-oauthlib>=0.7.0 in /opt/conda/lib/python3.8/site-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (1.3.0)\n",
      "Requirement already satisfied: importlib-metadata>=4.4 in /opt/conda/lib/python3.8/site-packages (from markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (4.10.1)\n",
      "Requirement already satisfied: charset-normalizer~=2.0.0 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2.0.9)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (1.26.7)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (2021.10.8)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.8/site-packages (from requests<3,>=2.21.0->tensorboard<2.11,>=2.10->tensorflow) (3.1)\n",
      "Requirement already satisfied: zipp>=0.5 in /opt/conda/lib/python3.8/site-packages (from importlib-metadata>=4.4->markdown>=2.6.8->tensorboard<2.11,>=2.10->tensorflow) (3.7.0)\n",
      "Requirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /opt/conda/lib/python3.8/site-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.11,>=2.10->tensorflow) (0.4.8)\n",
      "Requirement already satisfied: oauthlib>=3.0.0 in /opt/conda/lib/python3.8/site-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.11,>=2.10->tensorflow) (3.1.1)\n",
      "Installing collected packages: libclang, keras, flatbuffers, wrapt, termcolor, tensorflow-io-gcs-filesystem, tensorflow-estimator, opt-einsum, keras-preprocessing, h5py, google-pasta, gast, astunparse, tensorboard, tensorflow\n",
      "  Attempting uninstall: tensorboard\n",
      "    Found existing installation: tensorboard 2.8.0\n",
      "    Uninstalling tensorboard-2.8.0:\n",
      "      Successfully uninstalled tensorboard-2.8.0\n",
      "Successfully installed astunparse-1.6.3 flatbuffers-22.9.24 gast-0.4.0 google-pasta-0.2.0 h5py-3.7.0 keras-2.10.0 keras-preprocessing-1.1.2 libclang-14.0.6 opt-einsum-3.3.0 tensorboard-2.10.1 tensorflow-2.10.0 tensorflow-estimator-2.10.0 tensorflow-io-gcs-filesystem-0.27.0 termcolor-2.0.1 wrapt-1.14.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0mNote: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d7ce0fa2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-10-04 13:19:56.354102: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2022-10-04 13:19:56.582057: E tensorflow/stream_executor/cuda/cuda_blas.cc:2981] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2022-10-04 13:19:57.478167: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer.so.7'; dlerror: libnvinfer.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-04 13:19:57.478311: W tensorflow/stream_executor/platform/default/dso_loader.cc:64] Could not load dynamic library 'libnvinfer_plugin.so.7'; dlerror: libnvinfer_plugin.so.7: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/compat/lib.real:/opt/conda/lib/python3.8/site-packages/torch/lib:/opt/conda/lib/python3.8/site-packages/torch_tensorrt/lib:/usr/local/cuda/compat/lib:/usr/local/nvidia/lib:/usr/local/nvidia/lib64\n",
      "2022-10-04 13:19:57.478324: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Cannot dlopen some TensorRT libraries. If you would like to use Nvidia GPU with TensorRT, please make sure the missing libraries mentioned above are installed properly.\n"
     ]
    }
   ],
   "source": [
    "from transformers import Pipeline\n",
    "from torch import Tensor\n",
    "import torch\n",
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "2548d63c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers.pipelines.base import ChunkPipeline\n",
    "from transformers.pipelines.token_classification import (TokenClassificationArgumentHandler, \n",
    "                                                         TokenClassificationPipeline, AggregationStrategy )\n",
    "from transformers.models.auto.modeling_auto import MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n",
    "from typing import Optional, List, Tuple, Union, Any, Dict\n",
    "from transformers.models.bert.tokenization_bert import BasicTokenizer\n",
    "from math import ceil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "f8706b46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LongTextTokenClassificationPipeline(ChunkPipeline):\n",
    "    \"\"\"\n",
    "    Named Entity Recognition pipeline using any `ModelForTokenClassification`. See the [named entity recognition\n",
    "    examples](../task_summary#named-entity-recognition) for more information.\n",
    "    Strings of any length can be passed. If they exceed `ModelForTokenClassification.config.max_position_embeddings` tokens,\n",
    "    they will be divided into several parts text that will be passed to the `forward` method.\n",
    "    The results will then be concatenated together and be sent back.\n",
    "    *LongTextTokenClassificationPipeline* uses `offsets_mapping` and therefore is available only with `FastTokenizer`.\n",
    "    The models that this pipeline can use are models that have been fine-tuned on a token classification task. See the\n",
    "    up-to-date list of available models on\n",
    "    [huggingface.co/models](https://huggingface.co/models?filter=token-classification).\n",
    "    \"\"\"    \n",
    "    default_input_names = \"sequences\"\n",
    "\n",
    "    def __init__(self, args_parser=TokenClassificationArgumentHandler(), *args, **kwargs):\n",
    "        super().__init__(*args, **kwargs)\n",
    "        self.check_model_type(\n",
    "            TF_MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n",
    "            if self.framework == \"tf\"\n",
    "            else MODEL_FOR_TOKEN_CLASSIFICATION_MAPPING\n",
    "        )\n",
    "\n",
    "        self._basic_tokenizer = BasicTokenizer(do_lower_case=False)\n",
    "        self._args_parser = args_parser\n",
    "        if not self.tokenizer.is_fast:\n",
    "            raise TypeError(\n",
    "            \"\"\"LongTextTokenClassificationPipeline works only with fast tokenizers.\n",
    "            Please choose a fast tokenizer.\"\"\"\n",
    "            )\n",
    "\n",
    "    def _sanitize_parameters(\n",
    "        self,\n",
    "        ignore_labels=None,\n",
    "        grouped_entities: Optional[bool] = None,\n",
    "        ignore_subwords: Optional[bool] = None,\n",
    "        aggregation_strategy: Optional[AggregationStrategy] = None,\n",
    "        offset_mapping: Optional[List[Tuple[int, int]]] = None,\n",
    "        stride: Optional[int] = None,\n",
    "    ):\n",
    "\n",
    "        preprocess_params = {}\n",
    "        if offset_mapping is not None:\n",
    "            preprocess_params[\"offset_mapping\"] = offset_mapping\n",
    "\n",
    "        postprocess_params = {}\n",
    "        if grouped_entities is not None or ignore_subwords is not None:\n",
    "            if grouped_entities and ignore_subwords:\n",
    "                aggregation_strategy = AggregationStrategy.FIRST\n",
    "            elif grouped_entities and not ignore_subwords:\n",
    "                aggregation_strategy = AggregationStrategy.SIMPLE\n",
    "            else:\n",
    "                aggregation_strategy = AggregationStrategy.NONE\n",
    "\n",
    "            if grouped_entities is not None:\n",
    "                warnings.warn(\n",
    "                    \"`grouped_entities` is deprecated and will be removed in version v5.0.0, defaulted to\"\n",
    "                    f' `aggregation_strategy=\"{aggregation_strategy}\"` instead.'\n",
    "                )\n",
    "            if ignore_subwords is not None:\n",
    "                warnings.warn(\n",
    "                    \"`ignore_subwords` is deprecated and will be removed in version v5.0.0, defaulted to\"\n",
    "                    f' `aggregation_strategy=\"{aggregation_strategy}\"` instead.'\n",
    "                )\n",
    "\n",
    "        if aggregation_strategy is not None:\n",
    "            if isinstance(aggregation_strategy, str):\n",
    "                aggregation_strategy = AggregationStrategy[aggregation_strategy.upper()]\n",
    "            if (\n",
    "                aggregation_strategy\n",
    "                in {AggregationStrategy.FIRST, AggregationStrategy.MAX, AggregationStrategy.AVERAGE}\n",
    "                and not self.tokenizer.is_fast\n",
    "            ):\n",
    "                raise ValueError(\n",
    "                    \"Slow tokenizers cannot handle subwords. Please set the `aggregation_strategy` option\"\n",
    "                    'to `\"simple\"` or use a fast tokenizer.'\n",
    "                )\n",
    "            postprocess_params[\"aggregation_strategy\"] = aggregation_strategy\n",
    "        if ignore_labels is not None:\n",
    "            postprocess_params[\"ignore_labels\"] = ignore_labels\n",
    "            \n",
    "            \n",
    "        if stride is not None:\n",
    "            if not isinstance(stride, int): \n",
    "                raise TypeError(\n",
    "                    f\"Strides must be of type `int`. {type(stride)} was given.\"\n",
    "                )\n",
    "            postprocess_params[\"stride\"] = stride\n",
    "            preprocess_params[\"stride\"] = stride\n",
    "            \n",
    "        return preprocess_params, {}, postprocess_params\n",
    "    \n",
    "    def __call__(self, inputs: Union[str, List[str]], **kwargs):\n",
    "        \"\"\"\n",
    "        Classify each token of the text(s) given as inputs.\n",
    "        Args:\n",
    "            inputs (`str` or `List[str]`):\n",
    "                One or several texts (or one list of texts) for token classification.\n",
    "        Return:\n",
    "            A list or a list of list of `dict`: Each result comes as a list of dictionaries (one for each token in the\n",
    "            corresponding input, or each entity if this pipeline was instantiated with an aggregation_strategy) with\n",
    "            the following keys:\n",
    "            - **word** (`str`) -- The token/word classified. This is obtained by decoding the selected tokens. If you\n",
    "              want to have the exact string in the original sentence, use `start` and `stop`.\n",
    "            - **score** (`float`) -- The corresponding probability for `entity`.\n",
    "            - **entity** (`str`) -- The entity predicted for that token/word (it is named *entity_group* when\n",
    "              *aggregation_strategy* is not `\"none\"`.\n",
    "            - **index** (`int`, only present when `aggregation_strategy=\"none\"`) -- The index of the corresponding\n",
    "              token in the sentence.\n",
    "            - **start** (`int`, *optional*) -- The index of the start of the corresponding entity in the sentence. Only\n",
    "              exists if the offsets are available within the tokenizer\n",
    "            - **end** (`int`, *optional*) -- The index of the end of the corresponding entity in the sentence. Only\n",
    "              exists if the offsets are available within the tokenizer\n",
    "        \"\"\"\n",
    "\n",
    "        _inputs, offset_mapping = self._args_parser(inputs, **kwargs)\n",
    "        if offset_mapping:\n",
    "            kwargs[\"offset_mapping\"] = offset_mapping\n",
    "            \n",
    "        return super().__call__(inputs, **kwargs)\n",
    "\n",
    "    def preprocess(self, sentence, offset_mapping=None, stride=0):\n",
    "        truncation = False\n",
    "        \n",
    "        model_inputs = self.tokenizer(\n",
    "            sentence,\n",
    "            return_tensors=None,\n",
    "            truncation=truncation,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_offsets_mapping=self.tokenizer.is_fast,\n",
    "        )\n",
    "\n",
    "#         sentence_chunks = self._get_sentence_chunks(model_inputs[\"input_ids\"], stride)\n",
    "                        \n",
    "        if offset_mapping:\n",
    "            model_inputs[\"offset_mapping\"] = offset_mapping\n",
    "                    \n",
    "        model_inputs[\"sentence\"] = sentence\n",
    "        \n",
    "        idx_lookup = list(range(len(model_inputs[\"input_ids\"])))[1:-1]\n",
    "        first_token = 0\n",
    "        bos_token = model_inputs[\"input_ids\"][0]\n",
    "        eos_token = model_inputs[\"input_ids\"][-1]\n",
    "        \n",
    "        chunk_inputs = {}\n",
    "        \n",
    "        while first_token < len(idx_lookup):\n",
    "            start = max(0,first_token-stride)\n",
    "            end = min(start + self.model.config.max_length - 2, len(idx_lookup))\n",
    "            \n",
    "            chunk_inputs[\"input_ids\"] = self._to_tensor(\n",
    "                [bos_token] + model_inputs[\"input_ids\"][1:-1][start:end] + [eos_token]\n",
    "                )\n",
    "            chunk_inputs[\"token_type_ids\"] = self._to_tensor(\n",
    "                [0] + model_inputs[\"token_type_ids\"][1:-1][start:end] + [0]\n",
    "                )\n",
    "            chunk_inputs[\"attention_mask\"] = self._to_tensor(\n",
    "                [1] + model_inputs[\"attention_mask\"][1:-1][start:end] + [1]\n",
    "                )\n",
    "            chunk_inputs[\"special_tokens_mask\"] = self._to_tensor(\n",
    "                [1] + model_inputs[\"special_tokens_mask\"][1:-1][start:end] + [1]\n",
    "                )\n",
    "            chunk_inputs[\"offset_mapping\"] = [(0,0)] + model_inputs[\"offset_mapping\"][1:-1][start:end] + [(0,0)]\n",
    "            chunk_inputs[\"chunk_sentence\"] = tokenizer.decode(chunk_inputs[\"input_ids\"][0])\n",
    "            chunk_inputs[\"sentence\"] = sentence\n",
    "            \n",
    "            first_token = end\n",
    "                        \n",
    "            yield {**chunk_inputs}\n",
    "            \n",
    "    def _forward(self, chunk_inputs: Dict[str, Any]) -> List[dict]:\n",
    "        # Forward\n",
    "        special_tokens_mask = chunk_inputs.pop(\"special_tokens_mask\")\n",
    "        offset_mapping = chunk_inputs.pop(\"offset_mapping\", None)\n",
    "        sentence = chunk_inputs.pop(\"sentence\")\n",
    "        chunk_sentence = chunk_inputs.pop(\"chunk_sentence\")\n",
    "        if self.framework == \"tf\":\n",
    "            logits = self.model(chunk_inputs.data)[0]\n",
    "        else:\n",
    "            logits = self.model(**chunk_inputs)[0]\n",
    "\n",
    "        return {\n",
    "            \"logits\": logits,\n",
    "            \"special_tokens_mask\": special_tokens_mask,\n",
    "            \"offset_mapping\": offset_mapping,\n",
    "            \"sentence\": sentence,\n",
    "            \"chunk_sentence\": chunk_sentence,\n",
    "            **chunk_inputs,\n",
    "        }\n",
    "    \n",
    "    def postprocess(self, model_outputs: List[Dict[str, Any]], \n",
    "                    aggregation_strategy=AggregationStrategy.NONE, \n",
    "                    ignore_labels=None, \n",
    "                    stride=0):\n",
    "        sentence = model_outputs[0][\"sentence\"]\n",
    "        aggregated_tokenizer_outputs = tokenizer(sentence,\n",
    "            return_tensors=self.framework,\n",
    "            return_special_tokens_mask=True,\n",
    "            return_offsets_mapping=self.tokenizer.is_fast,\n",
    "        )\n",
    "        input_ids = aggregated_tokenizer_outputs[\"input_ids\"]\n",
    "        offset_mapping = aggregated_tokenizer_outputs[\"offset_mapping\"]\n",
    "        special_tokens_mask = aggregated_tokenizer_outputs[\"special_tokens_mask\"]\n",
    "        \n",
    "        logits = self._aggregate_chunk_outputs(model_outputs, stride)\n",
    "        \n",
    "        if ignore_labels is None:\n",
    "            ignore_labels = [\"O\"]\n",
    "        logits = logits.numpy()\n",
    "        input_ids = input_ids[0]\n",
    "        offset_mapping = offset_mapping[0] if offset_mapping is not None else None\n",
    "        special_tokens_mask = special_tokens_mask[0].numpy()\n",
    "\n",
    "        maxes = np.max(logits, axis=-1, keepdims=True)\n",
    "        shifted_exp = np.exp(logits - maxes)\n",
    "        scores = shifted_exp / shifted_exp.sum(axis=-1, keepdims=True)\n",
    "        \n",
    "        pre_entities = self.gather_pre_entities(\n",
    "            sentence, input_ids, scores, offset_mapping, special_tokens_mask, aggregation_strategy\n",
    "        )\n",
    "        grouped_entities = self.aggregate(pre_entities, aggregation_strategy)\n",
    "        print(grouped_entities)\n",
    "        # Filter anything that is in self.ignore_labels\n",
    "        entities = [\n",
    "            entity\n",
    "            for entity in grouped_entities\n",
    "            if entity.get(\"entity\", None) not in ignore_labels\n",
    "            and entity.get(\"entity_group\", None) not in ignore_labels\n",
    "        ]\n",
    "        return entities                \n",
    "        \n",
    "    def _to_tensor(self, inputs: List[Any]) -> Union[tf.Tensor, torch.tensor, np.ndarray]:\n",
    "        if self.framework == \"pt\":\n",
    "            return torch.tensor(inputs).unsqueeze(0)\n",
    "        if self.framework == \"tf\":\n",
    "            return tf.reshape(tf.convert_to_tensor(inputs), (1,-1))\n",
    "        if self.framework == \"np\":\n",
    "            return np.array(inputs).reshape(1,-1)\n",
    "\n",
    "    def _aggregate_chunk_outputs(self, outputs: \n",
    "                                 List[Dict[str, Any]], \n",
    "                                 stride: int) -> Union[tf.Tensor, torch.tensor, np.ndarray]:\n",
    "        \"\"\"\n",
    "        Change this to numpy or lits to save cuda space\n",
    "        \"\"\"\n",
    "        for iter_, chunk_output in enumerate(outputs):\n",
    "            is_first = (iter_ == 0)\n",
    "            is_last = (iter_ == len(outputs)-1)\n",
    "            if is_first:\n",
    "                logits = chunk_output[\"logits\"][0][:-1]\n",
    "            elif is_last:\n",
    "                logits = self._concat(logits, chunk_output[\"logits\"][0][stride+1:])\n",
    "            else:\n",
    "                logits = self._concat(logits, chunk_output[\"logits\"][0][stride+1:-1])\n",
    "                \n",
    "        return logits\n",
    "            \n",
    "    def _concat(self, \n",
    "                 t1: Union[tf.Tensor, torch.tensor, np.ndarray],\n",
    "                 t2: Union[tf.Tensor, torch.tensor, np.ndarray],\n",
    "                 axis: int  = 0\n",
    "                ) -> Union[tf.Tensor, torch.tensor, np.ndarray]:\n",
    "        if self.framework == \"pt\":\n",
    "            concat = torch.concat([t1, t2], axis=axis)\n",
    "        if self.framework == \"tf\":\n",
    "            concat = tf.concat([t1, t2], axis=axis)\n",
    "        if self.framework == \"np\":\n",
    "            concat = np.concatenate([t1, t2], axis=axis)\n",
    "        return concat\n",
    "    \n",
    "    def gather_pre_entities(\n",
    "        self,\n",
    "        sentence: str,\n",
    "        input_ids: np.ndarray,\n",
    "        scores: np.ndarray,\n",
    "        offset_mapping: Optional[List[Tuple[int, int]]],\n",
    "        special_tokens_mask: np.ndarray,\n",
    "        aggregation_strategy: AggregationStrategy,\n",
    "    ) -> List[dict]:\n",
    "        \"\"\"Fuse various numpy arrays into dicts with all the information needed for aggregation\"\"\"\n",
    "        pre_entities = []\n",
    "        for idx, token_scores in enumerate(scores):\n",
    "            # Filter special_tokens, they should only occur\n",
    "            # at the sentence boundaries since we're not encoding pairs of\n",
    "            # sentences so we don't have to keep track of those.\n",
    "            if special_tokens_mask[idx]:\n",
    "                continue\n",
    "\n",
    "            word = self.tokenizer.convert_ids_to_tokens(int(input_ids[idx]))\n",
    "            if offset_mapping is not None:\n",
    "                start_ind, end_ind = offset_mapping[idx]\n",
    "                if not isinstance(start_ind, int):\n",
    "                    if self.framework == \"pt\":\n",
    "                        start_ind = start_ind.item()\n",
    "                        end_ind = end_ind.item()\n",
    "                    else:\n",
    "                        start_ind = int(start_ind.numpy())\n",
    "                        end_ind = int(end_ind.numpy())\n",
    "                word_ref = sentence[start_ind:end_ind]\n",
    "                if getattr(self.tokenizer._tokenizer.model, \"continuing_subword_prefix\", None):\n",
    "                    # This is a BPE, word aware tokenizer, there is a correct way\n",
    "                    # to fuse tokens\n",
    "                    is_subword = len(word) != len(word_ref)\n",
    "                else:\n",
    "                    # This is a fallback heuristic. This will fail most likely on any kind of text + punctuation mixtures that will be considered \"words\". Non word aware models cannot do better than this unfortunately.\n",
    "                    if aggregation_strategy in {\n",
    "                        AggregationStrategy.FIRST,\n",
    "                        AggregationStrategy.AVERAGE,\n",
    "                        AggregationStrategy.MAX,\n",
    "                    }:\n",
    "                        warnings.warn(\"Tokenizer does not support real words, using fallback heuristic\", UserWarning)\n",
    "                    is_subword = start_ind > 0 and \" \" not in sentence[start_ind - 1 : start_ind + 1]\n",
    "\n",
    "                if int(input_ids[idx]) == self.tokenizer.unk_token_id:\n",
    "                    word = word_ref\n",
    "                    is_subword = False\n",
    "            else:\n",
    "                start_ind = None\n",
    "                end_ind = None\n",
    "                is_subword = False\n",
    "\n",
    "            pre_entity = {\n",
    "                \"word\": word,\n",
    "                \"scores\": token_scores,\n",
    "                \"start\": start_ind,\n",
    "                \"end\": end_ind,\n",
    "                \"index\": idx,\n",
    "                \"is_subword\": is_subword,\n",
    "            }\n",
    "            pre_entities.append(pre_entity)\n",
    "        return pre_entities\n",
    "\n",
    "    def aggregate(self, pre_entities: List[dict], aggregation_strategy: AggregationStrategy) -> List[dict]:\n",
    "        if aggregation_strategy in {AggregationStrategy.NONE, AggregationStrategy.SIMPLE}:\n",
    "            entities = []\n",
    "            for pre_entity in pre_entities:\n",
    "                entity_idx = pre_entity[\"scores\"].argmax()\n",
    "                score = pre_entity[\"scores\"][entity_idx]\n",
    "                entity = {\n",
    "                    \"entity\": self.model.config.id2label[entity_idx],\n",
    "                    \"score\": score,\n",
    "                    \"index\": pre_entity[\"index\"],\n",
    "                    \"word\": pre_entity[\"word\"],\n",
    "                    \"start\": pre_entity[\"start\"],\n",
    "                    \"end\": pre_entity[\"end\"],\n",
    "                }\n",
    "                entities.append(entity)\n",
    "        else:\n",
    "            entities = self.aggregate_words(pre_entities, aggregation_strategy)\n",
    "\n",
    "        if aggregation_strategy == AggregationStrategy.NONE:\n",
    "            return entities\n",
    "        return self.group_entities(entities)\n",
    "\n",
    "    def aggregate_word(self, entities: List[dict], aggregation_strategy: AggregationStrategy) -> dict:\n",
    "        word = self.tokenizer.convert_tokens_to_string([entity[\"word\"] for entity in entities])\n",
    "        if aggregation_strategy == AggregationStrategy.FIRST:\n",
    "            scores = entities[0][\"scores\"]\n",
    "            idx = scores.argmax()\n",
    "            score = scores[idx]\n",
    "            entity = self.model.config.id2label[idx]\n",
    "        elif aggregation_strategy == AggregationStrategy.MAX:\n",
    "            max_entity = max(entities, key=lambda entity: entity[\"scores\"].max())\n",
    "            scores = max_entity[\"scores\"]\n",
    "            idx = scores.argmax()\n",
    "            score = scores[idx]\n",
    "            entity = self.model.config.id2label[idx]\n",
    "        elif aggregation_strategy == AggregationStrategy.AVERAGE:\n",
    "            scores = np.stack([entity[\"scores\"] for entity in entities])\n",
    "            average_scores = np.nanmean(scores, axis=0)\n",
    "            entity_idx = average_scores.argmax()\n",
    "            entity = self.model.config.id2label[entity_idx]\n",
    "            score = average_scores[entity_idx]\n",
    "        else:\n",
    "            raise ValueError(\"Invalid aggregation_strategy\")\n",
    "        new_entity = {\n",
    "            \"entity\": entity,\n",
    "            \"score\": score,\n",
    "            \"word\": word,\n",
    "            \"start\": entities[0][\"start\"],\n",
    "            \"end\": entities[-1][\"end\"],\n",
    "        }\n",
    "        return new_entity\n",
    "\n",
    "    def aggregate_words(self, entities: List[dict], aggregation_strategy: AggregationStrategy) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Override tokens from a given word that disagree to force agreement on word boundaries.\n",
    "        Example: micro|soft| com|pany| B-ENT I-NAME I-ENT I-ENT will be rewritten with first strategy as microsoft|\n",
    "        company| B-ENT I-ENT\n",
    "        \"\"\"\n",
    "        if aggregation_strategy in {\n",
    "            AggregationStrategy.NONE,\n",
    "            AggregationStrategy.SIMPLE,\n",
    "        }:\n",
    "            raise ValueError(\"NONE and SIMPLE strategies are invalid for word aggregation\")\n",
    "\n",
    "        word_entities = []\n",
    "        word_group = None\n",
    "        for entity in entities:\n",
    "            if word_group is None:\n",
    "                word_group = [entity]\n",
    "            elif entity[\"is_subword\"]:\n",
    "                word_group.append(entity)\n",
    "            else:\n",
    "                word_entities.append(self.aggregate_word(word_group, aggregation_strategy))\n",
    "                word_group = [entity]\n",
    "        # Last item\n",
    "        word_entities.append(self.aggregate_word(word_group, aggregation_strategy))\n",
    "        return word_entities\n",
    "\n",
    "    def group_sub_entities(self, entities: List[dict]) -> dict:\n",
    "        \"\"\"\n",
    "        Group together the adjacent tokens with the same entity predicted.\n",
    "        Args:\n",
    "            entities (`dict`): The entities predicted by the pipeline.\n",
    "        \"\"\"\n",
    "        # Get the first entity in the entity group\n",
    "        entity = entities[0][\"entity\"].split(\"-\")[-1]\n",
    "        scores = np.nanmean([entity[\"score\"] for entity in entities])\n",
    "        tokens = [entity[\"word\"] for entity in entities]\n",
    "\n",
    "        entity_group = {\n",
    "            \"entity_group\": entity,\n",
    "            \"score\": np.mean(scores),\n",
    "            \"word\": self.tokenizer.convert_tokens_to_string(tokens),\n",
    "            \"start\": entities[0][\"start\"],\n",
    "            \"end\": entities[-1][\"end\"],\n",
    "        }\n",
    "        return entity_group\n",
    "\n",
    "    def get_tag(self, entity_name: str) -> Tuple[str, str]:\n",
    "        if entity_name.startswith(\"B-\"):\n",
    "            bi = \"B\"\n",
    "            tag = entity_name[2:]\n",
    "        elif entity_name.startswith(\"I-\"):\n",
    "            bi = \"I\"\n",
    "            tag = entity_name[2:]\n",
    "        else:\n",
    "            # It's not in B-, I- format\n",
    "            # Default to I- for continuation.\n",
    "            bi = \"I\"\n",
    "            tag = entity_name\n",
    "        return bi, tag\n",
    "\n",
    "    def group_entities(self, entities: List[dict]) -> List[dict]:\n",
    "        \"\"\"\n",
    "        Find and group together the adjacent tokens with the same entity predicted.\n",
    "        Args:\n",
    "            entities (`dict`): The entities predicted by the pipeline.\n",
    "        \"\"\"\n",
    "\n",
    "        entity_groups = []\n",
    "        entity_group_disagg = []\n",
    "\n",
    "        for entity in entities:\n",
    "            if not entity_group_disagg:\n",
    "                entity_group_disagg.append(entity)\n",
    "                continue\n",
    "\n",
    "            # If the current entity is similar and adjacent to the previous entity,\n",
    "            # append it to the disaggregated entity group\n",
    "            # The split is meant to account for the \"B\" and \"I\" prefixes\n",
    "            # Shouldn't merge if both entities are B-type\n",
    "            bi, tag = self.get_tag(entity[\"entity\"])\n",
    "            last_bi, last_tag = self.get_tag(entity_group_disagg[-1][\"entity\"])\n",
    "\n",
    "            if tag == last_tag and bi != \"B\":\n",
    "                # Modify subword type to be previous_type\n",
    "                entity_group_disagg.append(entity)\n",
    "            else:\n",
    "                # If the current entity is different from the previous entity\n",
    "                # aggregate the disaggregated entity group\n",
    "                entity_groups.append(self.group_sub_entities(entity_group_disagg))\n",
    "                entity_group_disagg = [entity]\n",
    "        if entity_group_disagg:\n",
    "            # it's the last entity, add it to the entity groups\n",
    "            entity_groups.append(self.group_sub_entities(entity_group_disagg))\n",
    "\n",
    "        return entity_groups\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6841a7d1",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[{'entity_group': 'O', 'score': 0.9999321, 'word': 'figure 2a.', 'start': 0, 'end': 10}, {'entity_group': 'CELL', 'score': 0.9697927, 'word': 'hek293t', 'start': 11, 'end': 18}, {'entity_group': 'O', 'score': 0.9916782, 'word': 'cells were transfected with', 'start': 19, 'end': 46}, {'entity_group': 'GENEPROD', 'score': 0.9749185, 'word': 'myc', 'start': 47, 'end': 50}, {'entity_group': 'O', 'score': 0.99988616, 'word': '-', 'start': 50, 'end': 51}, {'entity_group': 'GENEPROD', 'score': 0.9739129, 'word': 'foxp3', 'start': 51, 'end': 56}, {'entity_group': 'O', 'score': 0.9999181, 'word': 'and', 'start': 57, 'end': 60}, {'entity_group': 'GENEPROD', 'score': 0.97236145, 'word': 'flag', 'start': 61, 'end': 65}, {'entity_group': 'O', 'score': 0.99988174, 'word': '-', 'start': 65, 'end': 66}, {'entity_group': 'GENEPROD', 'score': 0.9444879, 'word': 'usp44', 'start': 66, 'end': 71}, {'entity_group': 'O', 'score': 0.99732995, 'word': 'encoding expression constructs using', 'start': 72, 'end': 108}, {'entity_group': 'SMALL_MOLECULE', 'score': 0.9096496, 'word': 'polyethylenimine', 'start': 109, 'end': 125}, {'entity_group': 'O', 'score': 0.9999284, 'word': '. 48hrs post - transfection, cells were harvested, lysed, and anti -', 'start': 125, 'end': 190}, {'entity_group': 'GENEPROD', 'score': 0.9734517, 'word': 'flag', 'start': 190, 'end': 194}, {'entity_group': 'O', 'score': 0.9999253, 'word': 'or anti -', 'start': 195, 'end': 203}, {'entity_group': 'GENEPROD', 'score': 0.9762305, 'word': 'myc', 'start': 203, 'end': 206}, {'entity_group': 'O', 'score': 0.9998, 'word': 'antibody coated beads were used to', 'start': 207, 'end': 241}, {'entity_group': 'EXP_ASSAY', 'score': 0.85167843, 'word': 'immunoprecipitate', 'start': 242, 'end': 259}, {'entity_group': 'O', 'score': 0.98904926, 'word': 'the given labeled protein along with its binding partner.', 'start': 260, 'end': 317}, {'entity_group': 'EXP_ASSAY', 'score': 0.91382194, 'word': 'co - ip', 'start': 318, 'end': 323}, {'entity_group': 'O', 'score': 0.9980168, 'word': \"' ed proteins were subjected to\", 'start': 323, 'end': 354}, {'entity_group': 'EXP_ASSAY', 'score': 0.96977097, 'word': 'sds page', 'start': 355, 'end': 363}, {'entity_group': 'O', 'score': 0.9998154, 'word': 'followed by', 'start': 364, 'end': 375}, {'entity_group': 'EXP_ASSAY', 'score': 0.9499349, 'word': 'immunoblot', 'start': 376, 'end': 386}, {'entity_group': 'O', 'score': 0.97016174, 'word': 'analysis. antibodies recognizing', 'start': 387, 'end': 419}, {'entity_group': 'GENEPROD', 'score': 0.9735077, 'word': 'flag', 'start': 420, 'end': 424}, {'entity_group': 'O', 'score': 0.99992085, 'word': 'or', 'start': 425, 'end': 427}, {'entity_group': 'GENEPROD', 'score': 0.9763381, 'word': 'myc', 'start': 428, 'end': 431}, {'entity_group': 'O', 'score': 0.9999172, 'word': 'tags were used to probe for', 'start': 432, 'end': 459}, {'entity_group': 'GENEPROD', 'score': 0.9424182, 'word': 'usp44', 'start': 460, 'end': 465}, {'entity_group': 'O', 'score': 0.9999293, 'word': 'and', 'start': 466, 'end': 469}, {'entity_group': 'GENEPROD', 'score': 0.97232336, 'word': 'foxp3', 'start': 470, 'end': 475}, {'entity_group': 'O', 'score': 0.99982876, 'word': ', respectively. b. endogenous', 'start': 475, 'end': 504}, {'entity_group': 'EXP_ASSAY', 'score': 0.9235905, 'word': 'co - ip', 'start': 505, 'end': 510}, {'entity_group': 'O', 'score': 0.99991643, 'word': 'of', 'start': 511, 'end': 513}, {'entity_group': 'GENEPROD', 'score': 0.94051975, 'word': 'usp44', 'start': 514, 'end': 519}, {'entity_group': 'O', 'score': 0.99991405, 'word': 'and', 'start': 520, 'end': 523}, {'entity_group': 'GENEPROD', 'score': 0.9730732, 'word': 'foxp3', 'start': 524, 'end': 529}, {'entity_group': 'O', 'score': 0.999931, 'word': 'in', 'start': 530, 'end': 532}, {'entity_group': 'ORGANISM', 'score': 0.85359573, 'word': 'murine', 'start': 533, 'end': 539}, {'entity_group': 'CELL', 'score': 0.79451394, 'word': 'itregs', 'start': 540, 'end': 546}, {'entity_group': 'O', 'score': 0.9999293, 'word': '.', 'start': 546, 'end': 547}, {'entity_group': 'CELL', 'score': 0.7646559, 'word': 'itregs', 'start': 548, 'end': 554}, {'entity_group': 'O', 'score': 0.9523152, 'word': 'were generated as in fig. 1 from naive', 'start': 555, 'end': 593}, {'entity_group': 'CELL', 'score': 0.80001426, 'word': 'cd4 + t cells', 'start': 594, 'end': 605}, {'entity_group': 'EXP_ASSAY', 'score': 0.94524765, 'word': 'facs', 'start': 606, 'end': 610}, {'entity_group': 'O', 'score': 0.9997832, 'word': 'isolated from pooled suspensions of the', 'start': 611, 'end': 650}, {'entity_group': 'TISSUE', 'score': 0.9555095, 'word': 'lymph node', 'start': 651, 'end': 661}, {'entity_group': 'O', 'score': 0.99971575, 'word': 'and', 'start': 662, 'end': 665}, {'entity_group': 'TISSUE', 'score': 0.9748618, 'word': 'spleen', 'start': 666, 'end': 672}, {'entity_group': 'O', 'score': 0.9554667, 'word': 'cells of wild type c57bl / 6', 'start': 673, 'end': 699}, {'entity_group': 'ORGANISM', 'score': 0.84294766, 'word': 'mice', 'start': 700, 'end': 704}, {'entity_group': 'O', 'score': 0.999941, 'word': '( n = 2 - 3 / experiment ).', 'start': 705, 'end': 728}, {'entity_group': 'CELL', 'score': 0.7307768, 'word': 'itregs', 'start': 729, 'end': 735}, {'entity_group': 'O', 'score': 0.99982387, 'word': 'were lysed and key proteins were', 'start': 736, 'end': 768}, {'entity_group': 'EXP_ASSAY', 'score': 0.9327851, 'word': 'immunoprecipitated', 'start': 769, 'end': 787}, {'entity_group': 'O', 'score': 0.9999362, 'word': 'using either anti -', 'start': 788, 'end': 806}, {'entity_group': 'GENEPROD', 'score': 0.9448201, 'word': 'usp44', 'start': 806, 'end': 811}, {'entity_group': 'O', 'score': 0.9999389, 'word': '( right panel ) or anti -', 'start': 812, 'end': 834}, {'entity_group': 'GENEPROD', 'score': 0.9728305, 'word': 'foxp3', 'start': 834, 'end': 839}, {'entity_group': 'O', 'score': 0.99854034, 'word': '( left panel ) antibody. proteins', 'start': 840, 'end': 871}, {'entity_group': 'EXP_ASSAY', 'score': 0.65205085, 'word': 'pulled - down', 'start': 872, 'end': 883}, {'entity_group': 'O', 'score': 0.99993867, 'word': 'in this experiment were then resolved and analyzed by', 'start': 884, 'end': 937}, {'entity_group': 'EXP_ASSAY', 'score': 0.9449408, 'word': 'immunoblot', 'start': 938, 'end': 948}, {'entity_group': 'O', 'score': 0.99993724, 'word': 'using anti -', 'start': 949, 'end': 960}, {'entity_group': 'GENEPROD', 'score': 0.97509015, 'word': 'foxp3', 'start': 960, 'end': 965}, {'entity_group': 'O', 'score': 0.9999315, 'word': 'or anti -', 'start': 966, 'end': 974}, {'entity_group': 'GENEPROD', 'score': 0.9489068, 'word': 'usp44', 'start': 974, 'end': 979}, {'entity_group': 'O', 'score': 0.9997362, 'word': 'antibodies. c. endogenous', 'start': 980, 'end': 1005}, {'entity_group': 'EXP_ASSAY', 'score': 0.91671085, 'word': 'co - ip', 'start': 1006, 'end': 1011}, {'entity_group': 'O', 'score': 0.9999044, 'word': 'of', 'start': 1012, 'end': 1014}, {'entity_group': 'GENEPROD', 'score': 0.94218355, 'word': 'usp44', 'start': 1015, 'end': 1020}, {'entity_group': 'O', 'score': 0.9999145, 'word': 'and', 'start': 1021, 'end': 1024}, {'entity_group': 'GENEPROD', 'score': 0.97386926, 'word': 'foxp3', 'start': 1025, 'end': 1030}, {'entity_group': 'O', 'score': 0.99993193, 'word': 'in', 'start': 1031, 'end': 1033}, {'entity_group': 'ORGANISM', 'score': 0.8716879, 'word': 'murine', 'start': 1034, 'end': 1040}, {'entity_group': 'CELL', 'score': 0.87000436, 'word': 'ntregs', 'start': 1041, 'end': 1047}, {'entity_group': 'O', 'score': 0.9999336, 'word': '.', 'start': 1047, 'end': 1048}, {'entity_group': 'CELL', 'score': 0.88294345, 'word': 'ntregs', 'start': 1049, 'end': 1055}, {'entity_group': 'O', 'score': 0.9998116, 'word': '(', 'start': 1056, 'end': 1057}, {'entity_group': 'GENEPROD', 'score': 0.95699954, 'word': 'cd4', 'start': 1057, 'end': 1060}, {'entity_group': 'O', 'score': 0.76367974, 'word': '+', 'start': 1060, 'end': 1061}, {'entity_group': 'GENEPROD', 'score': 0.8986723, 'word': 'cd25high', 'start': 1061, 'end': 1069}, {'entity_group': 'O', 'score': 0.9994369, 'word': ') isolated by', 'start': 1069, 'end': 1082}, {'entity_group': 'EXP_ASSAY', 'score': 0.9581188, 'word': 'facs', 'start': 1083, 'end': 1087}, {'entity_group': 'O', 'score': 0.9998883, 'word': 'were activated by anti -', 'start': 1088, 'end': 1111}, {'entity_group': 'GENEPROD', 'score': 0.97740275, 'word': 'cd3', 'start': 1111, 'end': 1114}, {'entity_group': 'O', 'score': 0.9999277, 'word': 'and anti -', 'start': 1115, 'end': 1124}, {'entity_group': 'GENEPROD', 'score': 0.98043597, 'word': 'cd28', 'start': 1124, 'end': 1128}, {'entity_group': 'O', 'score': 0.99993974, 'word': '( 1 and 4 ug / ml, respectively ) overnight in the presence of', 'start': 1129, 'end': 1187}, {'entity_group': 'GENEPROD', 'score': 0.96194893, 'word': 'il - 2', 'start': 1188, 'end': 1192}, {'entity_group': 'O', 'score': 0.99986494, 'word': '( 100 u / ml ). the cells were lysed and proteins were', 'start': 1193, 'end': 1243}, {'entity_group': 'EXP_ASSAY', 'score': 0.9138452, 'word': 'immunoprecipitated', 'start': 1244, 'end': 1262}, {'entity_group': 'O', 'score': 0.99993694, 'word': 'using either anti -', 'start': 1263, 'end': 1281}, {'entity_group': 'GENEPROD', 'score': 0.97689724, 'word': 'foxp3', 'start': 1281, 'end': 1286}, {'entity_group': 'O', 'score': 0.99993956, 'word': '( left panel ) or anti -', 'start': 1287, 'end': 1308}, {'entity_group': 'GENEPROD', 'score': 0.9506428, 'word': 'usp44', 'start': 1308, 'end': 1313}, {'entity_group': 'O', 'score': 0.9976954, 'word': '( right panel ). proteins', 'start': 1314, 'end': 1337}, {'entity_group': 'EXP_ASSAY', 'score': 0.5626529, 'word': 'pulled down', 'start': 1338, 'end': 1349}, {'entity_group': 'O', 'score': 0.99661016, 'word': 'in this experiment were then resolved and identified with the indicated antibodies. d. naive', 'start': 1350, 'end': 1443}, {'entity_group': 'ORGANISM', 'score': 0.7337083, 'word': 'murine', 'start': 1444, 'end': 1450}, {'entity_group': 'CELL', 'score': 0.8416855, 'word': 'cd4 + t cells', 'start': 1451, 'end': 1462}, {'entity_group': 'O', 'score': 0.9999323, 'word': 'were isolated by', 'start': 1463, 'end': 1479}, {'entity_group': 'EXP_ASSAY', 'score': 0.9531496, 'word': 'facs', 'start': 1480, 'end': 1484}, {'entity_group': 'O', 'score': 0.999943, 'word': 'from', 'start': 1485, 'end': 1489}, {'entity_group': 'TISSUE', 'score': 0.9548194, 'word': 'lymph node', 'start': 1490, 'end': 1500}, {'entity_group': 'O', 'score': 0.9998031, 'word': 'and', 'start': 1501, 'end': 1504}, {'entity_group': 'TISSUE', 'score': 0.9722382, 'word': 'spleen', 'start': 1505, 'end': 1511}, {'entity_group': 'O', 'score': 0.9896552, 'word': 'cell suspension of', 'start': 1512, 'end': 1530}, {'entity_group': 'GENEPROD', 'score': 0.942637, 'word': 'usp44fl', 'start': 1531, 'end': 1538}, {'entity_group': 'O', 'score': 0.99984145, 'word': '/ fl', 'start': 1538, 'end': 1541}, {'entity_group': 'GENEPROD', 'score': 0.95258266, 'word': 'cd4cre', 'start': 1542, 'end': 1548}, {'entity_group': 'O', 'score': 0.99943703, 'word': '+', 'start': 1548, 'end': 1549}, {'entity_group': 'ORGANISM', 'score': 0.9582726, 'word': 'mice', 'start': 1550, 'end': 1554}, {'entity_group': 'O', 'score': 0.99766815, 'word': 'and that of their wild type littermates (', 'start': 1555, 'end': 1596}, {'entity_group': 'GENEPROD', 'score': 0.94260424, 'word': 'usp44fl', 'start': 1596, 'end': 1603}, {'entity_group': 'O', 'score': 0.9998187, 'word': '/ fl', 'start': 1603, 'end': 1606}, {'entity_group': 'GENEPROD', 'score': 0.9477131, 'word': 'cd4cre', 'start': 1607, 'end': 1613}, {'entity_group': 'O', 'score': 0.9996669, 'word': '-', 'start': 1613, 'end': 1614}, {'entity_group': 'ORGANISM', 'score': 0.9513346, 'word': 'mice', 'start': 1614, 'end': 1618}, {'entity_group': 'O', 'score': 0.99994135, 'word': '; n = 2 - 3 / group / experiment ).', 'start': 1618, 'end': 1651}, {'entity_group': 'CELL', 'score': 0.75146365, 'word': 'itreg', 'start': 1652, 'end': 1657}, {'entity_group': 'O', 'score': 0.98527944, 'word': 'cells were generated from these', 'start': 1658, 'end': 1689}, {'entity_group': 'ORGANISM', 'score': 0.92907244, 'word': 'mice', 'start': 1690, 'end': 1694}, {'entity_group': 'O', 'score': 0.9987016, 'word': 'as described for fig. 1 before incubation on a microscope slide pre - coated with', 'start': 1695, 'end': 1774}, {'entity_group': 'SMALL_MOLECULE', 'score': 0.9226137, 'word': 'poly - l lysine', 'start': 1775, 'end': 1788}, {'entity_group': 'O', 'score': 0.9978737, 'word': 'for 1h. adhered cells were then fixed by', 'start': 1789, 'end': 1829}, {'entity_group': 'SMALL_MOLECULE', 'score': 0.9200406, 'word': 'pfa', 'start': 1830, 'end': 1833}, {'entity_group': 'O', 'score': 0.9999162, 'word': 'for 0. 5 followed by blocking with 1 %', 'start': 1834, 'end': 1870}, {'entity_group': 'GENEPROD', 'score': 0.74593717, 'word': 'bsa', 'start': 1871, 'end': 1874}, {'entity_group': 'O', 'score': 0.99993914, 'word': 'for 1h, then incubation with the specified antibodies. representative', 'start': 1875, 'end': 1944}, {'entity_group': 'EXP_ASSAY', 'score': 0.96029603, 'word': 'confocal microscopy', 'start': 1945, 'end': 1964}, {'entity_group': 'O', 'score': 0.9771433, 'word': 'images ( 40x ) were visualized for endogenous', 'start': 1965, 'end': 2008}, {'entity_group': 'GENEPROD', 'score': 0.9436666, 'word': 'usp44', 'start': 2009, 'end': 2014}, {'entity_group': 'O', 'score': 0.9999389, 'word': '( red ) and', 'start': 2015, 'end': 2024}, {'entity_group': 'GENEPROD', 'score': 0.9735299, 'word': 'foxp3', 'start': 2025, 'end': 2030}, {'entity_group': 'O', 'score': 0.9999108, 'word': 'baxter et al ( ).', 'start': 2031, 'end': 2047}, {'entity_group': 'SMALL_MOLECULE', 'score': 0.5049016, 'word': 'dapi', 'start': 2048, 'end': 2052}, {'entity_group': 'O', 'score': 0.99958265, 'word': 'was used to visualize cell', 'start': 2053, 'end': 2079}, {'entity_group': 'SUBCELLULAR', 'score': 0.97036606, 'word': 'nuclei', 'start': 2080, 'end': 2086}, {'entity_group': 'O', 'score': 0.999945, 'word': '( blue ) ; scale bar 50μm.', 'start': 2087, 'end': 2110}]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[{'entity_group': 'CELL',\n",
       "  'score': 0.9697927,\n",
       "  'word': 'hek293t',\n",
       "  'start': 11,\n",
       "  'end': 18},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9749185,\n",
       "  'word': 'myc',\n",
       "  'start': 47,\n",
       "  'end': 50},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9739129,\n",
       "  'word': 'foxp3',\n",
       "  'start': 51,\n",
       "  'end': 56},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.97236145,\n",
       "  'word': 'flag',\n",
       "  'start': 61,\n",
       "  'end': 65},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9444879,\n",
       "  'word': 'usp44',\n",
       "  'start': 66,\n",
       "  'end': 71},\n",
       " {'entity_group': 'SMALL_MOLECULE',\n",
       "  'score': 0.9096496,\n",
       "  'word': 'polyethylenimine',\n",
       "  'start': 109,\n",
       "  'end': 125},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9734517,\n",
       "  'word': 'flag',\n",
       "  'start': 190,\n",
       "  'end': 194},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9762305,\n",
       "  'word': 'myc',\n",
       "  'start': 203,\n",
       "  'end': 206},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.85167843,\n",
       "  'word': 'immunoprecipitate',\n",
       "  'start': 242,\n",
       "  'end': 259},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.91382194,\n",
       "  'word': 'co - ip',\n",
       "  'start': 318,\n",
       "  'end': 323},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.96977097,\n",
       "  'word': 'sds page',\n",
       "  'start': 355,\n",
       "  'end': 363},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.9499349,\n",
       "  'word': 'immunoblot',\n",
       "  'start': 376,\n",
       "  'end': 386},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9735077,\n",
       "  'word': 'flag',\n",
       "  'start': 420,\n",
       "  'end': 424},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9763381,\n",
       "  'word': 'myc',\n",
       "  'start': 428,\n",
       "  'end': 431},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9424182,\n",
       "  'word': 'usp44',\n",
       "  'start': 460,\n",
       "  'end': 465},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.97232336,\n",
       "  'word': 'foxp3',\n",
       "  'start': 470,\n",
       "  'end': 475},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.9235905,\n",
       "  'word': 'co - ip',\n",
       "  'start': 505,\n",
       "  'end': 510},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.94051975,\n",
       "  'word': 'usp44',\n",
       "  'start': 514,\n",
       "  'end': 519},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9730732,\n",
       "  'word': 'foxp3',\n",
       "  'start': 524,\n",
       "  'end': 529},\n",
       " {'entity_group': 'ORGANISM',\n",
       "  'score': 0.85359573,\n",
       "  'word': 'murine',\n",
       "  'start': 533,\n",
       "  'end': 539},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.79451394,\n",
       "  'word': 'itregs',\n",
       "  'start': 540,\n",
       "  'end': 546},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.7646559,\n",
       "  'word': 'itregs',\n",
       "  'start': 548,\n",
       "  'end': 554},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.80001426,\n",
       "  'word': 'cd4 + t cells',\n",
       "  'start': 594,\n",
       "  'end': 605},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.94524765,\n",
       "  'word': 'facs',\n",
       "  'start': 606,\n",
       "  'end': 610},\n",
       " {'entity_group': 'TISSUE',\n",
       "  'score': 0.9555095,\n",
       "  'word': 'lymph node',\n",
       "  'start': 651,\n",
       "  'end': 661},\n",
       " {'entity_group': 'TISSUE',\n",
       "  'score': 0.9748618,\n",
       "  'word': 'spleen',\n",
       "  'start': 666,\n",
       "  'end': 672},\n",
       " {'entity_group': 'ORGANISM',\n",
       "  'score': 0.84294766,\n",
       "  'word': 'mice',\n",
       "  'start': 700,\n",
       "  'end': 704},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.7307768,\n",
       "  'word': 'itregs',\n",
       "  'start': 729,\n",
       "  'end': 735},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.9327851,\n",
       "  'word': 'immunoprecipitated',\n",
       "  'start': 769,\n",
       "  'end': 787},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9448201,\n",
       "  'word': 'usp44',\n",
       "  'start': 806,\n",
       "  'end': 811},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9728305,\n",
       "  'word': 'foxp3',\n",
       "  'start': 834,\n",
       "  'end': 839},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.65205085,\n",
       "  'word': 'pulled - down',\n",
       "  'start': 872,\n",
       "  'end': 883},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.9449408,\n",
       "  'word': 'immunoblot',\n",
       "  'start': 938,\n",
       "  'end': 948},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.97509015,\n",
       "  'word': 'foxp3',\n",
       "  'start': 960,\n",
       "  'end': 965},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9489068,\n",
       "  'word': 'usp44',\n",
       "  'start': 974,\n",
       "  'end': 979},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.91671085,\n",
       "  'word': 'co - ip',\n",
       "  'start': 1006,\n",
       "  'end': 1011},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.94218355,\n",
       "  'word': 'usp44',\n",
       "  'start': 1015,\n",
       "  'end': 1020},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.97386926,\n",
       "  'word': 'foxp3',\n",
       "  'start': 1025,\n",
       "  'end': 1030},\n",
       " {'entity_group': 'ORGANISM',\n",
       "  'score': 0.8716879,\n",
       "  'word': 'murine',\n",
       "  'start': 1034,\n",
       "  'end': 1040},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.87000436,\n",
       "  'word': 'ntregs',\n",
       "  'start': 1041,\n",
       "  'end': 1047},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.88294345,\n",
       "  'word': 'ntregs',\n",
       "  'start': 1049,\n",
       "  'end': 1055},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.95699954,\n",
       "  'word': 'cd4',\n",
       "  'start': 1057,\n",
       "  'end': 1060},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.8986723,\n",
       "  'word': 'cd25high',\n",
       "  'start': 1061,\n",
       "  'end': 1069},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.9581188,\n",
       "  'word': 'facs',\n",
       "  'start': 1083,\n",
       "  'end': 1087},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.97740275,\n",
       "  'word': 'cd3',\n",
       "  'start': 1111,\n",
       "  'end': 1114},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.98043597,\n",
       "  'word': 'cd28',\n",
       "  'start': 1124,\n",
       "  'end': 1128},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.96194893,\n",
       "  'word': 'il - 2',\n",
       "  'start': 1188,\n",
       "  'end': 1192},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.9138452,\n",
       "  'word': 'immunoprecipitated',\n",
       "  'start': 1244,\n",
       "  'end': 1262},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.97689724,\n",
       "  'word': 'foxp3',\n",
       "  'start': 1281,\n",
       "  'end': 1286},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9506428,\n",
       "  'word': 'usp44',\n",
       "  'start': 1308,\n",
       "  'end': 1313},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.5626529,\n",
       "  'word': 'pulled down',\n",
       "  'start': 1338,\n",
       "  'end': 1349},\n",
       " {'entity_group': 'ORGANISM',\n",
       "  'score': 0.7337083,\n",
       "  'word': 'murine',\n",
       "  'start': 1444,\n",
       "  'end': 1450},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.8416855,\n",
       "  'word': 'cd4 + t cells',\n",
       "  'start': 1451,\n",
       "  'end': 1462},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.9531496,\n",
       "  'word': 'facs',\n",
       "  'start': 1480,\n",
       "  'end': 1484},\n",
       " {'entity_group': 'TISSUE',\n",
       "  'score': 0.9548194,\n",
       "  'word': 'lymph node',\n",
       "  'start': 1490,\n",
       "  'end': 1500},\n",
       " {'entity_group': 'TISSUE',\n",
       "  'score': 0.9722382,\n",
       "  'word': 'spleen',\n",
       "  'start': 1505,\n",
       "  'end': 1511},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.942637,\n",
       "  'word': 'usp44fl',\n",
       "  'start': 1531,\n",
       "  'end': 1538},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.95258266,\n",
       "  'word': 'cd4cre',\n",
       "  'start': 1542,\n",
       "  'end': 1548},\n",
       " {'entity_group': 'ORGANISM',\n",
       "  'score': 0.9582726,\n",
       "  'word': 'mice',\n",
       "  'start': 1550,\n",
       "  'end': 1554},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.94260424,\n",
       "  'word': 'usp44fl',\n",
       "  'start': 1596,\n",
       "  'end': 1603},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9477131,\n",
       "  'word': 'cd4cre',\n",
       "  'start': 1607,\n",
       "  'end': 1613},\n",
       " {'entity_group': 'ORGANISM',\n",
       "  'score': 0.9513346,\n",
       "  'word': 'mice',\n",
       "  'start': 1614,\n",
       "  'end': 1618},\n",
       " {'entity_group': 'CELL',\n",
       "  'score': 0.75146365,\n",
       "  'word': 'itreg',\n",
       "  'start': 1652,\n",
       "  'end': 1657},\n",
       " {'entity_group': 'ORGANISM',\n",
       "  'score': 0.92907244,\n",
       "  'word': 'mice',\n",
       "  'start': 1690,\n",
       "  'end': 1694},\n",
       " {'entity_group': 'SMALL_MOLECULE',\n",
       "  'score': 0.9226137,\n",
       "  'word': 'poly - l lysine',\n",
       "  'start': 1775,\n",
       "  'end': 1788},\n",
       " {'entity_group': 'SMALL_MOLECULE',\n",
       "  'score': 0.9200406,\n",
       "  'word': 'pfa',\n",
       "  'start': 1830,\n",
       "  'end': 1833},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.74593717,\n",
       "  'word': 'bsa',\n",
       "  'start': 1871,\n",
       "  'end': 1874},\n",
       " {'entity_group': 'EXP_ASSAY',\n",
       "  'score': 0.96029603,\n",
       "  'word': 'confocal microscopy',\n",
       "  'start': 1945,\n",
       "  'end': 1964},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9436666,\n",
       "  'word': 'usp44',\n",
       "  'start': 2009,\n",
       "  'end': 2014},\n",
       " {'entity_group': 'GENEPROD',\n",
       "  'score': 0.9735299,\n",
       "  'word': 'foxp3',\n",
       "  'start': 2025,\n",
       "  'end': 2030},\n",
       " {'entity_group': 'SMALL_MOLECULE',\n",
       "  'score': 0.5049016,\n",
       "  'word': 'dapi',\n",
       "  'start': 2048,\n",
       "  'end': 2052},\n",
       " {'entity_group': 'SUBCELLULAR',\n",
       "  'score': 0.97036606,\n",
       "  'word': 'nuclei',\n",
       "  'start': 2080,\n",
       "  'end': 2086}]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SENTENCE = \"\"\"Figure 2A. HEK293T cells were transfected with MYC-FOXP3 and FLAG-USP44 encoding expression constructs using Polyethylenimine. 48hrs post-transfection, cells were harvested, lysed, and anti-FLAG or anti-MYC antibody coated beads were used to immunoprecipitate the given labeled protein along with its binding partner. Co-IP' ed proteins were subjected to SDS PAGE followed by immunoblot analysis. Antibodies recognizing FLAG or MYC tags were used to probe for USP44 and FOXP3, respectively. B. Endogenous co-IP of USP44 and FOXP3 in murine iTregs. iTregs were generated as in Fig. 1 from naïve CD4+T cells FACS isolated from pooled suspensions of the lymph node and spleen cells of wild type C57BL/6 mice (n = 2-3 / experiment). iTregs were lysed and key proteins were immunoprecipitated using either anti-USP44 (right panel) or anti-FOXP3 (left panel) antibody. Proteins pulled-down in this experiment were then resolved and analyzed by immunoblot using anti-FOXP3 or anti-USP44 antibodies. C. Endogenous co-IP of USP44 and FOXP3 in murine nTregs. nTregs (CD4+CD25high) isolated by FACS were activated by anti-CD3 and anti-CD28 (1 and 4 ug/ml, respectively) overnight in the presence of IL-2 (100 U/ml). The cells were lysed and proteins were immunoprecipitated using either anti-Foxp3 (left panel) or anti-Usp44 (right panel). Proteins pulled down in this experiment were then resolved and identified with the indicated antibodies. D . Naïve murine CD4+T cells were isolated by FACS from lymph node and spleen cell suspension of USP44fl/fl CD4Cre+ mice and that of their wild type littermates (USP44fl/fl CD4Cre-mice; n = 2-3 / group / experiment) . iTreg cells were generated from these mice as described for Fig. 1 before incubation on a microscope slide pre-coated with poly-L lysine for 1h. Adhered cells were then fixed by PFA for 0.5 followed by blocking with 1% BSA for 1h, then incubation with the specified antibodies. Representative confocal microscopy images (40X) were visualized for endogenous USP44 (red) and FOXP3 Baxter et al (). DAPI was used to visualize cell nuclei (blue); scale bar 50μm.\"\"\"\n",
    "model = AutoModelForTokenClassification.from_pretrained(\"EMBO/sd-ner-v2\")\n",
    "pipe = LongTextTokenClassificationPipeline(task=\"token-classification\", \n",
    "                     model=model, \n",
    "                     tokenizer=tokenizer,\n",
    "                     device=0,\n",
    "                     aggregation_strategy=\"simple\")\n",
    "\n",
    "\n",
    "outputs = pipe(SENTENCE, stride=50)\n",
    "outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "014cb8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (982 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "ename": "KeyError",
     "evalue": "'offset_mapping'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_446/1612205117.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtokenizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mSENTENCE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"offset_mapping\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, item)\u001b[0m\n\u001b[1;32m    234\u001b[0m         \"\"\"\n\u001b[1;32m    235\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 236\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    237\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    238\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_encodings\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'offset_mapping'"
     ]
    }
   ],
   "source": [
    "len(tokenizer(SENTENCE)[\"offset_mapping\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "e998da06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': [[2, 2389, 21011, 3], [2, 2702, 21011, 3]], 'token_type_ids': [[0, 0, 0, 0], [0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1], [1, 1, 1, 1]], 'special_tokens_mask': [[1, 0, 0, 1], [1, 0, 0, 1]]}"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer([\"First sentence\", \"second sentence\"], return_special_tokens_mask=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "24db4e9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 512, 3])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1][\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "0a90d95f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 62, 3])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2][\"logits\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "14cc580b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.3776, -3.5248, -5.2105]), tensor(2181))"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[0][\"logits\"][0,510,:], outputs[0][\"input_ids\"][0,510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "785886a6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.5788, -4.2457, -4.9862]), tensor(2181))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1][\"logits\"][0,50,:], outputs[1][\"input_ids\"][0,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ea326345",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 7.9096, -2.7037, -5.1575]), tensor(1816))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[1][\"logits\"][0,510,:], outputs[1][\"input_ids\"][0,510]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d76c41f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([ 8.0859, -2.9973, -4.8152]), tensor(1816))"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs[2][\"logits\"][0,50,:], outputs[2][\"input_ids\"][0,50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "67bc34af",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,2]]\n",
    "b = [[3,4]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "64178c3c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(1, 4), dtype=int32, numpy=array([[1, 2, 3, 4]], dtype=int32)>"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.concat([tf.convert_to_tensor(a), tf.convert_to_tensor(b)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "1f6f735f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.concat([torch.tensor(a), torch.tensor(b)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "2a404804",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1, 2, 3, 4]])"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.concatenate([np.array(a), np.array(b)], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f437ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c6a8b24d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(True, True, False)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "offset_mapping = [[(0, 1), (1, 2)], [(0, 1), (1, 2)]]\n",
    "isinstance(offset_mapping[0], list), len(offset_mapping[0]) > 1, not isinstance(offset_mapping[0][0], tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "c3d6db96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(offset_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "44127b66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "not isinstance(offset_mapping[0][0], tuple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42067e9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
