{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b98ec562",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "883e6a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b546cea5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b0dc05b",
   "metadata": {},
   "source": [
    "In `config`:\n",
    "\n",
    "    config = Config(\n",
    "        max_length = 64  # in tokens\n",
    "        from_pretrained = \"facebook/bart-base\"\n",
    "        model_type = \"VAE\"\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e49ac579",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1de2fa8c402e43e09d2b3bb285f9fafb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.68k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a046c4964bcc47fd988cd2330e1a623f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/878k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bb2d32defa974479ab3ba2ec248515cb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/446k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2c4b740737134ad783e3e4cd6bfd3b3e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.29M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from smtag.config import config\n",
    "assert config.max_length==64\n",
    "config.from_pretrained=='facebook/bart-base'\n",
    "config.model_type=='VAE'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9f4bca7f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "660f4f76",
   "metadata": {},
   "source": [
    "## Extracting examples for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "035a6b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.extract import ExtractorXML"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf322783",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eval  test  train\r\n"
     ]
    }
   ],
   "source": [
    "! dir /data/xml/oapmc_articles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d0e0972c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/text/oapmc_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0d010582",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"/data/xml/oapmc_articles\"\n",
    "text_examples = \"/data/text/oapmc_title\"\n",
    "xpath = \".//article-meta/title-group/article-title\"\n",
    "sentence_level = False\n",
    "keep_xml = False\n",
    "inclusion_probability = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "5a814341",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/text/oapmc_title created\n"
     ]
    }
   ],
   "source": [
    "extractor_lm = ExtractorXML(\n",
    "    corpus,\n",
    "    destination_dir=text_examples,\n",
    "    sentence_level=sentence_level,\n",
    "    xpath=xpath,\n",
    "    keep_xml=keep_xml,\n",
    "    inclusion_probability=inclusion_probability\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c8ad33f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3223/3223 [1:31:53<00:00,  1.71s/it]\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.68s/it]\n",
      "100%|██████████| 10/10 [00:16<00:00,  1.67s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/data/text/oapmc_title/train.txt'): 967335,\n",
       " PosixPath('/data/text/oapmc_title/eval.txt'): 2970,\n",
       " PosixPath('/data/text/oapmc_title/test.txt'): 3004}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_lm.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7af205c1",
   "metadata": {},
   "source": [
    "#### same via CLI:\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/emboj_all /data/text/emboj_twin --xpath \".//article-meta/title-group/article-title\" \".//abstract\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97d46fec",
   "metadata": {},
   "source": [
    "## Preparing tokenized dataset for LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "55adc4c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.dataprep import PreparatorLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "485cbe1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_examples = \"/data/json/oapmc_title\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "8495693e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -fr /data/json/oapmc_title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8325107a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/json/oapmc_title created\n"
     ]
    }
   ],
   "source": [
    "prep_lm = PreparatorLM(\n",
    "    text_examples,\n",
    "    tokenized_examples,\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5122d4b5",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 967335/967335 [22:17<00:00, 723.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 35 (min=16, max=64) tokens\n",
      "longest example: <s>Efficiency and Tolerability of Induction and Consolidation Therapy with Arsenic Trioxide/Bortezomib/Ascorbic Acid/Dexamethasone (ABCD) Regimen Compared to Bortezomib/Dexamethasone (BD) Regimen in</s>\n",
      "shortest example: <s>Data on entrepreneurship education and entrepreneurial performance of aspiring entrepreneurs in selected Nigerian universities</s>\n",
      "Preparing: eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2970/2970 [00:02<00:00, 1009.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 35 (min=18, max=64) tokens\n",
      "longest example: <s>Characterization of an Indole-3-Acetamide Hydrolase from Alcaligenes faecalis subsp. parafaecalis and Its Application in Efficient Preparation of Both Enantiomers of Chiral Building Block 2,3-Dihydro-1,4-Benz</s>\n",
      "shortest example: <s>A bilateral tumor model identifies transcriptional programs associated with patient response to immune checkpoint blockade</s>\n",
      "Preparing: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3004/3004 [00:04<00:00, 747.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 35 (min=18, max=64) tokens\n",
      "longest example: <s>Comparison of Inappropriate Shocks and Other Health Outcomes Between Single- and Dual-Chamber Implantable Cardioverter-Defibrillators for Primary Prevention of Sudden Cardiac Death: Results From the Cardiovascular Research Network Longitudinal Study of Implantable Cardioverter-Def</s>\n",
      "shortest example: <s>Primary care provider perceptions of intake transition records and shared care with outpatient cardiac rehabilitation programs</s>\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "prep_lm.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f87695c7",
   "metadata": {},
   "source": [
    "same vie CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.lm.dataprep /data/text/mini /data/json/mini\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa53dfa7",
   "metadata": {},
   "source": [
    "## Train LM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "603758ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.train.train_lm import (\n",
    "    train as train_lm,\n",
    "    TrainingArgumentsLM\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "91aa7272",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cache = True\n",
    "loader_path = \"./smtag/loader/loader_lm.py\"\n",
    "data_config_name = \"SEQ2SEQ\"\n",
    "tokenizer = config.tokenizer  # tokenizer has to be the same application-wide\n",
    "model_type = \"VAE\"\n",
    "from_pretrained = config.from_pretrained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f6d27bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.mask_token = '<mask>'  # why is this here? maybe because in case of character-level tokenizer\n",
    "# tokenizer.unk_token = '<unk>'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74ac0cb8",
   "metadata": {},
   "source": [
    "Model architecture parameters: \n",
    "\n",
    "```python\n",
    "model_config = VAEConfigLM(\n",
    "    freeze_pretrained=None,  # 'encoder' # 'both' # 'decoder' # None\n",
    "    hidden_features=256,\n",
    "    z_dim=96,\n",
    "    gamma=1E-1,  # weight of lm loss as compared to z_loss\n",
    "    sampling_iterations=200,\n",
    "    seq_length=config.max_length,\n",
    "    residuals=False,\n",
    "    latent_var_loss=\"kl\"  # \"kl\" or \"mmd\" or None\n",
    ")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d987c634",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsLM(output_dir='/lm_models', overwrite_output_dir=True, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=32, per_device_eval_batch_size=32, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=5e-05, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/lm_models/runs/May26_15-41-57_8021e3d0dc73', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=100, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=100, dataloader_num_workers=0, past_index=-1, run_name='/lm_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args_tokcl = TrainingArgumentsLM(\n",
    "    num_train_epochs = 1,\n",
    "    logging_steps = 100,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=32,\n",
    ")\n",
    "training_args_tokcl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ef60c95a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Using custom data configuration SEQ2SEQ-1ddd9282e7145ba8\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading datasets found in /data/json/oapmc_title.\n",
      "using ./smtag/loader/loader_lm.py as dataset loader.\n",
      "Downloading and preparing dataset bio_lang/SEQ2SEQ (download: Unknown size, generated: 268.49 MiB, post-processed: Unknown size, total: 268.49 MiB) to /cache/bio_lang/SEQ2SEQ-1ddd9282e7145ba8/0.0.1/ff9dbe678aba55520bef244a55868bd4acf85eb086ce21a8454da23294256c2e...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset bio_lang downloaded and prepared to /cache/bio_lang/SEQ2SEQ-1ddd9282e7145ba8/0.0.1/ff9dbe678aba55520bef244a55868bd4acf85eb086ce21a8454da23294256c2e. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ea5463472398459c8aa7803b5acf244e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 967335 examples.\n",
      "Evaluating on 2970 examples.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "da5495226546410096e3bb287941789f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/532M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training arguments:\n",
      "TrainingArgumentsLM(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=100,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=5e-05,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/runs/lm-SEQ2SEQ-2022-05-26T15-42-11.285743,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=100,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1,\n",
      "output_dir=/lm_models,\n",
      "overwrite_output_dir=True,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=32,\n",
      "per_device_train_batch_size=32,\n",
      "prediction_loss_only=True,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=False,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/lm_models,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running training *****\n",
      "  Num examples = 967335\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 32\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 128\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 7558\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA available: True\n",
      "Available devices  4\n",
      "Current cuda device  0\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "71ac7e7dc3ba464a818be036eca6683b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/7558 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='6626' max='7558' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [6626/7558 53:49 < 07:34, 2.05 it/s, Epoch 0.88/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "      <th>Supp Data Loss Z</th>\n",
       "      <th>Supp Data Loss Lm</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>45.427300</td>\n",
       "      <td>2.278832</td>\n",
       "      <td>1.455738</td>\n",
       "      <td>0.783757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>8.827800</td>\n",
       "      <td>1.624580</td>\n",
       "      <td>0.898766</td>\n",
       "      <td>0.701679</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>6.249000</td>\n",
       "      <td>1.200030</td>\n",
       "      <td>0.545309</td>\n",
       "      <td>0.640245</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>5.050500</td>\n",
       "      <td>1.034896</td>\n",
       "      <td>0.432444</td>\n",
       "      <td>0.591074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>4.208200</td>\n",
       "      <td>0.974537</td>\n",
       "      <td>0.413509</td>\n",
       "      <td>0.550343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>3.694500</td>\n",
       "      <td>0.985467</td>\n",
       "      <td>0.455868</td>\n",
       "      <td>0.517927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>700</td>\n",
       "      <td>3.208000</td>\n",
       "      <td>0.825795</td>\n",
       "      <td>0.324736</td>\n",
       "      <td>0.492802</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>800</td>\n",
       "      <td>2.779300</td>\n",
       "      <td>0.731545</td>\n",
       "      <td>0.249720</td>\n",
       "      <td>0.475507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>900</td>\n",
       "      <td>2.430500</td>\n",
       "      <td>0.713125</td>\n",
       "      <td>0.245874</td>\n",
       "      <td>0.461090</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1000</td>\n",
       "      <td>2.202200</td>\n",
       "      <td>0.673489</td>\n",
       "      <td>0.218760</td>\n",
       "      <td>0.449216</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1100</td>\n",
       "      <td>2.012700</td>\n",
       "      <td>0.629624</td>\n",
       "      <td>0.184997</td>\n",
       "      <td>0.440016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1200</td>\n",
       "      <td>1.857500</td>\n",
       "      <td>0.636507</td>\n",
       "      <td>0.199687</td>\n",
       "      <td>0.431746</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1300</td>\n",
       "      <td>1.691200</td>\n",
       "      <td>0.586281</td>\n",
       "      <td>0.157851</td>\n",
       "      <td>0.424540</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1400</td>\n",
       "      <td>1.502000</td>\n",
       "      <td>0.552354</td>\n",
       "      <td>0.130785</td>\n",
       "      <td>0.418383</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1500</td>\n",
       "      <td>1.381500</td>\n",
       "      <td>0.541374</td>\n",
       "      <td>0.125625</td>\n",
       "      <td>0.412681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1600</td>\n",
       "      <td>1.309500</td>\n",
       "      <td>0.508364</td>\n",
       "      <td>0.098680</td>\n",
       "      <td>0.407290</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1700</td>\n",
       "      <td>1.205100</td>\n",
       "      <td>0.508370</td>\n",
       "      <td>0.103163</td>\n",
       "      <td>0.402576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1800</td>\n",
       "      <td>1.149100</td>\n",
       "      <td>0.511812</td>\n",
       "      <td>0.110600</td>\n",
       "      <td>0.398396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1900</td>\n",
       "      <td>1.100900</td>\n",
       "      <td>0.488509</td>\n",
       "      <td>0.091444</td>\n",
       "      <td>0.394596</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2000</td>\n",
       "      <td>1.069500</td>\n",
       "      <td>0.483611</td>\n",
       "      <td>0.090119</td>\n",
       "      <td>0.391063</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2100</td>\n",
       "      <td>1.036000</td>\n",
       "      <td>0.456361</td>\n",
       "      <td>0.066664</td>\n",
       "      <td>0.387947</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2200</td>\n",
       "      <td>1.006200</td>\n",
       "      <td>0.463401</td>\n",
       "      <td>0.076177</td>\n",
       "      <td>0.385166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2300</td>\n",
       "      <td>0.980300</td>\n",
       "      <td>0.462400</td>\n",
       "      <td>0.077553</td>\n",
       "      <td>0.382697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2400</td>\n",
       "      <td>0.938700</td>\n",
       "      <td>0.447981</td>\n",
       "      <td>0.065739</td>\n",
       "      <td>0.380421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2500</td>\n",
       "      <td>0.913600</td>\n",
       "      <td>0.439919</td>\n",
       "      <td>0.060079</td>\n",
       "      <td>0.378174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2600</td>\n",
       "      <td>0.889100</td>\n",
       "      <td>0.444456</td>\n",
       "      <td>0.066342</td>\n",
       "      <td>0.376239</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2700</td>\n",
       "      <td>0.867700</td>\n",
       "      <td>0.431278</td>\n",
       "      <td>0.055310</td>\n",
       "      <td>0.374384</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2800</td>\n",
       "      <td>0.844900</td>\n",
       "      <td>0.419411</td>\n",
       "      <td>0.045451</td>\n",
       "      <td>0.372627</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2900</td>\n",
       "      <td>0.820600</td>\n",
       "      <td>0.418679</td>\n",
       "      <td>0.046062</td>\n",
       "      <td>0.371233</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3000</td>\n",
       "      <td>0.795900</td>\n",
       "      <td>0.413894</td>\n",
       "      <td>0.043387</td>\n",
       "      <td>0.369155</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3100</td>\n",
       "      <td>0.773800</td>\n",
       "      <td>0.405386</td>\n",
       "      <td>0.036354</td>\n",
       "      <td>0.367841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3200</td>\n",
       "      <td>0.753200</td>\n",
       "      <td>0.411249</td>\n",
       "      <td>0.043310</td>\n",
       "      <td>0.366621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3300</td>\n",
       "      <td>0.737000</td>\n",
       "      <td>0.406524</td>\n",
       "      <td>0.039946</td>\n",
       "      <td>0.365330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3400</td>\n",
       "      <td>0.721200</td>\n",
       "      <td>0.406695</td>\n",
       "      <td>0.041478</td>\n",
       "      <td>0.363968</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3500</td>\n",
       "      <td>0.713600</td>\n",
       "      <td>0.406286</td>\n",
       "      <td>0.042318</td>\n",
       "      <td>0.362632</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3600</td>\n",
       "      <td>0.699900</td>\n",
       "      <td>0.395000</td>\n",
       "      <td>0.032562</td>\n",
       "      <td>0.361397</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3700</td>\n",
       "      <td>0.688500</td>\n",
       "      <td>0.389198</td>\n",
       "      <td>0.027883</td>\n",
       "      <td>0.360402</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3800</td>\n",
       "      <td>0.657700</td>\n",
       "      <td>0.381372</td>\n",
       "      <td>0.021216</td>\n",
       "      <td>0.359403</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3900</td>\n",
       "      <td>0.633500</td>\n",
       "      <td>0.387053</td>\n",
       "      <td>0.027691</td>\n",
       "      <td>0.358421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4000</td>\n",
       "      <td>0.623200</td>\n",
       "      <td>0.380553</td>\n",
       "      <td>0.022430</td>\n",
       "      <td>0.357311</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4100</td>\n",
       "      <td>0.612500</td>\n",
       "      <td>0.383209</td>\n",
       "      <td>0.025746</td>\n",
       "      <td>0.356530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4200</td>\n",
       "      <td>0.604600</td>\n",
       "      <td>0.381293</td>\n",
       "      <td>0.025203</td>\n",
       "      <td>0.355200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4300</td>\n",
       "      <td>0.596100</td>\n",
       "      <td>0.378809</td>\n",
       "      <td>0.022855</td>\n",
       "      <td>0.355094</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4400</td>\n",
       "      <td>0.589100</td>\n",
       "      <td>0.373687</td>\n",
       "      <td>0.019005</td>\n",
       "      <td>0.353927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4500</td>\n",
       "      <td>0.581000</td>\n",
       "      <td>0.369913</td>\n",
       "      <td>0.016227</td>\n",
       "      <td>0.353053</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4600</td>\n",
       "      <td>0.575600</td>\n",
       "      <td>0.371798</td>\n",
       "      <td>0.018506</td>\n",
       "      <td>0.352563</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4700</td>\n",
       "      <td>0.568400</td>\n",
       "      <td>0.369594</td>\n",
       "      <td>0.017212</td>\n",
       "      <td>0.351684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4800</td>\n",
       "      <td>0.562200</td>\n",
       "      <td>0.372014</td>\n",
       "      <td>0.020214</td>\n",
       "      <td>0.351027</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4900</td>\n",
       "      <td>0.556600</td>\n",
       "      <td>0.367565</td>\n",
       "      <td>0.016418</td>\n",
       "      <td>0.350489</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5000</td>\n",
       "      <td>0.552500</td>\n",
       "      <td>0.362797</td>\n",
       "      <td>0.012365</td>\n",
       "      <td>0.349859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5100</td>\n",
       "      <td>0.545000</td>\n",
       "      <td>0.364368</td>\n",
       "      <td>0.014475</td>\n",
       "      <td>0.349260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5200</td>\n",
       "      <td>0.540100</td>\n",
       "      <td>0.362849</td>\n",
       "      <td>0.013576</td>\n",
       "      <td>0.348648</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5300</td>\n",
       "      <td>0.533900</td>\n",
       "      <td>0.360401</td>\n",
       "      <td>0.011377</td>\n",
       "      <td>0.348467</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5400</td>\n",
       "      <td>0.531900</td>\n",
       "      <td>0.360795</td>\n",
       "      <td>0.012338</td>\n",
       "      <td>0.347879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5500</td>\n",
       "      <td>0.527400</td>\n",
       "      <td>0.357948</td>\n",
       "      <td>0.010028</td>\n",
       "      <td>0.347414</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5600</td>\n",
       "      <td>0.524800</td>\n",
       "      <td>0.356785</td>\n",
       "      <td>0.009164</td>\n",
       "      <td>0.347112</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5700</td>\n",
       "      <td>0.520200</td>\n",
       "      <td>0.356659</td>\n",
       "      <td>0.009637</td>\n",
       "      <td>0.346505</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5800</td>\n",
       "      <td>0.518500</td>\n",
       "      <td>0.358003</td>\n",
       "      <td>0.011253</td>\n",
       "      <td>0.346190</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5900</td>\n",
       "      <td>0.515500</td>\n",
       "      <td>0.354848</td>\n",
       "      <td>0.008531</td>\n",
       "      <td>0.345831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6000</td>\n",
       "      <td>0.511600</td>\n",
       "      <td>0.355197</td>\n",
       "      <td>0.009295</td>\n",
       "      <td>0.345393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6100</td>\n",
       "      <td>0.510600</td>\n",
       "      <td>0.352635</td>\n",
       "      <td>0.007122</td>\n",
       "      <td>0.345072</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6200</td>\n",
       "      <td>0.508300</td>\n",
       "      <td>0.352687</td>\n",
       "      <td>0.007395</td>\n",
       "      <td>0.344819</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6300</td>\n",
       "      <td>0.505200</td>\n",
       "      <td>0.352049</td>\n",
       "      <td>0.006949</td>\n",
       "      <td>0.344625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6400</td>\n",
       "      <td>0.504300</td>\n",
       "      <td>0.352208</td>\n",
       "      <td>0.007423</td>\n",
       "      <td>0.344307</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6500</td>\n",
       "      <td>0.502000</td>\n",
       "      <td>0.350064</td>\n",
       "      <td>0.005575</td>\n",
       "      <td>0.344039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6600</td>\n",
       "      <td>0.500100</td>\n",
       "      <td>0.350067</td>\n",
       "      <td>0.005743</td>\n",
       "      <td>0.343879</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 45.4273, 'learning_rate': 4.9338449325218316e-05, 'epoch': 0.01}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 1.455737590789795, 'eval_supp_data_loss_lm': 0.7837565541267395, 'eval_loss': 2.278831958770752, 'eval_runtime': 5.5902, 'eval_samples_per_second': 531.29, 'eval_steps_per_second': 4.293, 'epoch': 0.01}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1m-[Gen]\u001b[0m\u001b[31;1m-[ome]\u001b[0m\u001b[31;1m of[wide]\u001b[0m\u001b[31;1m-[identification]\u001b[0m\u001b[31;1m of[and]\u001b[0m\u001b[31;1m the[characterization]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[micro]\u001b[0m\u001b[31;1m-[s]\u001b[0m\u001b[31;1m-[atellite]\u001b[0m\u001b[31;1m-[markers]\u001b[0m\u001b[31;1m of[in]\u001b[0m\u001b[31;1m the[black]\u001b[0m\u001b[31;1m-[pepper]\u001b[0m\u001b[31;1m-[(]\u001b[0m\u001b[31;1m the[P]\u001b[0m\u001b[31;1m-[iper]\u001b[0m\u001b[31;1m-[n]\u001b[0m\u001b[31;1m-[igr]\u001b[0m\u001b[31;1m-[um]\u001b[0m\u001b[31;1m</s>[):]\u001b[0m\u001b[31;1m</s>[A]\u001b[0m\u001b[31;1m-[valuable]\u001b[0m\u001b[31;1m-[resource]\u001b[0m\u001b[31;1m of[for]\u001b[0m\u001b[31;1m the[boosting]\u001b[0m\u001b[31;1m</s>[gen]\u001b[0m\u001b[31;1m-[omics]\u001b[0m\u001b[31;1m</s>[applications]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 8.8278, 'learning_rate': 4.867689865043662e-05, 'epoch': 0.03}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.898766040802002, 'eval_supp_data_loss_lm': 0.7016785740852356, 'eval_loss': 1.6245797872543335, 'eval_runtime': 5.3912, 'eval_samples_per_second': 550.896, 'eval_steps_per_second': 4.452, 'epoch': 0.03}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Exp]\u001b[0m\u001b[31;1min[ression]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Concern]\u001b[0m\u001b[31;1m of[:]\u001b[0m\u001b[31;1m a[Caps]\u001b[0m\u001b[31;1mic[aic]\u001b[0m\u001b[31;1m-[in]\u001b[0m\u001b[31;1m and[inhibits]\u001b[0m\u001b[31;1m the[migration]\u001b[0m\u001b[31;1m of[and]\u001b[0m\u001b[31;1m the[invasion]\u001b[0m\u001b[31;1m of[via]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m the[AM]\u001b[0m\u001b[31;1m-[PK]\u001b[0m\u001b[31;1m-[/]\u001b[0m\u001b[31;1mA[NF]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mD[kB]\u001b[0m\u001b[31;1m-[signaling]\u001b[0m\u001b[31;1m</s>[pathway]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m the[es]\u001b[0m\u001b[31;1min[oph]\u001b[0m\u001b[31;1min[agus]\u001b[0m\u001b[31;1m</s>[sequ]\u001b[0m\u001b[31;1mic[amous]\u001b[0m\u001b[31;1m and[cell]\u001b[0m\u001b[31;1m-[carcin]\u001b[0m\u001b[31;1min[oma]\u001b[0m\u001b[31;1m</s>[by]\u001b[0m\u001b[31;1m the[decreasing]\u001b[0m\u001b[31;1m the[matrix]\u001b[0m\u001b[31;1m-[met]\u001b[0m\u001b[31;1mation[all]\u001b[0m\u001b[31;1mic[op]\u001b[0m\u001b[31;1min[rotein]\u001b[0m\u001b[31;1m</s>[ase]\u001b[0m\u001b[31;1m</s>[-]\u001b[0m\u001b[31;1mbased[9]\u001b[0m\u001b[31;1m</s>[expression]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 6.249, 'learning_rate': 4.801534797565494e-05, 'epoch': 0.04}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.5453088879585266, 'eval_supp_data_loss_lm': 0.6402448415756226, 'eval_loss': 1.2000300884246826, 'eval_runtime': 5.646, 'eval_samples_per_second': 526.037, 'eval_steps_per_second': 4.251, 'epoch': 0.04}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[No]\u001b[0m\u001b[31;1m-[Mod]\u001b[0m\u001b[31;1mal[ulatory]\u001b[0m\u001b[31;1m and[Effects]\u001b[0m\u001b[31;1m of[when]\u001b[0m\u001b[31;1m a[Stim]\u001b[0m\u001b[31;1mal[ulating]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m the[Right]\u001b[0m\u001b[31;1m and[In]\u001b[0m\u001b[31;1mhib[fer]\u001b[0m\u001b[31;1mon[ior]\u001b[0m\u001b[31;1m and[Front]\u001b[0m\u001b[31;1m-[al]\u001b[0m\u001b[31;1m and[G]\u001b[0m\u001b[31;1mas[yrus]\u001b[0m\u001b[31;1m in[with]\u001b[0m\u001b[31;1m the[Continuous]\u001b[0m\u001b[31;1m and[6]\u001b[0m\u001b[31;1m-[�]\u001b[0m\u001b[31;1m�[�]\u001b[0m\u001b[31;1m1[Hz]\u001b[0m\u001b[31;1m-[t]\u001b[0m\u001b[31;1m-[AC]\u001b[0m\u001b[31;1m-[S]\u001b[0m\u001b[31;1m-[and]\u001b[0m\u001b[31;1m the[t]\u001b[0m\u001b[31;1m-[R]\u001b[0m\u001b[31;1m-[NS]\u001b[0m\u001b[31;1m</s>[on]\u001b[0m\u001b[31;1m the[Response]\u001b[0m\u001b[31;1m to[In]\u001b[0m\u001b[31;1mhib[hibition]\u001b[0m\u001b[31;1m</s>[:]\u001b[0m\u001b[32;1m A\u001b[0m\u001b[31;1m case[Behavioral]\u001b[0m\u001b[31;1m study[Study]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 5.0505, 'learning_rate': 4.735379730087325e-05, 'epoch': 0.05}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.4324442446231842, 'eval_supp_data_loss_lm': 0.5910736918449402, 'eval_loss': 1.0348961353302002, 'eval_runtime': 5.6463, 'eval_samples_per_second': 526.012, 'eval_steps_per_second': 4.251, 'epoch': 0.05}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[E]\u001b[0m\u001b[32;1mval\u001b[0m\u001b[32;1muation\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m effect[Clinical]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m the[Economic]\u001b[0m\u001b[31;1m and[B]\u001b[0m\u001b[31;1macterial[urden]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Poor]\u001b[0m\u001b[31;1m and[Gly]\u001b[0m\u001b[31;1mt[cemic]\u001b[0m\u001b[31;1m and[Control]\u001b[0m\u001b[31;1m in[Associated]\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m the[Ther]\u001b[0m\u001b[32;1mape\u001b[0m\u001b[31;1mpt[utic]\u001b[0m\u001b[31;1m and[In]\u001b[0m\u001b[31;1mhib[ert]\u001b[0m\u001b[31;1mion[ia]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[Patients]\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m the[Type]\u001b[0m\u001b[31;1m 2[]\u001b[0m\u001b[31;1m1[2]\u001b[0m\u001b[31;1m-[Diabetes]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m a[the]\u001b[0m\u001b[31;1m Patients[United]\u001b[0m\u001b[31;1m and[States]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 4.2082, 'learning_rate': 4.6692246626091565e-05, 'epoch': 0.07}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.41350874304771423, 'eval_supp_data_loss_lm': 0.5503431558609009, 'eval_loss': 0.9745368957519531, 'eval_runtime': 5.5152, 'eval_samples_per_second': 538.515, 'eval_steps_per_second': 4.352, 'epoch': 0.07}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Multiple]\u001b[0m\u001b[31;1m-[s]\u001b[0m\u001b[31;1murgical[cler]\u001b[0m\u001b[31;1mop[osing]\u001b[0m\u001b[31;1m and[hem]\u001b[0m\u001b[31;1mat[ang]\u001b[0m\u001b[32;1mi\u001b[0m\u001b[32;1moma\u001b[0m\u001b[31;1m in[of]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m treatment[right]\u001b[0m\u001b[31;1m-[lung]\u001b[0m\u001b[31;1m:[in]\u001b[0m\u001b[31;1m the[a]\u001b[0m\u001b[31;1m patient[23]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1myear\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mterm[old]\u001b[0m\u001b[31;1m population[female]\u001b[0m\u001b[31;1m patients[patient]\u001b[0m\u001b[31;1m with[:]\u001b[0m\u001b[31;1m a[A]\u001b[0m\u001b[32;1m case\u001b[0m\u001b[32;1m report\u001b[0m\u001b[31;1m</s>[and]\u001b[0m\u001b[31;1m meta[review]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m clinical[literature]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-12000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.6945, 'learning_rate': 4.603069595130987e-05, 'epoch': 0.08}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.45586785674095154, 'eval_supp_data_loss_lm': 0.5179269909858704, 'eval_loss': 0.9854666590690613, 'eval_runtime': 5.6597, 'eval_samples_per_second': 524.766, 'eval_steps_per_second': 4.241, 'epoch': 0.08}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[A]\u001b[0m\u001b[31;1m novel[prospective]\u001b[0m\u001b[32;1m study\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[shoulder]\u001b[0m\u001b[31;1m cancer[pain]\u001b[0m\u001b[31;1m and[in]\u001b[0m\u001b[31;1m patients[primary]\u001b[0m\u001b[32;1m care\u001b[0m\u001b[31;1m patients[:]\u001b[0m\u001b[31;1m a[Pre]\u001b[0m\u001b[31;1m-[val]\u001b[0m\u001b[32;1mence\u001b[0m\u001b[31;1m and[of]\u001b[0m\u001b[31;1m the[im]\u001b[0m\u001b[31;1mplant[aged]\u001b[0m\u001b[31;1m patients[pathology]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m the[response]\u001b[0m\u001b[32;1m to\u001b[0m\u001b[31;1m the[guided]\u001b[0m\u001b[31;1m care[diagnostic]\u001b[0m\u001b[31;1m and[blocks]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 3.208, 'learning_rate': 4.5369145276528185e-05, 'epoch': 0.09}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.3247360587120056, 'eval_supp_data_loss_lm': 0.49280211329460144, 'eval_loss': 0.8257945775985718, 'eval_runtime': 5.4141, 'eval_samples_per_second': 548.563, 'eval_steps_per_second': 4.433, 'epoch': 0.09}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[N]\u001b[0m\u001b[31;1mucle[urses]\u001b[0m\u001b[32;1m�\u001b[0m\u001b[32;1m�\u001b[0m\u001b[31;1m and[knowledge]\u001b[0m\u001b[31;1m of[and]\u001b[0m\u001b[31;1m health[practices]\u001b[0m\u001b[31;1m of[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m treatment[face]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m treatment[challenge]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[using]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m treatment[system]\u001b[0m\u001b[31;1m to[at]\u001b[0m\u001b[31;1mical[ization]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[nursing]\u001b[0m\u001b[31;1m and[care]\u001b[0m\u001b[31;1m in[as]\u001b[0m\u001b[31;1m a[an]\u001b[0m\u001b[31;1m evaluation[instrument]\u001b[0m\u001b[31;1m for[of]\u001b[0m\u001b[31;1m the[assistance]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m the[a]\u001b[0m\u001b[31;1m patient[first]\u001b[0m\u001b[31;1m-[aid]\u001b[0m\u001b[31;1m model[in]\u001b[0m\u001b[31;1m the[Brazil]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.7793, 'learning_rate': 4.470759460174649e-05, 'epoch': 0.11}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.24971961975097656, 'eval_supp_data_loss_lm': 0.47550714015960693, 'eval_loss': 0.7315453290939331, 'eval_runtime': 5.5349, 'eval_samples_per_second': 536.599, 'eval_steps_per_second': 4.336, 'epoch': 0.11}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[T]\u001b[0m\u001b[31;1mreatment[ACC]\u001b[0m\u001b[31;1m-[3]\u001b[0m\u001b[31;1m-[is]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m novel[micro]\u001b[0m\u001b[31;1mRNA[tub]\u001b[0m\u001b[31;1mular[ule]\u001b[0m\u001b[31;1m for[plus]\u001b[0m\u001b[31;1m a[end]\u001b[0m\u001b[31;1mopl[-]\u001b[0m\u001b[31;1mof[tracking]\u001b[0m\u001b[31;1m of[protein]\u001b[0m\u001b[31;1m for[that]\u001b[0m\u001b[31;1m is[promotes]\u001b[0m\u001b[31;1m the[ax]\u001b[0m\u001b[31;1mial[on]\u001b[0m\u001b[31;1m-[elong]\u001b[0m\u001b[32;1mation\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m in[also]\u001b[0m\u001b[31;1m in[regulates]\u001b[0m\u001b[31;1m the[micro]\u001b[0m\u001b[31;1mRNA[tub]\u001b[0m\u001b[31;1mular[ule]\u001b[0m\u001b[31;1m-[plus]\u001b[0m\u001b[31;1m cell[end]\u001b[0m\u001b[31;1m-[dynamics]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m patients[multiple]\u001b[0m\u001b[31;1m cell[embryonic]\u001b[0m\u001b[31;1m cells[cell]\u001b[0m\u001b[31;1m carcin[types]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.4305, 'learning_rate': 4.4046043926964806e-05, 'epoch': 0.12}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.24587424099445343, 'eval_supp_data_loss_lm': 0.46108973026275635, 'eval_loss': 0.7131246328353882, 'eval_runtime': 5.5469, 'eval_samples_per_second': 535.438, 'eval_steps_per_second': 4.327, 'epoch': 0.12}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[�]\u001b[0m\u001b[32;1m�\u001b[0m\u001b[31;1mThe[T]\u001b[0m\u001b[31;1mreatment[ape]\u001b[0m\u001b[31;1m-[dermat]\u001b[0m\u001b[31;1mology[osc]\u001b[0m\u001b[32;1mopy\u001b[0m\u001b[31;1m of[�]\u001b[0m\u001b[32;1m�\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m a[constructing]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m new[low]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mdose[cost]\u001b[0m\u001b[31;1m,[dermat]\u001b[0m\u001b[31;1mology[oscope]\u001b[0m\u001b[31;1m for[using]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m new[mobile]\u001b[0m\u001b[31;1m-[phone]\u001b[0m\u001b[31;1m-[,]\u001b[0m\u001b[31;1m a[immersion]\u001b[0m\u001b[31;1m,[fluid]\u001b[0m\u001b[31;1m,[and]\u001b[0m\u001b[31;1m the[transparent]\u001b[0m\u001b[31;1m-[adhesive]\u001b[0m\u001b[31;1m</s>[tape]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.2022, 'learning_rate': 4.338449325218312e-05, 'epoch': 0.13}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.21875999867916107, 'eval_supp_data_loss_lm': 0.449216365814209, 'eval_loss': 0.6734893321990967, 'eval_runtime': 5.6476, 'eval_samples_per_second': 525.887, 'eval_steps_per_second': 4.25, 'epoch': 0.13}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[32;1mThe\u001b[0m\u001b[31;1m effect[Chinese]\u001b[0m\u001b[31;1m version[Her]\u001b[0m\u001b[31;1mpes[bal]\u001b[0m\u001b[31;1m Health[Formula]\u001b[0m\u001b[31;1m of[Shen]\u001b[0m\u001b[31;1mter[z]\u001b[0m\u001b[31;1mia[hu]\u001b[0m\u001b[31;1m,[T]\u001b[0m\u001b[31;1mum[ia]\u001b[0m\u001b[31;1m,[op]\u001b[0m\u001b[31;1mo[i]\u001b[0m\u001b[31;1m ([Gran]\u001b[0m\u001b[31;1mc[ule]\u001b[0m\u001b[31;1m ([Results]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[Met]\u001b[0m\u001b[31;1mabol[abolic]\u001b[0m\u001b[31;1m and[Improvement]\u001b[0m\u001b[31;1m of[in]\u001b[0m\u001b[31;1m Patients[Type]\u001b[0m\u001b[32;1m 2\u001b[0m\u001b[31;1m Diabetes[Di]\u001b[0m\u001b[32;1mabetic\u001b[0m\u001b[31;1m Patients[Rats]\u001b[0m\u001b[31;1m</s>[by]\u001b[0m\u001b[31;1m the[Mod]\u001b[0m\u001b[32;1mulating\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m Expression[Gut]\u001b[0m\u001b[31;1m-[Micro]\u001b[0m\u001b[32;1mbi\u001b[0m\u001b[32;1mota\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-1000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-24000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 2.0127, 'learning_rate': 4.2722942577401434e-05, 'epoch': 0.15}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.1849970817565918, 'eval_supp_data_loss_lm': 0.4400160312652588, 'eval_loss': 0.6296237707138062, 'eval_runtime': 5.5923, 'eval_samples_per_second': 531.09, 'eval_steps_per_second': 4.292, 'epoch': 0.15}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Effect]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[ankle]\u001b[0m\u001b[31;1m and[stretching]\u001b[0m\u001b[31;1m on[combined]\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m a[arm]\u001b[0m\u001b[31;1m ar[cycling]\u001b[0m\u001b[32;1m on\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m risk[improvement]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[calf]\u001b[0m\u001b[31;1m and[muscle]\u001b[0m\u001b[31;1m and[stiffness]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[32;1m patients\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m chronic[stroke]\u001b[0m\u001b[31;1m</s>[:]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m systematic[pilot]\u001b[0m\u001b[32;1m study\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.8575, 'learning_rate': 4.206139190261974e-05, 'epoch': 0.16}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.19968722760677338, 'eval_supp_data_loss_lm': 0.4317455291748047, 'eval_loss': 0.6365070939064026, 'eval_runtime': 5.6729, 'eval_samples_per_second': 523.54, 'eval_steps_per_second': 4.231, 'epoch': 0.16}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Pl]\u001b[0m\u001b[32;1masma\u001b[0m\u001b[31;1m-[Micro]\u001b[0m\u001b[31;1mbi[RNA]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mBased[21]\u001b[0m\u001b[31;1m and[,]\u001b[0m\u001b[31;1m a[26]\u001b[0m\u001b[31;1m-[a]\u001b[0m\u001b[32;1m,\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m E[29]\u001b[0m\u001b[32;1ma\u001b[0m\u001b[31;1m Are[-]\u001b[0m\u001b[32;1m3\u001b[0m\u001b[32;1mp\u001b[0m\u001b[31;1m Are[as]\u001b[0m\u001b[31;1m a[Pred]\u001b[0m\u001b[32;1mictive\u001b[0m\u001b[31;1m Factor[Mark]\u001b[0m\u001b[32;1mers\u001b[0m\u001b[31;1m of[for]\u001b[0m\u001b[31;1m the[Treatment]\u001b[0m\u001b[31;1m of[Response]\u001b[0m\u001b[31;1m to[Following]\u001b[0m\u001b[31;1m Int[Trans]\u001b[0m\u001b[31;1mplant[arter]\u001b[0m\u001b[32;1mial\u001b[0m\u001b[31;1m My[Che]\u001b[0m\u001b[31;1mmor[mo]\u001b[0m\u001b[32;1memb\u001b[0m\u001b[32;1mol\u001b[0m\u001b[32;1mization\u001b[0m\u001b[31;1m of[in]\u001b[0m\u001b[32;1m Patients\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m Type[Hep]\u001b[0m\u001b[32;1mato\u001b[0m\u001b[32;1mcell\u001b[0m\u001b[32;1mular\u001b[0m\u001b[32;1m Car\u001b[0m\u001b[32;1mcin\u001b[0m\u001b[32;1moma\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.6912, 'learning_rate': 4.1399841227838055e-05, 'epoch': 0.17}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.15785063803195953, 'eval_supp_data_loss_lm': 0.4245401918888092, 'eval_loss': 0.5862813591957092, 'eval_runtime': 5.5296, 'eval_samples_per_second': 537.106, 'eval_steps_per_second': 4.34, 'epoch': 0.17}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Small]\u001b[0m\u001b[31;1m-[RNA]\u001b[0m\u001b[31;1m-[Sequ]\u001b[0m\u001b[32;1mencing\u001b[0m\u001b[31;1m of[Analysis]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[mi]\u001b[0m\u001b[31;1mR[RNA]\u001b[0m\u001b[31;1m-[Expression]\u001b[0m\u001b[31;1m in[Reve]\u001b[0m\u001b[32;1mals\u001b[0m\u001b[31;1m a[Novel]\u001b[0m\u001b[31;1m Ant[Ins]\u001b[0m\u001b[31;1mights[ih]\u001b[0m\u001b[31;1myd[ts]\u001b[0m\u001b[31;1m in[into]\u001b[0m\u001b[31;1m the[Root]\u001b[0m\u001b[31;1m-[Formation]\u001b[0m\u001b[31;1m and[under]\u001b[0m\u001b[31;1m the[Root]\u001b[0m\u001b[31;1m-[Restrict]\u001b[0m\u001b[32;1mion\u001b[0m\u001b[31;1m</s>[Cult]\u001b[0m\u001b[31;1mured[ivation]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m the[Grape]\u001b[0m\u001b[31;1m-[vine]\u001b[0m\u001b[31;1m</s>[(]\u001b[0m\u001b[31;1mC[V]\u001b[0m\u001b[31;1mit[itis]\u001b[0m\u001b[31;1m sat[v]\u001b[0m\u001b[31;1mes[in]\u001b[0m\u001b[31;1mum[ifer]\u001b[0m\u001b[32;1ma\u001b[0m\u001b[31;1m)[L]\u001b[0m\u001b[32;1m.)\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.502, 'learning_rate': 4.073829055305637e-05, 'epoch': 0.19}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.1307850480079651, 'eval_supp_data_loss_lm': 0.4183826744556427, 'eval_loss': 0.5523537993431091, 'eval_runtime': 5.6377, 'eval_samples_per_second': 526.814, 'eval_steps_per_second': 4.257, 'epoch': 0.19}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Performance]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[the]\u001b[0m\u001b[31;1m R[Abbott]\u001b[0m\u001b[31;1m-[Real]\u001b[0m\u001b[31;1m-[Time]\u001b[0m\u001b[31;1m Method[MT]\u001b[0m\u001b[31;1mF[B]\u001b[0m\u001b[31;1m-[R]\u001b[0m\u001b[31;1misks[IF]\u001b[0m\u001b[31;1m-[/]\u001b[0m\u001b[31;1mMS[IN]\u001b[0m\u001b[31;1m-[H]\u001b[0m\u001b[31;1m/[resistance]\u001b[0m\u001b[32;1m assay\u001b[0m\u001b[31;1m in[when]\u001b[0m\u001b[31;1m in[used]\u001b[0m\u001b[31;1m in[to]\u001b[0m\u001b[31;1m assess[test]\u001b[0m\u001b[31;1m the[My]\u001b[0m\u001b[32;1mc\u001b[0m\u001b[32;1mob\u001b[0m\u001b[32;1macter\u001b[0m\u001b[32;1mium\u001b[0m\u001b[32;1m tuberculosis\u001b[0m\u001b[31;1m in[specimens]\u001b[0m\u001b[31;1m in[from]\u001b[0m\u001b[31;1m the[Bangladesh]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3815, 'learning_rate': 4.0076739878274675e-05, 'epoch': 0.2}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.12562504410743713, 'eval_supp_data_loss_lm': 0.4126805067062378, 'eval_loss': 0.5413737893104553, 'eval_runtime': 5.5084, 'eval_samples_per_second': 539.175, 'eval_steps_per_second': 4.357, 'epoch': 0.2}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Sm]\u001b[0m\u001b[31;1moking[ad]\u001b[0m\u001b[31;1m-[4]\u001b[0m\u001b[31;1m-[in]\u001b[0m\u001b[31;1m the[T]\u001b[0m\u001b[31;1mum[cells]\u001b[0m\u001b[31;1m is[plays]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m role[protective]\u001b[0m\u001b[32;1m role\u001b[0m\u001b[32;1m in\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m proliferation[development]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[autoimmune]\u001b[0m\u001b[31;1m diseases[S]\u001b[0m\u001b[31;1mARS[j]\u001b[0m\u001b[32;1mö\u001b[0m\u001b[32;1mgren\u001b[0m\u001b[32;1m's\u001b[0m\u001b[31;1m disease[syndrome]\u001b[0m\u001b[31;1m:[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m rat[non]\u001b[0m\u001b[31;1m-[ob]\u001b[0m\u001b[31;1mesity[ese]\u001b[0m\u001b[31;1m rat[diabetic]\u001b[0m\u001b[31;1m rat[mouse]\u001b[0m\u001b[31;1m model[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-1500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-36000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.3095, 'learning_rate': 3.941518920349299e-05, 'epoch': 0.21}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.09868025779724121, 'eval_supp_data_loss_lm': 0.4072902202606201, 'eval_loss': 0.5083640813827515, 'eval_runtime': 5.6092, 'eval_samples_per_second': 529.485, 'eval_steps_per_second': 4.279, 'epoch': 0.21}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Sub]\u001b[0m\u001b[31;1mstrate[ac]\u001b[0m\u001b[32;1mute\u001b[0m\u001b[31;1m and[Thy]\u001b[0m\u001b[32;1mroid\u001b[0m\u001b[31;1m Cancer[itis]\u001b[0m\u001b[31;1m in[is]\u001b[0m\u001b[32;1m Associated\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m the[H]\u001b[0m\u001b[31;1morm[LA]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1m1[B]\u001b[0m\u001b[31;1m1[*]\u001b[0m\u001b[31;1mB[18]\u001b[0m\u001b[31;1m and[:]\u001b[0m\u001b[31;1m A[01]\u001b[0m\u001b[31;1m-[,]\u001b[0m\u001b[31;1m3[-]\u001b[0m\u001b[31;1m3[DR]\u001b[0m\u001b[31;1m-[B]\u001b[0m\u001b[31;1m-[1]\u001b[0m\u001b[31;1m,[*]\u001b[0m\u001b[31;1m1[01]\u001b[0m\u001b[31;1m,[and]\u001b[0m\u001b[32;1m -\u001b[0m\u001b[31;1m3[C]\u001b[0m\u001b[31;1m9[*]\u001b[0m\u001b[31;1m3[04]\u001b[0m\u001b[31;1m,[:]\u001b[0m\u001b[31;1m3[01]\u001b[0m\u001b[31;1m,[-]\u001b[0m\u001b[31;1m5[The]\u001b[0m\u001b[31;1m Role[Sign]\u001b[0m\u001b[32;1mific\u001b[0m\u001b[32;1mance\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m T[New]\u001b[0m\u001b[31;1m Pro[Molecular]\u001b[0m\u001b[31;1m Re[Background]\u001b[0m\u001b[31;1m of[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.2051, 'learning_rate': 3.87536385287113e-05, 'epoch': 0.22}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.10316312313079834, 'eval_supp_data_loss_lm': 0.402576208114624, 'eval_loss': 0.508370041847229, 'eval_runtime': 5.6762, 'eval_samples_per_second': 523.241, 'eval_steps_per_second': 4.228, 'epoch': 0.22}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Effect]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m novel[mass]\u001b[0m\u001b[31;1m spect[radio]\u001b[0m\u001b[31;1mfrequency[campaign]\u001b[0m\u001b[32;1m on\u001b[0m\u001b[31;1m the[family]\u001b[0m\u001b[31;1m health[behaviours]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m health[child]\u001b[0m\u001b[31;1m health[survival]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m patients[Burk]\u001b[0m\u001b[31;1mhold[ina]\u001b[0m\u001b[32;1m Fas\u001b[0m\u001b[32;1mo\u001b[0m\u001b[32;1m:\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m systematic[repeated]\u001b[0m\u001b[31;1m review[cross]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1msectional\u001b[0m\u001b[31;1m study[,]\u001b[0m\u001b[31;1m prospective[cluster]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mrandom\u001b[0m\u001b[31;1mized[ised]\u001b[0m\u001b[31;1m,[trial]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1491, 'learning_rate': 3.809208785392962e-05, 'epoch': 0.24}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.11059979349374771, 'eval_supp_data_loss_lm': 0.3983963429927826, 'eval_loss': 0.5118117332458496, 'eval_runtime': 5.5555, 'eval_samples_per_second': 534.608, 'eval_steps_per_second': 4.32, 'epoch': 0.24}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Ne]\u001b[0m\u001b[32;1muro\u001b[0m\u001b[31;1mprot[t]\u001b[0m\u001b[31;1mrophic[oxicity]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[NM]\u001b[0m\u001b[32;1mDA\u001b[0m\u001b[31;1m-[antagonists]\u001b[0m\u001b[31;1m in[:]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m novel[glut]\u001b[0m\u001b[31;1math[am]\u001b[0m\u001b[31;1myl[ater]\u001b[0m\u001b[32;1mg\u001b[0m\u001b[32;1mic\u001b[0m\u001b[31;1m and[theory]\u001b[0m\u001b[31;1m-[of]\u001b[0m\u001b[31;1m the[schizophrenia]\u001b[0m\u001b[31;1m and[based]\u001b[0m\u001b[32;1m on\u001b[0m\u001b[31;1m the[selective]\u001b[0m\u001b[31;1m and[impairment]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[local]\u001b[0m\u001b[31;1m and[inhibit]\u001b[0m\u001b[32;1mory\u001b[0m\u001b[31;1m activity[feedback]\u001b[0m\u001b[31;1m</s>[circuits]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.1009, 'learning_rate': 3.7430537179147924e-05, 'epoch': 0.25}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.09144443273544312, 'eval_supp_data_loss_lm': 0.3945960998535156, 'eval_loss': 0.4885094165802002, 'eval_runtime': 5.6728, 'eval_samples_per_second': 523.551, 'eval_steps_per_second': 4.231, 'epoch': 0.25}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Consider]\u001b[0m\u001b[32;1mations\u001b[0m\u001b[31;1m on[regarding]\u001b[0m\u001b[31;1m the[treatment]\u001b[0m\u001b[31;1m of[efficiency]\u001b[0m\u001b[31;1m and[,]\u001b[0m\u001b[31;1m safety[diss]\u001b[0m\u001b[31;1mociation[oci]\u001b[0m\u001b[31;1mations[ative]\u001b[0m\u001b[31;1m effects[parts]\u001b[0m\u001b[31;1m of[and]\u001b[0m\u001b[31;1m the[diss]\u001b[0m\u001b[31;1mociation[oci]\u001b[0m\u001b[31;1mations[ative]\u001b[0m\u001b[31;1m factors[am]\u001b[0m\u001b[31;1myl[nesia]\u001b[0m\u001b[31;1m in[for]\u001b[0m\u001b[31;1m patients[Hunt]\u001b[0m\u001b[31;1m's[j]\u001b[0m\u001b[31;1mö[ens]\u001b[0m\u001b[31;1m syndrome[et]\u001b[0m\u001b[32;1m al\u001b[0m\u001b[32;1m.\u001b[0m\u001b[31;1m A[�]\u001b[0m\u001b[31;1m�[�]\u001b[0m\u001b[32;1ms\u001b[0m\u001b[31;1m disease[Sche]\u001b[0m\u001b[31;1mletal[ma]\u001b[0m\u001b[31;1m ([Therapy]\u001b[0m\u001b[31;1m ([for]\u001b[0m\u001b[31;1m the[Diss]\u001b[0m\u001b[31;1mociation[oci]\u001b[0m\u001b[32;1mative\u001b[0m\u001b[31;1m Diseases[Identity]\u001b[0m\u001b[32;1m Disorder\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0695, 'learning_rate': 3.676898650436624e-05, 'epoch': 0.26}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.09011886268854141, 'eval_supp_data_loss_lm': 0.39106258749961853, 'eval_loss': 0.48361077904701233, 'eval_runtime': 5.5455, 'eval_samples_per_second': 535.572, 'eval_steps_per_second': 4.328, 'epoch': 0.26}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[32;1mThe\u001b[0m\u001b[31;1m effect[Con]\u001b[0m\u001b[31;1mventional[sequence]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Imm]\u001b[0m\u001b[32;1mune\u001b[0m\u001b[31;1m Respons[Supp]\u001b[0m\u001b[31;1mression[ressive]\u001b[0m\u001b[31;1m Factors[Cells]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m Human[Use]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[Ther]\u001b[0m\u001b[32;1mape\u001b[0m\u001b[32;1mutic\u001b[0m\u001b[31;1m Agents[Cancer]\u001b[0m\u001b[31;1m Cells[Vacc]\u001b[0m\u001b[31;1mine[ines]\u001b[0m\u001b[31;1m:[and]\u001b[0m\u001b[32;1m Their\u001b[0m\u001b[31;1m Role[Import]\u001b[0m\u001b[32;1mance\u001b[0m\u001b[31;1m for[in]\u001b[0m\u001b[31;1m the[Imm]\u001b[0m\u001b[32;1mune\u001b[0m\u001b[31;1m Response[Monitoring]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-2000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-48000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.036, 'learning_rate': 3.6107435829584545e-05, 'epoch': 0.28}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.06666389107704163, 'eval_supp_data_loss_lm': 0.3879471719264984, 'eval_loss': 0.45636147260665894, 'eval_runtime': 5.6124, 'eval_samples_per_second': 529.187, 'eval_steps_per_second': 4.276, 'epoch': 0.28}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Pre]\u001b[0m\u001b[32;1mval\u001b[0m\u001b[32;1mence\u001b[0m\u001b[31;1m and[,]\u001b[0m\u001b[31;1m risk[intensity]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[32;1m risk\u001b[0m\u001b[32;1m factors\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m acute[t]\u001b[0m\u001b[31;1mib[ung]\u001b[0m\u001b[31;1mular[iasis]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[Kil]\u001b[0m\u001b[31;1mmo[ifi]\u001b[0m\u001b[31;1m,[County]\u001b[0m\u001b[32;1m,\u001b[0m\u001b[31;1m China[Kenya]\u001b[0m\u001b[31;1m:[II]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m a[Results]\u001b[0m\u001b[32;1m from\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m cross[school]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mbased\u001b[0m\u001b[31;1m cohort[observational]\u001b[0m\u001b[32;1m study\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 1.0062, 'learning_rate': 3.544588515480286e-05, 'epoch': 0.29}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.07617712020874023, 'eval_supp_data_loss_lm': 0.3851659595966339, 'eval_loss': 0.46340084075927734, 'eval_runtime': 5.6158, 'eval_samples_per_second': 528.861, 'eval_steps_per_second': 4.274, 'epoch': 0.29}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Compar]\u001b[0m\u001b[32;1mison\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[skin]\u001b[0m\u001b[31;1m-[dose]\u001b[0m\u001b[31;1m and[measurement]\u001b[0m\u001b[31;1m and[using]\u001b[0m\u001b[31;1m a[nano]\u001b[0m\u001b[31;1m-[D]\u001b[0m\u001b[31;1m-[ot]\u001b[0m\u001b[31;1m-[®]\u001b[0m\u001b[31;1m and[dos]\u001b[0m\u001b[31;1mim[imeter]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m a[machine]\u001b[0m\u001b[31;1m learning[readings]\u001b[0m\u001b[31;1m for[of]\u001b[0m\u001b[31;1m the[radiation]\u001b[0m\u001b[31;1m-[dose]\u001b[0m\u001b[31;1m in[during]\u001b[0m\u001b[31;1m the[cardiac]\u001b[0m\u001b[31;1m surgery[cat]\u001b[0m\u001b[32;1mheter\u001b[0m\u001b[32;1mization\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m patients[children]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9803, 'learning_rate': 3.478433448002117e-05, 'epoch': 0.3}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.07755330204963684, 'eval_supp_data_loss_lm': 0.3826967179775238, 'eval_loss': 0.462399959564209, 'eval_runtime': 5.6676, 'eval_samples_per_second': 524.029, 'eval_steps_per_second': 4.235, 'epoch': 0.3}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Coll]\u001b[0m\u001b[32;1magen\u001b[0m\u001b[31;1m-[triple]\u001b[0m\u001b[31;1m-[hel]\u001b[0m\u001b[31;1mmin[ix]\u001b[0m\u001b[31;1m-[repeat]\u001b[0m\u001b[31;1m-[containing]\u001b[0m\u001b[31;1m a[1]\u001b[0m\u001b[31;1m,[is]\u001b[0m\u001b[31;1m a[overe]\u001b[0m\u001b[32;1mxp\u001b[0m\u001b[31;1mression[ressed]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[hep]\u001b[0m\u001b[32;1mato\u001b[0m\u001b[32;1mcell\u001b[0m\u001b[32;1mular\u001b[0m\u001b[32;1m carcin\u001b[0m\u001b[32;1moma\u001b[0m\u001b[31;1m cells[and]\u001b[0m\u001b[31;1m is[promotes]\u001b[0m\u001b[31;1m apopt[cell]\u001b[0m\u001b[32;1m proliferation\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m invasion[mot]\u001b[0m\u001b[32;1mility\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9387, 'learning_rate': 3.4122783805239486e-05, 'epoch': 0.32}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.06573893129825592, 'eval_supp_data_loss_lm': 0.3804208040237427, 'eval_loss': 0.4479807913303375, 'eval_runtime': 5.5334, 'eval_samples_per_second': 536.74, 'eval_steps_per_second': 4.337, 'epoch': 0.32}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Correction]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m The[f]\u001b[0m\u001b[31;1mMRI[Mi]\u001b[0m\u001b[31;1mR[RNA]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1m1[192]\u001b[0m\u001b[31;1m-[and]\u001b[0m\u001b[32;1m mi\u001b[0m\u001b[31;1mR[RNA]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1m21[204]\u001b[0m\u001b[31;1m are[Direct]\u001b[0m\u001b[32;1mly\u001b[0m\u001b[31;1m Reg[Supp]\u001b[0m\u001b[31;1mresses[ress]\u001b[0m\u001b[31;1m the[l]\u001b[0m\u001b[32;1mnc\u001b[0m\u001b[32;1mRNA\u001b[0m\u001b[31;1m-[H]\u001b[0m\u001b[31;1meter[OTT]\u001b[0m\u001b[31;1m1[IP]\u001b[0m\u001b[31;1m1[and]\u001b[0m\u001b[31;1m Supp[Inter]\u001b[0m\u001b[31;1maction[rupt]\u001b[0m\u001b[31;1ms[G]\u001b[0m\u001b[31;1mTP[LS]\u001b[0m\u001b[32;1m1\u001b[0m\u001b[31;1m Expression[-]\u001b[0m\u001b[32;1mMed\u001b[0m\u001b[32;1miated\u001b[0m\u001b[31;1m Ap[Gl]\u001b[0m\u001b[31;1muc[ut]\u001b[0m\u001b[31;1mamate[am]\u001b[0m\u001b[31;1myl[ino]\u001b[0m\u001b[32;1mly\u001b[0m\u001b[32;1msis\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m Human[Hep]\u001b[0m\u001b[32;1mato\u001b[0m\u001b[32;1mcell\u001b[0m\u001b[32;1mular\u001b[0m\u001b[32;1m Car\u001b[0m\u001b[32;1mcin\u001b[0m\u001b[32;1moma\u001b[0m\u001b[31;1m Cells[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.9136, 'learning_rate': 3.346123313045779e-05, 'epoch': 0.33}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.060078684240579605, 'eval_supp_data_loss_lm': 0.3781735897064209, 'eval_loss': 0.43991875648498535, 'eval_runtime': 5.5747, 'eval_samples_per_second': 532.765, 'eval_steps_per_second': 4.305, 'epoch': 0.33}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[A]\u001b[0m\u001b[31;1m Novel[Dist]\u001b[0m\u001b[32;1minct\u001b[0m\u001b[31;1m Role[Ur]\u001b[0m\u001b[32;1minary\u001b[0m\u001b[31;1m T[Bi]\u001b[0m\u001b[32;1mom\u001b[0m\u001b[32;1mark\u001b[0m\u001b[32;1mer\u001b[0m\u001b[31;1m of[Pattern]\u001b[0m\u001b[31;1m of[Character]\u001b[0m\u001b[31;1mistics[istic]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Female]\u001b[0m\u001b[31;1m Patients[Fab]\u001b[0m\u001b[32;1mry\u001b[0m\u001b[31;1m-[Patients]\u001b[0m\u001b[31;1m with[That]\u001b[0m\u001b[31;1m Have[Mir]\u001b[0m\u001b[31;1mac[rors]\u001b[0m\u001b[31;1m the[Response]\u001b[0m\u001b[32;1m to\u001b[0m\u001b[31;1m the[En]\u001b[0m\u001b[31;1mz[zyme]\u001b[0m\u001b[31;1m-[Replacement]\u001b[0m\u001b[31;1m</s>[Therapy]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-2500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-60000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8891, 'learning_rate': 3.279968245567611e-05, 'epoch': 0.34}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.06634222716093063, 'eval_supp_data_loss_lm': 0.37623894214630127, 'eval_loss': 0.4444561302661896, 'eval_runtime': 5.6292, 'eval_samples_per_second': 527.61, 'eval_steps_per_second': 4.264, 'epoch': 0.34}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Child]\u001b[0m\u001b[31;1mhood[Health]\u001b[0m\u001b[31;1m and[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m United[Per]\u001b[0m\u001b[31;1mipher[uvian]\u001b[0m\u001b[31;1m Republic[Amazon]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m A[Pre]\u001b[0m\u001b[32;1mval\u001b[0m\u001b[32;1mence\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m Risk[Factors]\u001b[0m\u001b[32;1m Associated\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m the[Referred]\u001b[0m\u001b[31;1m and[Mor]\u001b[0m\u001b[32;1mbid\u001b[0m\u001b[32;1mity\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m Risk[Health]\u001b[0m\u001b[31;1m-[Care]\u001b[0m\u001b[31;1m Use[Access]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m United[City]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m Edinburgh[I]\u001b[0m\u001b[31;1mso[ñ]\u001b[0m\u001b[31;1mob[ap]\u001b[0m\u001b[31;1mar[ari]\u001b[0m\u001b[31;1m,[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8677, 'learning_rate': 3.213813178089442e-05, 'epoch': 0.36}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.055309753865003586, 'eval_supp_data_loss_lm': 0.3743835985660553, 'eval_loss': 0.43127819895744324, 'eval_runtime': 5.5769, 'eval_samples_per_second': 532.557, 'eval_steps_per_second': 4.303, 'epoch': 0.36}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Cut]\u001b[0m\u001b[31;1maneous[ting]\u001b[0m\u001b[31;1m the[a]\u001b[0m\u001b[31;1m novel[Long]\u001b[0m\u001b[31;1mitudinal[Story]\u001b[0m\u001b[31;1m:[Short]\u001b[0m\u001b[31;1m:[?]\u001b[0m\u001b[32;1m The\u001b[0m\u001b[31;1m Role[Clinical]\u001b[0m\u001b[31;1m and[Re]\u001b[0m\u001b[32;1mlev\u001b[0m\u001b[32;1mance\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[As]\u001b[0m\u001b[31;1mper[king]\u001b[0m\u001b[31;1m for[Parents]\u001b[0m\u001b[31;1m and[,]\u001b[0m\u001b[31;1m and[Nurs]\u001b[0m\u001b[32;1mes\u001b[0m\u001b[32;1m,\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m Children[Young]\u001b[0m\u001b[31;1m Adults[Children]\u001b[0m\u001b[31;1m in[Them]\u001b[0m\u001b[31;1m to[selves]\u001b[0m\u001b[32;1m to\u001b[0m\u001b[31;1m the[Ident]\u001b[0m\u001b[32;1mify\u001b[0m\u001b[31;1m the[Children]\u001b[0m\u001b[31;1m with['s]\u001b[0m\u001b[31;1m Health[Mental]\u001b[0m\u001b[32;1m Health\u001b[0m\u001b[31;1m</s>[Problems]\u001b[0m\u001b[31;1m</s>[by]\u001b[0m\u001b[31;1m the[One]\u001b[0m\u001b[31;1m-[or]\u001b[0m\u001b[31;1m a[Two]\u001b[0m\u001b[31;1m-[Questions]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8449, 'learning_rate': 3.147658110611273e-05, 'epoch': 0.37}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.04545089974999428, 'eval_supp_data_loss_lm': 0.3726274073123932, 'eval_loss': 0.41941097378730774, 'eval_runtime': 5.5651, 'eval_samples_per_second': 533.684, 'eval_steps_per_second': 4.313, 'epoch': 0.37}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[My]\u001b[0m\u001b[31;1mocard[c]\u001b[0m\u001b[32;1mob\u001b[0m\u001b[31;1macter[acterial]\u001b[0m\u001b[31;1m and[gly]\u001b[0m\u001b[31;1mcop[col]\u001b[0m\u001b[31;1mic[ip]\u001b[0m\u001b[32;1mids\u001b[0m\u001b[31;1m in[di]\u001b[0m\u001b[31;1mhyd[-]\u001b[0m\u001b[31;1ml[O]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1ml[acy]\u001b[0m\u001b[31;1ml[lated]\u001b[0m\u001b[31;1m protein[tre]\u001b[0m\u001b[31;1mp[hal]\u001b[0m\u001b[31;1mos[ose]\u001b[0m\u001b[31;1m-[and]\u001b[0m\u001b[31;1m its[tri]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mhyd[O]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mmethyl[acy]\u001b[0m\u001b[31;1ml[lated]\u001b[0m\u001b[31;1m poly[tre]\u001b[0m\u001b[31;1mp[hal]\u001b[0m\u001b[32;1mose\u001b[0m\u001b[31;1m:[down]\u001b[0m\u001b[32;1mreg\u001b[0m\u001b[32;1mulate\u001b[0m\u001b[31;1m the[in]\u001b[0m\u001b[31;1m vitro[duc]\u001b[0m\u001b[32;1mible\u001b[0m\u001b[31;1m protein[nit]\u001b[0m\u001b[32;1mric\u001b[0m\u001b[32;1m oxide\u001b[0m\u001b[31;1m production[synth]\u001b[0m\u001b[32;1mase\u001b[0m\u001b[31;1m activity[and]\u001b[0m\u001b[31;1m the[nit]\u001b[0m\u001b[32;1mric\u001b[0m\u001b[32;1m oxide\u001b[0m\u001b[32;1m production\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m human[mac]\u001b[0m\u001b[32;1mroph\u001b[0m\u001b[32;1mages\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.8206, 'learning_rate': 3.081503043133104e-05, 'epoch': 0.38}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.046061720699071884, 'eval_supp_data_loss_lm': 0.3712327480316162, 'eval_loss': 0.41867882013320923, 'eval_runtime': 5.6093, 'eval_samples_per_second': 529.48, 'eval_steps_per_second': 4.279, 'epoch': 0.38}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Mult]\u001b[0m\u001b[31;1mic[ivariate]\u001b[0m\u001b[31;1m Analysis[Gen]\u001b[0m\u001b[31;1momic[ome]\u001b[0m\u001b[31;1m Analysis[-]\u001b[0m\u001b[32;1mWide\u001b[0m\u001b[31;1m Analysis[Association]\u001b[0m\u001b[31;1m Study[An]\u001b[0m\u001b[32;1malyses\u001b[0m\u001b[32;1m Reve\u001b[0m\u001b[32;1mal\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m Role[Genetic]\u001b[0m\u001b[31;1m Diversity[Bas]\u001b[0m\u001b[32;1mis\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Seed]\u001b[0m\u001b[31;1mling[Fat]\u001b[0m\u001b[32;1mty\u001b[0m\u001b[32;1m Acid\u001b[0m\u001b[31;1m-[Com]\u001b[0m\u001b[32;1mposition\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[O]\u001b[0m\u001b[31;1mste[at]\u001b[0m\u001b[31;1m-[(]\u001b[0m\u001b[31;1mL[A]\u001b[0m\u001b[31;1mry[ven]\u001b[0m\u001b[32;1ma\u001b[0m\u001b[32;1m sat\u001b[0m\u001b[32;1miva\u001b[0m\u001b[32;1m L\u001b[0m\u001b[32;1m.)\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7959, 'learning_rate': 3.0153479756549352e-05, 'epoch': 0.4}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.043386634439229965, 'eval_supp_data_loss_lm': 0.36915454268455505, 'eval_loss': 0.4138941168785095, 'eval_runtime': 5.6628, 'eval_samples_per_second': 524.475, 'eval_steps_per_second': 4.238, 'epoch': 0.4}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Consider]\u001b[0m\u001b[32;1mations\u001b[0m\u001b[31;1m of[regarding]\u001b[0m\u001b[31;1m the[treatment]\u001b[0m\u001b[31;1m of[efficiency]\u001b[0m\u001b[31;1m of[,]\u001b[0m\u001b[31;1m treatment[diss]\u001b[0m\u001b[31;1mociation[oci]\u001b[0m\u001b[32;1mative\u001b[0m\u001b[31;1m effects[parts]\u001b[0m\u001b[31;1m of[and]\u001b[0m\u001b[31;1m clinical[diss]\u001b[0m\u001b[31;1mociation[oci]\u001b[0m\u001b[32;1mative\u001b[0m\u001b[31;1m effects[am]\u001b[0m\u001b[31;1myl[nesia]\u001b[0m\u001b[31;1m in[for]\u001b[0m\u001b[31;1m patients[Hunt]\u001b[0m\u001b[31;1m syndrome[j]\u001b[0m\u001b[31;1mö[ens]\u001b[0m\u001b[31;1m syndrome[et]\u001b[0m\u001b[32;1m al\u001b[0m\u001b[32;1m.\u001b[0m\u001b[31;1m A[�]\u001b[0m\u001b[32;1m�\u001b[0m\u001b[32;1ms\u001b[0m\u001b[31;1m �[Sche]\u001b[0m\u001b[31;1mng[ma]\u001b[0m\u001b[31;1m ([Therapy]\u001b[0m\u001b[31;1m ([for]\u001b[0m\u001b[31;1m Alzheimer[Diss]\u001b[0m\u001b[31;1mociation[oci]\u001b[0m\u001b[32;1mative\u001b[0m\u001b[31;1m Diseases[Identity]\u001b[0m\u001b[32;1m Disorder\u001b[0m\u001b[31;1m ([</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-3000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7738, 'learning_rate': 2.9491929081767666e-05, 'epoch': 0.41}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.0363537073135376, 'eval_supp_data_loss_lm': 0.3678407371044159, 'eval_loss': 0.40538638830184937, 'eval_runtime': 5.5842, 'eval_samples_per_second': 531.855, 'eval_steps_per_second': 4.298, 'epoch': 0.41}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Correction]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m A[f]\u001b[0m\u001b[31;1mMRI[Mi]\u001b[0m\u001b[31;1mR[RNA]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1m5[192]\u001b[0m\u001b[31;1m-[and]\u001b[0m\u001b[32;1m mi\u001b[0m\u001b[32;1mRNA\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1m146[204]\u001b[0m\u001b[31;1m are[Direct]\u001b[0m\u001b[32;1mly\u001b[0m\u001b[31;1m Reg[Supp]\u001b[0m\u001b[31;1mresses[ress]\u001b[0m\u001b[31;1m the[l]\u001b[0m\u001b[32;1mnc\u001b[0m\u001b[32;1mRNA\u001b[0m\u001b[31;1m-[H]\u001b[0m\u001b[31;1meter[OTT]\u001b[0m\u001b[31;1m-[IP]\u001b[0m\u001b[31;1m1[and]\u001b[0m\u001b[31;1m Prom[Inter]\u001b[0m\u001b[31;1macts[rupt]\u001b[0m\u001b[31;1ms[G]\u001b[0m\u001b[31;1mSK[LS]\u001b[0m\u001b[32;1m1\u001b[0m\u001b[31;1m Expression[-]\u001b[0m\u001b[32;1mMed\u001b[0m\u001b[32;1miated\u001b[0m\u001b[31;1m Ap[Gl]\u001b[0m\u001b[31;1muc[ut]\u001b[0m\u001b[31;1math[am]\u001b[0m\u001b[31;1mater[ino]\u001b[0m\u001b[32;1mly\u001b[0m\u001b[32;1msis\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m Human[Hep]\u001b[0m\u001b[32;1mato\u001b[0m\u001b[32;1mcell\u001b[0m\u001b[32;1mular\u001b[0m\u001b[32;1m Car\u001b[0m\u001b[32;1mcin\u001b[0m\u001b[32;1moma\u001b[0m\u001b[31;1m Cells[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7532, 'learning_rate': 2.8830378406985976e-05, 'epoch': 0.42}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.04331038519740105, 'eval_supp_data_loss_lm': 0.36662086844444275, 'eval_loss': 0.41124922037124634, 'eval_runtime': 5.6263, 'eval_samples_per_second': 527.873, 'eval_steps_per_second': 4.266, 'epoch': 0.42}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[32;1mThe\u001b[0m\u001b[31;1m Effect[association]\u001b[0m\u001b[32;1m between\u001b[0m\u001b[31;1m the[time]\u001b[0m\u001b[31;1m of[to]\u001b[0m\u001b[31;1m life[antibiotics]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m the[relevant]\u001b[0m\u001b[31;1m risk[clinical]\u001b[0m\u001b[32;1m outcomes\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m patients[emergency]\u001b[0m\u001b[32;1m department\u001b[0m\u001b[32;1m patients\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m type[various]\u001b[0m\u001b[31;1m disease[stages]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m renal[se]\u001b[0m\u001b[32;1mps\u001b[0m\u001b[32;1mis\u001b[0m\u001b[31;1m</s>[:]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m retrospective[prospective]\u001b[0m\u001b[31;1m cohort[multi]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mcenter\u001b[0m\u001b[32;1m study\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.737, 'learning_rate': 2.816882773220429e-05, 'epoch': 0.44}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.039946477860212326, 'eval_supp_data_loss_lm': 0.3653295934200287, 'eval_loss': 0.4065241515636444, 'eval_runtime': 5.5342, 'eval_samples_per_second': 536.664, 'eval_steps_per_second': 4.337, 'epoch': 0.44}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Vari]\u001b[0m\u001b[31;1mation[ations]\u001b[0m\u001b[31;1m in[of]\u001b[0m\u001b[31;1m the[Essential]\u001b[0m\u001b[32;1m Oil\u001b[0m\u001b[31;1m and[Const]\u001b[0m\u001b[32;1mitu\u001b[0m\u001b[32;1ments\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[Ore]\u001b[0m\u001b[31;1moch[gan]\u001b[0m\u001b[32;1mo\u001b[0m\u001b[32;1m (\u001b[0m\u001b[31;1mL[Orig]\u001b[0m\u001b[31;1mina[an]\u001b[0m\u001b[31;1mthus[um]\u001b[0m\u001b[31;1m aest[vul]\u001b[0m\u001b[32;1mg\u001b[0m\u001b[32;1mare\u001b[0m\u001b[31;1m L[sub]\u001b[0m\u001b[32;1msp\u001b[0m\u001b[32;1m.\u001b[0m\u001b[31;1m n[vir]\u001b[0m\u001b[31;1mg[id]\u001b[0m\u001b[31;1mum[ulum]\u001b[0m\u001b[31;1m)[(=]\u001b[0m\u001b[31;1m L[O]\u001b[0m\u001b[31;1mry[.]\u001b[0m\u001b[31;1m l[her]\u001b[0m\u001b[31;1mn[acle]\u001b[0m\u001b[31;1mae[otic]\u001b[0m\u001b[31;1mus[um]\u001b[0m\u001b[32;1m)\u001b[0m\u001b[31;1m and[over]\u001b[0m\u001b[31;1m the[Cult]\u001b[0m\u001b[31;1mured[ivation]\u001b[0m\u001b[31;1m and[Cy]\u001b[0m\u001b[31;1mt[cles]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7212, 'learning_rate': 2.7507277057422597e-05, 'epoch': 0.45}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.04147766903042793, 'eval_supp_data_loss_lm': 0.3639678955078125, 'eval_loss': 0.406694620847702, 'eval_runtime': 5.4184, 'eval_samples_per_second': 548.13, 'eval_steps_per_second': 4.429, 'epoch': 0.45}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[I]\u001b[0m\u001b[31;1mon[ne]\u001b[0m\u001b[31;1mur[ffect]\u001b[0m\u001b[31;1mive[iveness]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[lateral]\u001b[0m\u001b[31;1m thor[-]\u001b[0m\u001b[31;1minf[w]\u001b[0m\u001b[31;1malled[edge]\u001b[0m\u001b[31;1m ultrasound[ins]\u001b[0m\u001b[31;1muff[oles]\u001b[0m\u001b[31;1m in[on]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m treatment[improvement]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[pain]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m pain[function]\u001b[0m\u001b[31;1m in[for]\u001b[0m\u001b[31;1m patients[medial]\u001b[0m\u001b[31;1m vent[knee]\u001b[0m\u001b[32;1m oste\u001b[0m\u001b[32;1mo\u001b[0m\u001b[32;1marth\u001b[0m\u001b[32;1mritis\u001b[0m\u001b[32;1m:\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m systematic[meta]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1manalysis\u001b[0m\u001b[31;1m</s>[of]\u001b[0m\u001b[31;1m randomized[controlled]\u001b[0m\u001b[31;1m trials[randomized]\u001b[0m\u001b[31;1m controlled[trials]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.7136, 'learning_rate': 2.684572638264091e-05, 'epoch': 0.46}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.04231758043169975, 'eval_supp_data_loss_lm': 0.36263203620910645, 'eval_loss': 0.40628623962402344, 'eval_runtime': 5.613, 'eval_samples_per_second': 529.125, 'eval_steps_per_second': 4.276, 'epoch': 0.46}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Sec]\u001b[0m\u001b[31;1mular[rets]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m �[Sea]\u001b[0m\u001b[31;1m-[Ur]\u001b[0m\u001b[31;1minary[chin]\u001b[0m\u001b[31;1m ([Sp]\u001b[0m\u001b[31;1mine[ic]\u001b[0m\u001b[31;1mill[ule]\u001b[0m\u001b[31;1m:[Reve]\u001b[0m\u001b[31;1mals[aled]\u001b[0m\u001b[31;1m by[:]\u001b[0m\u001b[31;1m A[Protein]\u001b[0m\u001b[31;1m-[Cooper]\u001b[0m\u001b[31;1mations[ativity]\u001b[0m\u001b[31;1m and[Is]\u001b[0m\u001b[31;1m Associated[Respons]\u001b[0m\u001b[32;1mible\u001b[0m\u001b[32;1m for\u001b[0m\u001b[31;1m the[ACC]\u001b[0m\u001b[31;1m-[Transformation]\u001b[0m\u001b[31;1m in[,]\u001b[0m\u001b[31;1m and[Int]\u001b[0m\u001b[31;1mestinal[rac]\u001b[0m\u001b[31;1mran[ry]\u001b[0m\u001b[31;1mlate[stall]\u001b[0m\u001b[31;1mization[ine]\u001b[0m\u001b[31;1m Ox[Inc]\u001b[0m\u001b[32;1morpor\u001b[0m\u001b[32;1mation\u001b[0m\u001b[32;1m,\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m Ant[Gu]\u001b[0m\u001b[32;1mided\u001b[0m\u001b[31;1m by[Mineral]\u001b[0m\u001b[31;1mization[Part]\u001b[0m\u001b[32;1micle\u001b[0m\u001b[31;1m Formation[Assembly]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m the[Bi]\u001b[0m\u001b[31;1mom[ocom]\u001b[0m\u001b[32;1mpos\u001b[0m\u001b[31;1mites[ite]\u001b[0m\u001b[31;1m</s>[Material]\u001b[0m\u001b[31;1m</s>[Formation]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-3500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-1000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6999, 'learning_rate': 2.618417570785922e-05, 'epoch': 0.48}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.032561708241701126, 'eval_supp_data_loss_lm': 0.36139702796936035, 'eval_loss': 0.3950004577636719, 'eval_runtime': 5.6812, 'eval_samples_per_second': 522.776, 'eval_steps_per_second': 4.224, 'epoch': 0.48}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Sub]\u001b[0m\u001b[31;1mclinical[ac]\u001b[0m\u001b[32;1mute\u001b[0m\u001b[31;1m and[Thy]\u001b[0m\u001b[32;1mroid\u001b[0m\u001b[31;1mectomy[itis]\u001b[0m\u001b[31;1m in[is]\u001b[0m\u001b[32;1m Associated\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m Increased[H]\u001b[0m\u001b[31;1meter[LA]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1m1[B]\u001b[0m\u001b[31;1m1[*]\u001b[0m\u001b[31;1mA[18]\u001b[0m\u001b[31;1m and[:]\u001b[0m\u001b[31;1m A[01]\u001b[0m\u001b[31;1m-[,]\u001b[0m\u001b[31;1m a[-]\u001b[0m\u001b[31;1m18[DR]\u001b[0m\u001b[32;1mB\u001b[0m\u001b[32;1m1\u001b[0m\u001b[31;1m,[*]\u001b[0m\u001b[31;1m and[01]\u001b[0m\u001b[31;1m,[and]\u001b[0m\u001b[32;1m -\u001b[0m\u001b[31;1m10[C]\u001b[0m\u001b[31;1mX[*]\u001b[0m\u001b[31;1m00[04]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m11[01]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mD[The]\u001b[0m\u001b[31;1m Role[Sign]\u001b[0m\u001b[32;1mific\u001b[0m\u001b[32;1mance\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m H[New]\u001b[0m\u001b[31;1m Ins[Molecular]\u001b[0m\u001b[31;1m Network[Background]\u001b[0m\u001b[31;1m of[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6885, 'learning_rate': 2.5522625033077535e-05, 'epoch': 0.49}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.027882931753993034, 'eval_supp_data_loss_lm': 0.3604024350643158, 'eval_loss': 0.3891984224319458, 'eval_runtime': 5.7338, 'eval_samples_per_second': 517.978, 'eval_steps_per_second': 4.186, 'epoch': 0.49}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[R]\u001b[0m\u001b[31;1misk[ational]\u001b[0m\u001b[32;1me\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m design[study]\u001b[0m\u001b[31;1m protocol[design]\u001b[0m\u001b[31;1m of[for]\u001b[0m\u001b[31;1m a[one]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1myear[stop]\u001b[0m\u001b[31;1m random[assessment]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[renal]\u001b[0m\u001b[31;1m function[artery]\u001b[0m\u001b[31;1m bypass[sten]\u001b[0m\u001b[32;1mosis\u001b[0m\u001b[31;1m in[and]\u001b[0m\u001b[31;1m its[renal]\u001b[0m\u001b[31;1m function[micro]\u001b[0m\u001b[32;1mv\u001b[0m\u001b[32;1mascular\u001b[0m\u001b[31;1m endot[perf]\u001b[0m\u001b[32;1musion\u001b[0m\u001b[31;1m in[with]\u001b[0m\u001b[31;1m a[contrast]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1menh\u001b[0m\u001b[32;1manced\u001b[0m\u001b[31;1m radi[ultrasound]\u001b[0m\u001b[31;1m</s>[for]\u001b[0m\u001b[31;1m the[patients]\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m advanced[suspected]\u001b[0m\u001b[31;1m acute[renov]\u001b[0m\u001b[31;1mative[ascular]\u001b[0m\u001b[31;1mization[hypertension]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6577, 'learning_rate': 2.4861074358295845e-05, 'epoch': 0.5}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.021216275170445442, 'eval_supp_data_loss_lm': 0.3594028055667877, 'eval_loss': 0.3813721239566803, 'eval_runtime': 5.6371, 'eval_samples_per_second': 526.868, 'eval_steps_per_second': 4.258, 'epoch': 0.5}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[S]\u001b[0m\u001b[31;1must[ero]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mtem[ident]\u001b[0m\u001b[31;1mical[ification]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[the]\u001b[0m\u001b[31;1m novel[a]\u001b[0m\u001b[31;1mort[et]\u001b[0m\u001b[31;1miology[i]\u001b[0m\u001b[31;1mogenic[ologies]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[human]\u001b[0m\u001b[31;1m pap[malaria]\u001b[0m\u001b[31;1m virus[exposure]\u001b[0m\u001b[31;1m and[(]\u001b[0m\u001b[31;1mH[Pl]\u001b[0m\u001b[32;1mas\u001b[0m\u001b[32;1mmod\u001b[0m\u001b[32;1mium\u001b[0m\u001b[31;1m fal[s]\u001b[0m\u001b[32;1mpp\u001b[0m\u001b[32;1m.)\u001b[0m\u001b[31;1m and[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m United[Lim]\u001b[0m\u001b[31;1mb[u]\u001b[0m\u001b[31;1m,[K]\u001b[0m\u001b[31;1mwa[oss]\u001b[0m\u001b[31;1mu[a]\u001b[0m\u001b[31;1m region[District]\u001b[0m\u001b[31;1m,[of]\u001b[0m\u001b[31;1m China[Jim]\u001b[0m\u001b[32;1mma\u001b[0m\u001b[31;1m,[Zone]\u001b[0m\u001b[32;1m,\u001b[0m\u001b[31;1m Ethiopia[South]\u001b[0m\u001b[31;1m Africa[western]\u001b[0m\u001b[32;1m Ethiopia\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6335, 'learning_rate': 2.419952368351416e-05, 'epoch': 0.52}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.02769063599407673, 'eval_supp_data_loss_lm': 0.3584207594394684, 'eval_loss': 0.38705262541770935, 'eval_runtime': 5.6016, 'eval_samples_per_second': 530.205, 'eval_steps_per_second': 4.284, 'epoch': 0.52}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Pred]\u001b[0m\u001b[32;1miction\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[30]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mday\u001b[0m\u001b[31;1m mortality[pediatric]\u001b[0m\u001b[31;1m mortality[un]\u001b[0m\u001b[31;1mmet[planned]\u001b[0m\u001b[32;1m hospital\u001b[0m\u001b[31;1m stay[izations]\u001b[0m\u001b[31;1m in[using]\u001b[0m\u001b[31;1m a[the]\u001b[0m\u001b[31;1m first[Johns]\u001b[0m\u001b[31;1mful[Hopkins]\u001b[0m\u001b[31;1m Medical[Adjusted]\u001b[0m\u001b[31;1m Card[Clinical]\u001b[0m\u001b[31;1m Out[Groups]\u001b[0m\u001b[31;1m ([risk]\u001b[0m\u001b[31;1m score[adjustment]\u001b[0m\u001b[31;1m questionnaire[system]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6232, 'learning_rate': 2.353797300873247e-05, 'epoch': 0.53}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.022430196404457092, 'eval_supp_data_loss_lm': 0.3573106527328491, 'eval_loss': 0.38055309653282166, 'eval_runtime': 5.4728, 'eval_samples_per_second': 542.679, 'eval_steps_per_second': 4.385, 'epoch': 0.53}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Primary]\u001b[0m\u001b[31;1m and[Should]\u001b[0m\u001b[32;1mer\u001b[0m\u001b[32;1m Ar\u001b[0m\u001b[32;1mthro\u001b[0m\u001b[32;1mpl\u001b[0m\u001b[32;1masty\u001b[0m\u001b[31;1m for[Versus]\u001b[0m\u001b[31;1m Int[Conservative]\u001b[0m\u001b[31;1m Surgery[Treatment]\u001b[0m\u001b[32;1m for\u001b[0m\u001b[31;1m Ac[Com]\u001b[0m\u001b[31;1mor[min]\u001b[0m\u001b[31;1meral[uted]\u001b[0m\u001b[31;1m Cor[Pro]\u001b[0m\u001b[31;1mstate[x]\u001b[0m\u001b[32;1mimal\u001b[0m\u001b[31;1m L[Hum]\u001b[0m\u001b[31;1moral[eral]\u001b[0m\u001b[31;1m Ar[Fract]\u001b[0m\u001b[31;1mure[ures]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[32;1m A\u001b[0m\u001b[31;1m Retro[System]\u001b[0m\u001b[32;1matic\u001b[0m\u001b[31;1m Review[Literature]\u001b[0m\u001b[32;1m Review\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-4000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-1500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6125, 'learning_rate': 2.287642233395078e-05, 'epoch': 0.54}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.02574644424021244, 'eval_supp_data_loss_lm': 0.35653021931648254, 'eval_loss': 0.3832088112831116, 'eval_runtime': 5.6862, 'eval_samples_per_second': 522.317, 'eval_steps_per_second': 4.221, 'epoch': 0.54}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[C]\u001b[0m\u001b[31;1mognitive[ave]\u001b[0m\u001b[32;1molin\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1m1\u001b[0m\u001b[31;1m-[-]\u001b[0m\u001b[32;1m A\u001b[0m\u001b[32;1m Novel\u001b[0m\u001b[31;1m Ant[Inter]\u001b[0m\u001b[31;1maction[acting]\u001b[0m\u001b[31;1m Protein[Partner]\u001b[0m\u001b[31;1m with[of]\u001b[0m\u001b[31;1m the[Organic]\u001b[0m\u001b[31;1m Comp[C]\u001b[0m\u001b[32;1mation\u001b[0m\u001b[31;1mic[/]\u001b[0m\u001b[31;1mPoly[C]\u001b[0m\u001b[31;1mou[arn]\u001b[0m\u001b[32;1mit\u001b[0m\u001b[32;1mine\u001b[0m\u001b[31;1m and[Trans]\u001b[0m\u001b[32;1mporter\u001b[0m\u001b[31;1m 1[(]\u001b[0m\u001b[31;1mC[Oct]\u001b[0m\u001b[31;1m2[n]\u001b[0m\u001b[31;1m)[2]\u001b[0m\u001b[31;1m)[):]\u001b[0m\u001b[31;1m A[Effect]\u001b[0m\u001b[31;1m on[of]\u001b[0m\u001b[31;1m the[Protein]\u001b[0m\u001b[32;1m Kin\u001b[0m\u001b[32;1mase\u001b[0m\u001b[31;1m ([C]\u001b[0m\u001b[31;1m and[on]\u001b[0m\u001b[31;1m the[This]\u001b[0m\u001b[31;1m Mechan[Inter]\u001b[0m\u001b[32;1maction\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m the[Rat]\u001b[0m\u001b[31;1m Brain[Astro]\u001b[0m\u001b[32;1mcy\u001b[0m\u001b[32;1mtes\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.6046, 'learning_rate': 2.2214871659169094e-05, 'epoch': 0.56}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.025202862918376923, 'eval_supp_data_loss_lm': 0.35520002245903015, 'eval_loss': 0.38129258155822754, 'eval_runtime': 5.4891, 'eval_samples_per_second': 541.075, 'eval_steps_per_second': 4.372, 'epoch': 0.56}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Incre]\u001b[0m\u001b[32;1masing\u001b[0m\u001b[31;1m the[Serious]\u001b[0m\u001b[31;1m Diseases[ness]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Plant]\u001b[0m\u001b[31;1m Growth[Inv]\u001b[0m\u001b[31;1molve[asions]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[Cro]\u001b[0m\u001b[31;1mhn[pl]\u001b[0m\u001b[31;1masty[ands]\u001b[0m\u001b[31;1m:[of]\u001b[0m\u001b[31;1m the[Eastern]\u001b[0m\u001b[32;1m China\u001b[0m\u001b[31;1m:[in]\u001b[0m\u001b[31;1m the[Rel]\u001b[0m\u001b[32;1mation\u001b[0m\u001b[32;1m to\u001b[0m\u001b[31;1m the[Changing]\u001b[0m\u001b[31;1m Environmental[Farming]\u001b[0m\u001b[31;1m and[Practices]\u001b[0m\u001b[31;1m</s>[:]\u001b[0m\u001b[32;1m A\u001b[0m\u001b[31;1m Cross[Case]\u001b[0m\u001b[32;1m Study\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5961, 'learning_rate': 2.1553320984387404e-05, 'epoch': 0.57}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.022854924201965332, 'eval_supp_data_loss_lm': 0.35509398579597473, 'eval_loss': 0.37880855798721313, 'eval_runtime': 5.628, 'eval_samples_per_second': 527.721, 'eval_steps_per_second': 4.264, 'epoch': 0.57}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Vari]\u001b[0m\u001b[31;1mation[ations]\u001b[0m\u001b[31;1m in[of]\u001b[0m\u001b[31;1m the[Essential]\u001b[0m\u001b[32;1m Oil\u001b[0m\u001b[31;1m and[Const]\u001b[0m\u001b[32;1mitu\u001b[0m\u001b[32;1ments\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[Ore]\u001b[0m\u001b[31;1moch[gan]\u001b[0m\u001b[32;1mo\u001b[0m\u001b[32;1m (\u001b[0m\u001b[31;1mL[Orig]\u001b[0m\u001b[31;1mina[an]\u001b[0m\u001b[31;1mthus[um]\u001b[0m\u001b[31;1m aest[vul]\u001b[0m\u001b[32;1mg\u001b[0m\u001b[32;1mare\u001b[0m\u001b[31;1m L[sub]\u001b[0m\u001b[32;1msp\u001b[0m\u001b[32;1m.\u001b[0m\u001b[31;1m n[vir]\u001b[0m\u001b[31;1mg[id]\u001b[0m\u001b[31;1mum[ulum]\u001b[0m\u001b[31;1m L[(=]\u001b[0m\u001b[31;1m L[O]\u001b[0m\u001b[31;1mry[.]\u001b[0m\u001b[31;1m sp[her]\u001b[0m\u001b[31;1mnia[acle]\u001b[0m\u001b[31;1mum[otic]\u001b[0m\u001b[31;1mus[um]\u001b[0m\u001b[32;1m)\u001b[0m\u001b[31;1m and[over]\u001b[0m\u001b[31;1m the[Cult]\u001b[0m\u001b[31;1mured[ivation]\u001b[0m\u001b[31;1m and[Cy]\u001b[0m\u001b[31;1mt[cles]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5891, 'learning_rate': 2.0891770309605714e-05, 'epoch': 0.58}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.019005203619599342, 'eval_supp_data_loss_lm': 0.3539273738861084, 'eval_loss': 0.37368693947792053, 'eval_runtime': 5.5509, 'eval_samples_per_second': 535.05, 'eval_steps_per_second': 4.324, 'epoch': 0.58}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Cl]\u001b[0m\u001b[32;1minical\u001b[0m\u001b[31;1m and[practice]\u001b[0m\u001b[31;1m and[guidelines]\u001b[0m\u001b[32;1m for\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m management[surgical]\u001b[0m\u001b[32;1m management\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m patients[colon]\u001b[0m\u001b[32;1m cancer\u001b[0m\u001b[32;1m:\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m systematic[consensus]\u001b[0m\u001b[32;1m statement\u001b[0m\u001b[31;1m from[of]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m American[Hell]\u001b[0m\u001b[31;1men[enic]\u001b[0m\u001b[31;1m Society[and]\u001b[0m\u001b[31;1m European[Cy]\u001b[0m\u001b[31;1mstic[pri]\u001b[0m\u001b[31;1mo[ot]\u001b[0m\u001b[31;1m Society[Col]\u001b[0m\u001b[32;1more\u001b[0m\u001b[32;1mct\u001b[0m\u001b[32;1mal\u001b[0m\u001b[32;1m Cancer\u001b[0m\u001b[31;1m Society[Study]\u001b[0m\u001b[31;1m</s>[Group]\u001b[0m\u001b[31;1m</s>[by]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m Society[He]\u001b[0m\u001b[31;1mLa[S]\u001b[0m\u001b[31;1m-[MO]\u001b[0m\u001b[31;1m-[*]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.581, 'learning_rate': 2.0230219634824028e-05, 'epoch': 0.6}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.016227416694164276, 'eval_supp_data_loss_lm': 0.35305333137512207, 'eval_loss': 0.3699134886264801, 'eval_runtime': 5.6515, 'eval_samples_per_second': 525.521, 'eval_steps_per_second': 4.247, 'epoch': 0.6}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Evidence]\u001b[0m\u001b[32;1m for\u001b[0m\u001b[31;1m the[Phen]\u001b[0m\u001b[31;1molic[otyp]\u001b[0m\u001b[32;1mic\u001b[0m\u001b[31;1m and[Plastic]\u001b[0m\u001b[32;1mity\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[Agg]\u001b[0m\u001b[31;1mreg[ressive]\u001b[0m\u001b[31;1m and[Triple]\u001b[0m\u001b[31;1m Negative[-]\u001b[0m\u001b[32;1mNeg\u001b[0m\u001b[32;1mative\u001b[0m\u001b[32;1m Breast\u001b[0m\u001b[32;1m Cancer\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m A[Human]\u001b[0m\u001b[31;1m Immun[Biology]\u001b[0m\u001b[31;1m and[Is]\u001b[0m\u001b[31;1m a[Recap]\u001b[0m\u001b[32;1mit\u001b[0m\u001b[32;1mulated\u001b[0m\u001b[32;1m by\u001b[0m\u001b[31;1m the[a]\u001b[0m\u001b[32;1m Novel\u001b[0m\u001b[32;1m Model\u001b[0m\u001b[31;1m</s>[System]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-4500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-2000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5756, 'learning_rate': 1.9568668960042342e-05, 'epoch': 0.61}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.018505625426769257, 'eval_supp_data_loss_lm': 0.3525632917881012, 'eval_loss': 0.37179839611053467, 'eval_runtime': 5.5539, 'eval_samples_per_second': 534.755, 'eval_steps_per_second': 4.321, 'epoch': 0.61}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[End]\u001b[0m\u001b[31;1moscopic[ogenous]\u001b[0m\u001b[31;1m and[insulin]\u001b[0m\u001b[31;1m resistance[secretion]\u001b[0m\u001b[31;1m in[even]\u001b[0m\u001b[31;1m in[at]\u001b[0m\u001b[31;1m the[a]\u001b[0m\u001b[31;1m high[very]\u001b[0m\u001b[32;1m low\u001b[0m\u001b[31;1m risk[level]\u001b[0m\u001b[31;1m is[contributes]\u001b[0m\u001b[32;1m to\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m development[stability]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[blood]\u001b[0m\u001b[31;1m pressure[glucose]\u001b[0m\u001b[31;1m in[control]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m rats[ful]\u001b[0m\u001b[32;1mmin\u001b[0m\u001b[32;1mant\u001b[0m\u001b[31;1m rats[type]\u001b[0m\u001b[31;1m 2[1]\u001b[0m\u001b[31;1m diabetic[diabetes]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5684, 'learning_rate': 1.8907118285260652e-05, 'epoch': 0.62}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.01721191219985485, 'eval_supp_data_loss_lm': 0.35168394446372986, 'eval_loss': 0.3695942461490631, 'eval_runtime': 5.4479, 'eval_samples_per_second': 545.159, 'eval_steps_per_second': 4.405, 'epoch': 0.62}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[L]\u001b[0m\u001b[31;1moss[ateral]\u001b[0m\u001b[31;1m and[K]\u001b[0m\u001b[32;1mnee\u001b[0m\u001b[31;1m Ar[Pain]\u001b[0m\u001b[31;1m in[after]\u001b[0m\u001b[31;1m Total[Outside]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mof[in]\u001b[0m\u001b[31;1m Surgery[Anat]\u001b[0m\u001b[31;1momy[omic]\u001b[0m\u001b[31;1m Surgery[Double]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mBl[B]\u001b[0m\u001b[32;1mundle\u001b[0m\u001b[31;1m Surgery[An]\u001b[0m\u001b[32;1mterior\u001b[0m\u001b[32;1m Cru\u001b[0m\u001b[32;1mci\u001b[0m\u001b[32;1mate\u001b[0m\u001b[32;1m L\u001b[0m\u001b[32;1mig\u001b[0m\u001b[32;1mament\u001b[0m\u001b[32;1m Reconstruction\u001b[0m\u001b[31;1m:[Using]\u001b[0m\u001b[31;1m a[the]\u001b[0m\u001b[31;1m Poster[Tight]\u001b[0m\u001b[31;1m Junction[R]\u001b[0m\u001b[31;1misk[ope]\u001b[0m\u001b[31;1m-[RT]\u001b[0m\u001b[31;1m-[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5622, 'learning_rate': 1.8245567610478963e-05, 'epoch': 0.64}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.02021445706486702, 'eval_supp_data_loss_lm': 0.35102733969688416, 'eval_loss': 0.37201350927352905, 'eval_runtime': 5.7212, 'eval_samples_per_second': 519.124, 'eval_steps_per_second': 4.195, 'epoch': 0.64}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[T]\u001b[0m\u001b[31;1mreatment[ACC]\u001b[0m\u001b[31;1m-[3]\u001b[0m\u001b[31;1m-[is]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m novel[micro]\u001b[0m\u001b[31;1mRNA[tub]\u001b[0m\u001b[32;1mule\u001b[0m\u001b[31;1m-[plus]\u001b[0m\u001b[31;1m protein[end]\u001b[0m\u001b[31;1mopl[-]\u001b[0m\u001b[31;1mstage[tracking]\u001b[0m\u001b[32;1m protein\u001b[0m\u001b[32;1m that\u001b[0m\u001b[32;1m promotes\u001b[0m\u001b[31;1m the[ax]\u001b[0m\u001b[31;1monal[on]\u001b[0m\u001b[31;1m formation[elong]\u001b[0m\u001b[32;1mation\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m migration[also]\u001b[0m\u001b[31;1m inhibits[regulates]\u001b[0m\u001b[31;1m the[micro]\u001b[0m\u001b[31;1mgl[tub]\u001b[0m\u001b[32;1mule\u001b[0m\u001b[31;1m-[plus]\u001b[0m\u001b[31;1m cell[end]\u001b[0m\u001b[31;1m-[dynamics]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[31;1m human[multiple]\u001b[0m\u001b[31;1m my[embryonic]\u001b[0m\u001b[31;1m stem[cell]\u001b[0m\u001b[31;1m lines[types]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5566, 'learning_rate': 1.7584016935697276e-05, 'epoch': 0.65}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.016418354585766792, 'eval_supp_data_loss_lm': 0.3504890501499176, 'eval_loss': 0.3675645589828491, 'eval_runtime': 5.6926, 'eval_samples_per_second': 521.729, 'eval_steps_per_second': 4.216, 'epoch': 0.65}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Mult]\u001b[0m\u001b[31;1mid[ivariate]\u001b[0m\u001b[31;1m Analysis[Gen]\u001b[0m\u001b[31;1momics[ome]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mWide\u001b[0m\u001b[31;1m Analysis[Association]\u001b[0m\u001b[31;1m Study[An]\u001b[0m\u001b[32;1malyses\u001b[0m\u001b[32;1m Reve\u001b[0m\u001b[32;1mal\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m Role[Genetic]\u001b[0m\u001b[31;1m Diversity[Bas]\u001b[0m\u001b[32;1mis\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Seed]\u001b[0m\u001b[31;1mling[Fat]\u001b[0m\u001b[32;1mty\u001b[0m\u001b[32;1m Acid\u001b[0m\u001b[31;1m Production[Com]\u001b[0m\u001b[32;1mposition\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[O]\u001b[0m\u001b[31;1mry[at]\u001b[0m\u001b[31;1m-[(]\u001b[0m\u001b[31;1mL[A]\u001b[0m\u001b[31;1mry[ven]\u001b[0m\u001b[32;1ma\u001b[0m\u001b[32;1m sat\u001b[0m\u001b[32;1miva\u001b[0m\u001b[32;1m L\u001b[0m\u001b[32;1m.)\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5525, 'learning_rate': 1.6922466260915587e-05, 'epoch': 0.66}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.012365289032459259, 'eval_supp_data_loss_lm': 0.3498590886592865, 'eval_loss': 0.36279717087745667, 'eval_runtime': 5.6129, 'eval_samples_per_second': 529.137, 'eval_steps_per_second': 4.276, 'epoch': 0.66}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[S]\u001b[0m\u001b[31;1murgical[ero]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1m and[ident]\u001b[0m\u001b[31;1mical[ification]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[the]\u001b[0m\u001b[31;1m novel[a]\u001b[0m\u001b[31;1mry[et]\u001b[0m\u001b[31;1miology[i]\u001b[0m\u001b[31;1mogenic[ologies]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[human]\u001b[0m\u001b[31;1m pap[malaria]\u001b[0m\u001b[31;1m virus[exposure]\u001b[0m\u001b[31;1m and[(]\u001b[0m\u001b[31;1mH[Pl]\u001b[0m\u001b[32;1mas\u001b[0m\u001b[32;1mmod\u001b[0m\u001b[32;1mium\u001b[0m\u001b[31;1m fal[s]\u001b[0m\u001b[32;1mpp\u001b[0m\u001b[32;1m.)\u001b[0m\u001b[31;1m and[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m United[Lim]\u001b[0m\u001b[31;1mb[u]\u001b[0m\u001b[31;1m Province[K]\u001b[0m\u001b[31;1mwa[oss]\u001b[0m\u001b[32;1ma\u001b[0m\u001b[31;1m region[District]\u001b[0m\u001b[31;1m,[of]\u001b[0m\u001b[31;1m China[Jim]\u001b[0m\u001b[32;1mma\u001b[0m\u001b[31;1m,[Zone]\u001b[0m\u001b[32;1m,\u001b[0m\u001b[31;1m Ethiopia[South]\u001b[0m\u001b[31;1m Ethiopia[western]\u001b[0m\u001b[32;1m Ethiopia\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-5000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-2500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.545, 'learning_rate': 1.6260915586133897e-05, 'epoch': 0.67}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.014474832452833652, 'eval_supp_data_loss_lm': 0.34926021099090576, 'eval_loss': 0.3643675148487091, 'eval_runtime': 5.611, 'eval_samples_per_second': 529.316, 'eval_steps_per_second': 4.277, 'epoch': 0.67}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Sub]\u001b[0m\u001b[31;1mclinical[ac]\u001b[0m\u001b[32;1mute\u001b[0m\u001b[31;1m and[Thy]\u001b[0m\u001b[32;1mroid\u001b[0m\u001b[31;1mectomy[itis]\u001b[0m\u001b[31;1m in[is]\u001b[0m\u001b[32;1m Associated\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m Increased[H]\u001b[0m\u001b[31;1meter[LA]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mB\u001b[0m\u001b[31;1m1[*]\u001b[0m\u001b[31;1mA[18]\u001b[0m\u001b[31;1m and[:]\u001b[0m\u001b[31;1m A[01]\u001b[0m\u001b[31;1m-[,]\u001b[0m\u001b[31;1m a[-]\u001b[0m\u001b[31;1m18[DR]\u001b[0m\u001b[32;1mB\u001b[0m\u001b[32;1m1\u001b[0m\u001b[31;1m,[*]\u001b[0m\u001b[31;1m11[01]\u001b[0m\u001b[31;1m,[and]\u001b[0m\u001b[32;1m -\u001b[0m\u001b[31;1m1[C]\u001b[0m\u001b[31;1m>[*]\u001b[0m\u001b[31;1m12[04]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m11[01]\u001b[0m\u001b[31;1m,[-]\u001b[0m\u001b[31;1m3[The]\u001b[0m\u001b[31;1m Role[Sign]\u001b[0m\u001b[32;1mific\u001b[0m\u001b[32;1mance\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m N[New]\u001b[0m\u001b[31;1m Ins[Molecular]\u001b[0m\u001b[31;1m Mechan[Background]\u001b[0m\u001b[31;1m of[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5401, 'learning_rate': 1.559936491135221e-05, 'epoch': 0.69}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.013575717806816101, 'eval_supp_data_loss_lm': 0.3486480712890625, 'eval_loss': 0.362848699092865, 'eval_runtime': 5.6756, 'eval_samples_per_second': 523.296, 'eval_steps_per_second': 4.229, 'epoch': 0.69}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Compar]\u001b[0m\u001b[32;1mison\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Ex]\u001b[0m\u001b[31;1mogenous[isting]\u001b[0m\u001b[31;1m and[Clinical]\u001b[0m\u001b[31;1m Trials[Sc]\u001b[0m\u001b[31;1males[oring]\u001b[0m\u001b[31;1m Methods[Systems]\u001b[0m\u001b[31;1m for[in]\u001b[0m\u001b[31;1m Patients[Predict]\u001b[0m\u001b[32;1ming\u001b[0m\u001b[31;1m the[Sever]\u001b[0m\u001b[32;1mity\u001b[0m\u001b[31;1m of[and]\u001b[0m\u001b[31;1m Mort[Pro]\u001b[0m\u001b[32;1mgn\u001b[0m\u001b[31;1mosis[oses]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m Patients[Hyper]\u001b[0m\u001b[31;1mgly[lip]\u001b[0m\u001b[32;1mid\u001b[0m\u001b[31;1memia[emic]\u001b[0m\u001b[31;1m Patients[Ac]\u001b[0m\u001b[32;1mute\u001b[0m\u001b[31;1m My[Panc]\u001b[0m\u001b[32;1mreat\u001b[0m\u001b[32;1mitis\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m Patients[Chinese]\u001b[0m\u001b[32;1m Patients\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5339, 'learning_rate': 1.4937814236570521e-05, 'epoch': 0.7}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.011377017013728619, 'eval_supp_data_loss_lm': 0.3484667241573334, 'eval_loss': 0.3604012429714203, 'eval_runtime': 5.5525, 'eval_samples_per_second': 534.892, 'eval_steps_per_second': 4.322, 'epoch': 0.7}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Struct]\u001b[0m\u001b[32;1mural\u001b[0m\u001b[31;1m and[plastic]\u001b[0m\u001b[32;1mity\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[green]\u001b[0m\u001b[31;1m tea[fluorescent]\u001b[0m\u001b[31;1m nanop[protein]\u001b[0m\u001b[31;1m-[to]\u001b[0m\u001b[31;1m identify[amino]\u001b[0m\u001b[32;1m acid\u001b[0m\u001b[31;1m-[delet]\u001b[0m\u001b[32;1mions\u001b[0m\u001b[31;1m in[and]\u001b[0m\u001b[31;1m their[flu]\u001b[0m\u001b[32;1morescence\u001b[0m\u001b[31;1m of[rescue]\u001b[0m\u001b[31;1m of[by]\u001b[0m\u001b[31;1m a[folding]\u001b[0m\u001b[31;1m of[-]\u001b[0m\u001b[31;1mbased[enh]\u001b[0m\u001b[31;1manced[ancing]\u001b[0m\u001b[31;1m micro[mutations]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5319, 'learning_rate': 1.4276263561788834e-05, 'epoch': 0.71}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.012337611056864262, 'eval_supp_data_loss_lm': 0.3478792607784271, 'eval_loss': 0.3607954680919647, 'eval_runtime': 5.6774, 'eval_samples_per_second': 523.125, 'eval_steps_per_second': 4.227, 'epoch': 0.71}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Struct]\u001b[0m\u001b[32;1mural\u001b[0m\u001b[31;1m and[plastic]\u001b[0m\u001b[32;1mity\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[green]\u001b[0m\u001b[31;1m tea[fluorescent]\u001b[0m\u001b[31;1m nanop[protein]\u001b[0m\u001b[31;1m-[to]\u001b[0m\u001b[31;1m enhance[amino]\u001b[0m\u001b[32;1m acid\u001b[0m\u001b[31;1m-[delet]\u001b[0m\u001b[32;1mions\u001b[0m\u001b[31;1m in[and]\u001b[0m\u001b[31;1m their[flu]\u001b[0m\u001b[32;1morescence\u001b[0m\u001b[31;1m of[rescue]\u001b[0m\u001b[31;1m of[by]\u001b[0m\u001b[31;1m a[folding]\u001b[0m\u001b[31;1m of[-]\u001b[0m\u001b[31;1mbased[enh]\u001b[0m\u001b[31;1manced[ancing]\u001b[0m\u001b[31;1m micro[mutations]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5274, 'learning_rate': 1.3614712887007144e-05, 'epoch': 0.73}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.010027620941400528, 'eval_supp_data_loss_lm': 0.34741392731666565, 'eval_loss': 0.3579484522342682, 'eval_runtime': 5.7855, 'eval_samples_per_second': 513.348, 'eval_steps_per_second': 4.148, 'epoch': 0.73}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Pre]\u001b[0m\u001b[32;1mval\u001b[0m\u001b[32;1mence\u001b[0m\u001b[31;1m and[,]\u001b[0m\u001b[31;1m risk[intensity]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[32;1m risk\u001b[0m\u001b[32;1m factors\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m acute[t]\u001b[0m\u001b[31;1mib[ung]\u001b[0m\u001b[31;1msten[iasis]\u001b[0m\u001b[31;1m among[in]\u001b[0m\u001b[31;1m children[Kil]\u001b[0m\u001b[32;1mifi\u001b[0m\u001b[31;1m,[County]\u001b[0m\u001b[32;1m,\u001b[0m\u001b[31;1m South[Kenya]\u001b[0m\u001b[31;1m:[II]\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m a[Results]\u001b[0m\u001b[32;1m from\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m cross[school]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mbased\u001b[0m\u001b[31;1m cross[observational]\u001b[0m\u001b[32;1m study\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-5500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-3000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5248, 'learning_rate': 1.2953162212225456e-05, 'epoch': 0.74}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.009163916110992432, 'eval_supp_data_loss_lm': 0.34711185097694397, 'eval_loss': 0.3567846417427063, 'eval_runtime': 5.5578, 'eval_samples_per_second': 534.382, 'eval_steps_per_second': 4.318, 'epoch': 0.74}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[E]\u001b[0m\u001b[32;1mval\u001b[0m\u001b[32;1muation\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[New]\u001b[0m\u001b[31;1m Ins[D]\u001b[0m\u001b[31;1mental[ih]\u001b[0m\u001b[32;1myd\u001b[0m\u001b[31;1mro[roph]\u001b[0m\u001b[31;1mosph[thal]\u001b[0m\u001b[31;1mate[azine]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mBased[App]\u001b[0m\u001b[31;1mlying[ended]\u001b[0m\u001b[31;1m Poly[2]\u001b[0m\u001b[31;1m-[,]\u001b[0m\u001b[31;1m3[4]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mD\u001b[0m\u001b[31;1mih[iam]\u001b[0m\u001b[31;1mino[in]\u001b[0m\u001b[31;1mol[op]\u001b[0m\u001b[32;1myrim\u001b[0m\u001b[31;1midine[id]\u001b[0m\u001b[32;1mines\u001b[0m\u001b[31;1m as[against]\u001b[0m\u001b[31;1m the[Bac]\u001b[0m\u001b[32;1millus\u001b[0m\u001b[31;1m subt[anth]\u001b[0m\u001b[32;1mrac\u001b[0m\u001b[32;1mis\u001b[0m\u001b[31;1m and[:]\u001b[0m\u001b[31;1m A[Improved]\u001b[0m\u001b[31;1m Ant[Synt]\u001b[0m\u001b[31;1mhesis[heses]\u001b[0m\u001b[31;1m and[Using]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m Novel[New]\u001b[0m\u001b[31;1m Poly[P]\u001b[0m\u001b[31;1morous[inc]\u001b[0m\u001b[32;1mer\u001b[0m\u001b[31;1m-[Complex]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5202, 'learning_rate': 1.2291611537443768e-05, 'epoch': 0.75}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.009637362323701382, 'eval_supp_data_loss_lm': 0.3465050756931305, 'eval_loss': 0.3566593527793884, 'eval_runtime': 5.592, 'eval_samples_per_second': 531.115, 'eval_steps_per_second': 4.292, 'epoch': 0.75}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[M]\u001b[0m\u001b[32;1mole\u001b[0m\u001b[32;1mcular\u001b[0m\u001b[31;1m characterization[evidence]\u001b[0m\u001b[31;1m for[of]\u001b[0m\u001b[31;1m the[par]\u001b[0m\u001b[31;1mathy[v]\u001b[0m\u001b[32;1mov\u001b[0m\u001b[32;1mirus\u001b[0m\u001b[31;1m infection[B]\u001b[0m\u001b[31;1m1[19]\u001b[0m\u001b[31;1m infection[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m presence[cut]\u001b[0m\u001b[32;1maneous\u001b[0m\u001b[31;1m tract[poly]\u001b[0m\u001b[31;1mcy[arter]\u001b[0m\u001b[31;1mial[itis]\u001b[0m\u001b[31;1m of[nod]\u001b[0m\u001b[31;1mule[osa]\u001b[0m\u001b[31;1m of[tissue]\u001b[0m\u001b[31;1m of[from]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[32;1m patient\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m a[par]\u001b[0m\u001b[32;1mv\u001b[0m\u001b[32;1mov\u001b[0m\u001b[32;1mirus\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1massociated\u001b[0m\u001b[31;1m pneumonia[hem]\u001b[0m\u001b[32;1moph\u001b[0m\u001b[31;1milia[ag]\u001b[0m\u001b[32;1mocy\u001b[0m\u001b[32;1mtic\u001b[0m\u001b[31;1m leukemia[syndrome]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5185, 'learning_rate': 1.163006086266208e-05, 'epoch': 0.77}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.011253145523369312, 'eval_supp_data_loss_lm': 0.3461898863315582, 'eval_loss': 0.358002632856369, 'eval_runtime': 5.6414, 'eval_samples_per_second': 526.463, 'eval_steps_per_second': 4.254, 'epoch': 0.77}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Screen]\u001b[0m\u001b[32;1ming\u001b[0m\u001b[32;1m for\u001b[0m\u001b[31;1m the[an]\u001b[0m\u001b[31;1memia[underlying]\u001b[0m\u001b[31;1m role[my]\u001b[0m\u001b[32;1mel\u001b[0m\u001b[31;1moid[op]\u001b[0m\u001b[32;1mrol\u001b[0m\u001b[32;1mifer\u001b[0m\u001b[32;1mative\u001b[0m\u001b[31;1m syndrome[ne]\u001b[0m\u001b[31;1mph[opl]\u001b[0m\u001b[32;1masm\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m a[patients]\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m advanced[th]\u001b[0m\u001b[32;1mrom\u001b[0m\u001b[32;1mb\u001b[0m\u001b[32;1mocy\u001b[0m\u001b[31;1mtop[t]\u001b[0m\u001b[31;1moma[osis]\u001b[0m\u001b[31;1m:[post]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1moperative[ind]\u001b[0m\u001b[32;1muction\u001b[0m\u001b[31;1m:[chemotherapy]\u001b[0m\u001b[31;1m:[for]\u001b[0m\u001b[31;1m advanced[acute]\u001b[0m\u001b[31;1m lymph[my]\u001b[0m\u001b[32;1mel\u001b[0m\u001b[32;1moid\u001b[0m\u001b[32;1m leukemia\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5155, 'learning_rate': 1.0968510187880392e-05, 'epoch': 0.78}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.008530760183930397, 'eval_supp_data_loss_lm': 0.3458307683467865, 'eval_loss': 0.3548477590084076, 'eval_runtime': 5.6084, 'eval_samples_per_second': 529.563, 'eval_steps_per_second': 4.279, 'epoch': 0.78}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[�]\u001b[0m\u001b[32;1m�\u001b[0m\u001b[31;1mIt[T]\u001b[0m\u001b[31;1mreatment[ape]\u001b[0m\u001b[31;1m-[dermat]\u001b[0m\u001b[31;1mitis[osc]\u001b[0m\u001b[32;1mopy\u001b[0m\u001b[32;1m�\u001b[0m\u001b[32;1m�\u001b[0m\u001b[32;1m:\u001b[0m\u001b[31;1m a[constructing]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m new[low]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[31;1mlevel[cost]\u001b[0m\u001b[31;1m,[dermat]\u001b[0m\u001b[31;1mology[oscope]\u001b[0m\u001b[31;1m for[using]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m new[mobile]\u001b[0m\u001b[32;1m phone\u001b[0m\u001b[31;1m-[,]\u001b[0m\u001b[31;1m a[immersion]\u001b[0m\u001b[31;1m,[fluid]\u001b[0m\u001b[31;1m,[and]\u001b[0m\u001b[31;1m a[transparent]\u001b[0m\u001b[31;1m-[adhesive]\u001b[0m\u001b[31;1m</s>[tape]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5116, 'learning_rate': 1.0306959513098703e-05, 'epoch': 0.79}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.009295112453401089, 'eval_supp_data_loss_lm': 0.3453930914402008, 'eval_loss': 0.3551974892616272, 'eval_runtime': 5.6516, 'eval_samples_per_second': 525.512, 'eval_steps_per_second': 4.247, 'epoch': 0.79}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Ad]\u001b[0m\u001b[31;1mherence[ren]\u001b[0m\u001b[31;1mal[omed]\u001b[0m\u001b[32;1mull\u001b[0m\u001b[32;1min\u001b[0m\u001b[31;1m-[,]\u001b[0m\u001b[31;1m a[period]\u001b[0m\u001b[32;1mont\u001b[0m\u001b[31;1mal[itis]\u001b[0m\u001b[31;1m and[,]\u001b[0m\u001b[31;1m and[diabetes]\u001b[0m\u001b[31;1m,[-]\u001b[0m\u001b[31;1mrelated[un]\u001b[0m\u001b[31;1minfect[ravel]\u001b[0m\u001b[32;1ming\u001b[0m\u001b[31;1m,[the]\u001b[0m\u001b[31;1m role[equ]\u001b[0m\u001b[31;1mine[iv]\u001b[0m\u001b[31;1miral[ocal]\u001b[0m\u001b[31;1m role[relationship]\u001b[0m\u001b[31;1m between[:]\u001b[0m\u001b[31;1m a[A]\u001b[0m\u001b[31;1m case[clinic]\u001b[0m\u001b[31;1mopath[obi]\u001b[0m\u001b[31;1mological[ochemical]\u001b[0m\u001b[31;1m study[cross]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1msectional\u001b[0m\u001b[32;1m study\u001b[0m\u001b[31;1m in[</s>]\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-6000\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-3500] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5106, 'learning_rate': 9.645408838317017e-06, 'epoch': 0.81}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.007121555507183075, 'eval_supp_data_loss_lm': 0.34507158398628235, 'eval_loss': 0.3526352345943451, 'eval_runtime': 5.5007, 'eval_samples_per_second': 539.936, 'eval_steps_per_second': 4.363, 'epoch': 0.81}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Gen]\u001b[0m\u001b[31;1metic[ome]\u001b[0m\u001b[31;1m-[wide]\u001b[0m\u001b[31;1m association[identification]\u001b[0m\u001b[31;1m of[and]\u001b[0m\u001b[31;1m expression[characterization]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[micro]\u001b[0m\u001b[31;1mRNA[s]\u001b[0m\u001b[32;1matellite\u001b[0m\u001b[32;1m markers\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m the[black]\u001b[0m\u001b[31;1m and[pepper]\u001b[0m\u001b[32;1m (\u001b[0m\u001b[31;1mC[P]\u001b[0m\u001b[31;1mrun[iper]\u001b[0m\u001b[31;1mia[n]\u001b[0m\u001b[31;1miger[igr]\u001b[0m\u001b[32;1mum\u001b[0m\u001b[31;1m L[):]\u001b[0m\u001b[31;1m a[A]\u001b[0m\u001b[31;1m new[valuable]\u001b[0m\u001b[31;1m tool[resource]\u001b[0m\u001b[32;1m for\u001b[0m\u001b[31;1m the[boosting]\u001b[0m\u001b[31;1m the[gen]\u001b[0m\u001b[31;1motyp[omics]\u001b[0m\u001b[31;1m</s>[applications]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5083, 'learning_rate': 8.983858163535327e-06, 'epoch': 0.82}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.007395031396299601, 'eval_supp_data_loss_lm': 0.34481868147850037, 'eval_loss': 0.3526866137981415, 'eval_runtime': 5.6641, 'eval_samples_per_second': 524.358, 'eval_steps_per_second': 4.237, 'epoch': 0.82}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[E]\u001b[0m\u001b[32;1mval\u001b[0m\u001b[32;1muation\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m efficacy[Clinical]\u001b[0m\u001b[31;1m Out[and]\u001b[0m\u001b[31;1m Clinical[Economic]\u001b[0m\u001b[31;1m Out[B]\u001b[0m\u001b[32;1murden\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m Infect[Poor]\u001b[0m\u001b[31;1m Out[Gly]\u001b[0m\u001b[32;1mcemic\u001b[0m\u001b[32;1m Control\u001b[0m\u001b[31;1m in[Associated]\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m the[Ther]\u001b[0m\u001b[32;1mape\u001b[0m\u001b[32;1mutic\u001b[0m\u001b[31;1m Therapy[In]\u001b[0m\u001b[31;1mject[ert]\u001b[0m\u001b[31;1mial[ia]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[32;1m Patients\u001b[0m\u001b[32;1m with\u001b[0m\u001b[32;1m Type\u001b[0m\u001b[31;1m 2[]\u001b[0m\u001b[32;1m2\u001b[0m\u001b[32;1m Diabetes\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[32;1m the\u001b[0m\u001b[32;1m United\u001b[0m\u001b[32;1m States\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5052, 'learning_rate': 8.322307488753639e-06, 'epoch': 0.83}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.0069491066969931126, 'eval_supp_data_loss_lm': 0.3446246385574341, 'eval_loss': 0.3520488142967224, 'eval_runtime': 5.6317, 'eval_samples_per_second': 527.37, 'eval_steps_per_second': 4.262, 'epoch': 0.83}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[32;1mThe\u001b[0m\u001b[31;1m effect[Con]\u001b[0m\u001b[31;1msequ[sequence]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m the[Imm]\u001b[0m\u001b[32;1mune\u001b[0m\u001b[31;1m Response[Supp]\u001b[0m\u001b[31;1mression[ressive]\u001b[0m\u001b[31;1m Effects[Cells]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m Brain[Use]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m a[Ther]\u001b[0m\u001b[32;1mape\u001b[0m\u001b[32;1mutic\u001b[0m\u001b[31;1m Agents[Cancer]\u001b[0m\u001b[31;1m Therapy[Vacc]\u001b[0m\u001b[31;1mine[ines]\u001b[0m\u001b[31;1m:[and]\u001b[0m\u001b[32;1m Their\u001b[0m\u001b[31;1m Association[Import]\u001b[0m\u001b[32;1mance\u001b[0m\u001b[31;1m for[in]\u001b[0m\u001b[31;1m the[Imm]\u001b[0m\u001b[32;1mune\u001b[0m\u001b[31;1m Response[Monitoring]\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5043, 'learning_rate': 7.660756813971951e-06, 'epoch': 0.85}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.0074229673482477665, 'eval_supp_data_loss_lm': 0.3443067967891693, 'eval_loss': 0.3522076904773712, 'eval_runtime': 5.6985, 'eval_samples_per_second': 521.189, 'eval_steps_per_second': 4.212, 'epoch': 0.85}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[32;1mThe\u001b[0m\u001b[31;1m effect[association]\u001b[0m\u001b[32;1m between\u001b[0m\u001b[31;1m the[time]\u001b[0m\u001b[32;1m to\u001b[0m\u001b[31;1m death[antibiotics]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m the[relevant]\u001b[0m\u001b[32;1m clinical\u001b[0m\u001b[32;1m outcomes\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m patients[emergency]\u001b[0m\u001b[32;1m department\u001b[0m\u001b[32;1m patients\u001b[0m\u001b[32;1m with\u001b[0m\u001b[31;1m acute[various]\u001b[0m\u001b[31;1m disease[stages]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m chronic[se]\u001b[0m\u001b[32;1mps\u001b[0m\u001b[32;1mis\u001b[0m\u001b[31;1m</s>[:]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m retrospective[prospective]\u001b[0m\u001b[31;1m cohort[multi]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mcenter\u001b[0m\u001b[32;1m study\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.502, 'learning_rate': 6.9992061391902616e-06, 'epoch': 0.86}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.005575120449066162, 'eval_supp_data_loss_lm': 0.34403860569000244, 'eval_loss': 0.3500642478466034, 'eval_runtime': 5.5586, 'eval_samples_per_second': 534.308, 'eval_steps_per_second': 4.318, 'epoch': 0.86}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[Low]\u001b[0m\u001b[32;1m-\u001b[0m\u001b[32;1mdose\u001b[0m\u001b[31;1m chemotherapy[inoc]\u001b[0m\u001b[32;1mulation\u001b[0m\u001b[32;1m of\u001b[0m\u001b[31;1m human[Esc]\u001b[0m\u001b[32;1mher\u001b[0m\u001b[32;1mich\u001b[0m\u001b[32;1mia\u001b[0m\u001b[32;1m coli\u001b[0m\u001b[31;1m and[achieves]\u001b[0m\u001b[31;1m high[robust]\u001b[0m\u001b[31;1m antit[vaginal]\u001b[0m\u001b[31;1m muc[colonization]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m improves[results]\u001b[0m\u001b[32;1m in\u001b[0m\u001b[31;1m a[ascending]\u001b[0m\u001b[31;1m and[infection]\u001b[0m\u001b[31;1m in[accompanied]\u001b[0m\u001b[32;1m by\u001b[0m\u001b[31;1m a[severe]\u001b[0m\u001b[31;1m acute[uter]\u001b[0m\u001b[32;1mine\u001b[0m\u001b[31;1m infection[inflammation]\u001b[0m\u001b[31;1m</s>[in]\u001b[0m\u001b[32;1m mice\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /lm_models/checkpoint-6500\n",
      "Trainer.model is not a `PreTrainedModel`, only saving its state dict.\n",
      "Deleting older checkpoint [/lm_models/checkpoint-4000] due to args.save_total_limit\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "INFO:***** Running Evaluation *****\n",
      "INFO:  Num examples = 2970\n",
      "INFO:  Batch size = 128\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'loss': 0.5001, 'learning_rate': 6.337655464408574e-06, 'epoch': 0.87}\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/24 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'eval_supp_data_loss_z': 0.005742605309933424, 'eval_supp_data_loss_lm': 0.34387946128845215, 'eval_loss': 0.3500670790672302, 'eval_runtime': 5.6614, 'eval_samples_per_second': 524.605, 'eval_steps_per_second': 4.239, 'epoch': 0.87}\n",
      "\n",
      "\n",
      "\u001b[32;1m<s>\u001b[0m\u001b[31;1mThe[In]\u001b[0m\u001b[31;1mhibition[fer]\u001b[0m\u001b[32;1mring\u001b[0m\u001b[32;1m the\u001b[0m\u001b[31;1m effects[presence]\u001b[0m\u001b[32;1m of\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m novel[flat]\u001b[0m\u001b[32;1moxin\u001b[0m\u001b[31;1m in[-]\u001b[0m\u001b[31;1mlike[producing]\u001b[0m\u001b[31;1m Esc[As]\u001b[0m\u001b[32;1mper\u001b[0m\u001b[32;1mg\u001b[0m\u001b[32;1millus\u001b[0m\u001b[31;1m f[flav]\u001b[0m\u001b[32;1mus\u001b[0m\u001b[31;1m in[strains]\u001b[0m\u001b[31;1m in[using]\u001b[0m\u001b[31;1m a[RNA]\u001b[0m\u001b[31;1m-[sequencing]\u001b[0m\u001b[32;1m and\u001b[0m\u001b[31;1m RNA[electronic]\u001b[0m\u001b[31;1m health[probes]\u001b[0m\u001b[31;1m</s>[as]\u001b[0m\u001b[32;1m a\u001b[0m\u001b[31;1m tool[transcript]\u001b[0m\u001b[31;1mome[omic]\u001b[0m\u001b[31;1m approach[screening]\u001b[0m\u001b[32;1m tool\u001b[0m\u001b[32;1m</s>\u001b[0m\n",
      "\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_138/742420827.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m train_lm(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtraining_args_tokcl\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mloader_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mdata_config_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtokenized_examples\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/train/train_lm.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(training_args, loader_path, data_config_name, data_dir, no_cache, tokenizer, model_type, from_pretrained)\u001b[0m\n\u001b[1;32m    297\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Current cuda device '\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcurrent_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    298\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 299\u001b[0;31m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    300\u001b[0m     \u001b[0mtrainer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_args\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, resume_from_checkpoint, trial, ignore_keys_for_eval, **kwargs)\u001b[0m\n\u001b[1;32m   1330\u001b[0m                         \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1332\u001b[0;31m                     \u001b[0mtr_loss_step\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtraining_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1333\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1334\u001b[0m                 if (\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/transformers/trainer.py\u001b[0m in \u001b[0;36mtraining_step\u001b[0;34m(self, model, inputs)\u001b[0m\n\u001b[1;32m   1889\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1890\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautocast_smart_context_manager\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1891\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompute_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1892\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1893\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_gpu\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/app/smtag/trainer.py\u001b[0m in \u001b[0;36mcompute_loss\u001b[0;34m(self, model, inputs, return_outputs)\u001b[0m\n\u001b[1;32m    552\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    553\u001b[0m             \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 554\u001b[0;31m         \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    555\u001b[0m         \u001b[0;31m# Save past state if it exists\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    556\u001b[0m         \u001b[0;31m# TODO: this needs to be fixed and made cleaner later.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m   1108\u001b[0m         if not (self._backward_hooks or self._forward_hooks or self._forward_pre_hooks or _global_backward_hooks\n\u001b[1;32m   1109\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1110\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1111\u001b[0m         \u001b[0;31m# Do not call functions when jit is used\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1112\u001b[0m         \u001b[0mfull_backward_hooks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnon_full_backward_hooks\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, *inputs, **kwargs)\u001b[0m\n\u001b[1;32m    166\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    167\u001b[0m             \u001b[0mreplicas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreplicate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 168\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    169\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/data_parallel.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(self, replicas, inputs, kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 178\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mparallel_apply\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreplicas\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mgather\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moutput_device\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/parallel_apply.py\u001b[0m in \u001b[0;36mparallel_apply\u001b[0;34m(modules, inputs, kwargs_tup, devices)\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstart\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mthread\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mthreads\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m             \u001b[0mthread\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0m_worker\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodules\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs_tup\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36mjoin\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m   1009\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1010\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1011\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wait_for_tstate_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1012\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1013\u001b[0m             \u001b[0;31m# the behavior of a negative timeout isn't documented, but\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.8/threading.py\u001b[0m in \u001b[0;36m_wait_for_tstate_lock\u001b[0;34m(self, block, timeout)\u001b[0m\n\u001b[1;32m   1025\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlock\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# already determined that the C code is done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1026\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_is_stopped\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1027\u001b[0;31m         \u001b[0;32melif\u001b[0m \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1028\u001b[0m             \u001b[0mlock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1029\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stop\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "train_lm(\n",
    "    training_args_tokcl,\n",
    "    loader_path,\n",
    "    data_config_name,\n",
    "    tokenized_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe19048",
   "metadata": {},
   "source": [
    "#### With CLI:\n",
    "\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_lm.py SEQ2SEQ --data_dir /data/json/oapmc_title --per_device_train_batch_size=128 --per_device_eval_batch_size=128 --logging_steps=100 --num_train_epochs=1 --no_cache\n",
    "\n",
    "python -m smtag.cli.lm.train smtag/loader/loader_lm.py SEQ2SEQ --data_dir /data/json/emboj_abstracts --per_device_train_batch_size=8 --per_device_eval_batch_size=8 --logging_steps=100 --num_train_epochs=1 --no_cache\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0f6eb32",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
