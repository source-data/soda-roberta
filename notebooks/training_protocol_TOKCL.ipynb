{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "47874baf",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3af60288",
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2cacc65e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "8a2dd817",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Config(max_length=512, truncation=True, min_char_length=120, celery_batch_size=1000, from_pretrained='roberta-base', model_type='Autoencoder', nlp=<spacy.lang.en.English object at 0x7fd4142b98b0>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from smtag.config import config\n",
    "config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f4f0ba2a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'4.15.0'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import __version__\n",
    "__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "baee6ccc",
   "metadata": {},
   "source": [
    "## Download SourceData data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e9c0cf5",
   "metadata": {},
   "source": [
    "This takes a very long time! It advised to run this within a tmux session rather than in this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ff153ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "! python -m smtag.cli.prepo.get_sd  # files saved in xml_destination_files\n",
    "! # mv xml_destination_files/ data/xml/<name_of_source_data_compendium>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2318f0c4",
   "metadata": {},
   "source": [
    "## Split dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3104c168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.split import distribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57c8d6a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "distribute(Path(\"data/xml/220304_sd\"), ext=\"xml\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7955b03",
   "metadata": {},
   "source": [
    "## Extracting examples for TOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "800dbf84",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.extract import ExtractorXML"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55e9b173",
   "metadata": {},
   "source": [
    "#### Dataset with individual panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "24cd3c79",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_panel_examples = \"/data/text/220304_sd_panels\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1713e35f",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr /data/text/220304_panels_sd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cb1fbdff",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/text/220304_sd_panels created\n"
     ]
    }
   ],
   "source": [
    "extractor_tokcl = ExtractorXML(\n",
    "    \"/data/xml/220304_sd\",\n",
    "    destination_dir=xml_panel_examples,\n",
    "    sentence_level=False,\n",
    "    xpath=\".//sd-panel\",\n",
    "    keep_xml=True,\n",
    "    inclusion_probability=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc81025e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [01:11<00:00, 35.85s/it]\n",
      "100%|██████████| 1/1 [00:20<00:00, 20.51s/it]\n",
      "100%|██████████| 1/1 [00:10<00:00, 10.43s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/data/text/220304_sd_panels/train.txt'): 48771,\n",
       " PosixPath('/data/text/220304_sd_panels/eval.txt'): 13801,\n",
       " PosixPath('/data/text/220304_sd_panels/test.txt'): 7178}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_tokcl.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4396a",
   "metadata": {},
   "source": [
    "same via CLI:\n",
    "\n",
    "```bash\n",
    "python -m smtag.cli.prepro.extract /data/xml/191012/ /data/text/sd_test --xpath \".//sd-panel\" --sentence_level --keep_xml --inclusion_probability 1.0\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bdc9250",
   "metadata": {},
   "source": [
    "#### Dataset with full figures (used for panelization training)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c175a410",
   "metadata": {},
   "outputs": [],
   "source": [
    "xml_figure_examples = \"/data/text/220304_sd_fig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1c7c6df1",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr \"/data/text/220304_sd_fig\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a3c1a672",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/text/220304_sd_fig created\n"
     ]
    }
   ],
   "source": [
    "extractor_tokcl_2 = ExtractorXML(\n",
    "    \"/data/xml/220304_sd\",\n",
    "    destination_dir=xml_figure_examples,\n",
    "    sentence_level=False,\n",
    "    xpath=\".//fig\",\n",
    "    keep_xml=True,\n",
    "    inclusion_probability=1.0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e127f8c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:22<00:00, 11.15s/it]\n",
      "100%|██████████| 1/1 [00:06<00:00,  6.18s/it]\n",
      "100%|██████████| 1/1 [00:03<00:00,  3.31s/it]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{PosixPath('/data/text/220304_sd_fig/train.txt'): 12108,\n",
       " PosixPath('/data/text/220304_sd_fig/eval.txt'): 3439,\n",
       " PosixPath('/data/text/220304_sd_fig/test.txt'): 1802}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor_tokcl_2.extract_from_corpus()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2717053",
   "metadata": {},
   "source": [
    "## Preparing tokenized dataset for TOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7df6eb7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.dataprep import PreparatorTOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "bdef1b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.xml2labels import SourceDataCodes as sd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0bf063f4",
   "metadata": {},
   "source": [
    "#### Tokenize panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bbe30648",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr /data/json/220304_sd_panels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a3baafff",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_panel_examples = \"/data/json/220304_sd_panels\"\n",
    "code_maps: code_maps = [\n",
    "    sd.ENTITY_TYPES,\n",
    "    sd.GENEPROD_ROLES,\n",
    "    sd.SMALL_MOL_ROLES,\n",
    "    sd.BORING,\n",
    "    sd.PANELIZATION\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "eb11e0c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/json/220304_sd_panels created\n"
     ]
    }
   ],
   "source": [
    "prep_tokcl = PreparatorTOKCL(\n",
    "    xml_panel_examples,\n",
    "    tokenized_panel_examples,\n",
    "    code_maps,\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "30b5d173",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 3377/48771 [00:07<01:36, 472.07it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 61 in 'ced AhCre->>>ER^T...<<< Apc Pten '\n",
      "WARNING: token overlaps element boundary sd-tag at position 84 in 'and AhCre->>>ER^T...<<< Apc Pten '\n",
      "WARNING: token overlaps element boundary sd-tag at position 61 in 'ced AhCre->>>ER^T...<<< Apc Pten '\n",
      "WARNING: token overlaps element boundary sd-tag at position 84 in 'and AhCre->>>ER^T...<<< Apc Pten '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 5462/48771 [00:12<01:44, 414.72it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 338 in ' (green). >>>Cre^st...<<<aining (re'\n",
      "WARNING: token overlaps element boundary sd-tag at position 391 in 'β-gal and >>>Cre^st...<<<aining in '\n",
      "WARNING: token overlaps element boundary sd-tag at position 338 in ' (green). >>>Cre^st...<<<aining (re'\n",
      "WARNING: token overlaps element boundary sd-tag at position 391 in 'β-gal and >>>Cre^st...<<<aining in '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 5585/48771 [00:12<01:56, 369.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 650 in ' multiple >>>rod^s...<<<omata). (J'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 10105/48771 [00:22<01:22, 467.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 32 in 'cation of >>>mitochondria^l...<<< numbers f'\n",
      "WARNING: token overlaps element boundary sd-tag at position 32 in 'cation of >>>mitochondria^l...<<< numbers f'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 10849/48771 [00:24<01:22, 457.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 121 in 'l healthy >>>human^s...<<<kin biopsi'\n",
      "WARNING: token overlaps element boundary sd-tag at position 121 in 'l healthy >>>human^s...<<<kin biopsi'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 13159/48771 [00:29<01:31, 391.16it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 176 in 'bivalent (>>>X^Y...<<<) and thei'\n",
      "WARNING: token overlaps element boundary sd-tag at position 272 in 'bivalent (>>>X^Y...<<<) is indic'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 52%|█████▏    | 25604/48771 [00:57<00:50, 456.93it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 217 in ';Prox1-Cre>>>ER^T...<<<2 and litt'\n",
      "WARNING: token overlaps element boundary sd-tag at position 217 in ';Prox1-Cre>>>ER^T...<<<2 and litt'\n",
      "WARNING: token overlaps element boundary sd-tag at position 76 in ';Prox1-Cre>>>ER^T...<<<2 and litt'\n",
      "WARNING: token overlaps element boundary sd-tag at position 440 in ';Prox1-Cre>>>ER^T...<<<2 and cont'\n",
      "WARNING: token overlaps element boundary sd-tag at position 76 in ';Prox1-Cre>>>ER^T...<<<2 and litt'\n",
      "WARNING: token overlaps element boundary sd-tag at position 440 in ';Prox1-Cre>>>ER^T...<<<2 and cont'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 33110/48771 [01:14<00:29, 534.06it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 152 in 'uorescent >>>image^s...<<< of contro'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 36151/48771 [01:21<00:32, 387.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 110 in 'in VM and >>>AM^C...<<<Ms.Data in'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 38668/48771 [01:27<00:22, 443.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 161 in 'T = K14cre>>>ER^T...<<<g/+ Rosa26'\n",
      "WARNING: token overlaps element boundary sd-tag at position 201 in 'A = K14cre>>>ER^T...<<<g/+ Rosa26'\n",
      "WARNING: token overlaps element boundary sd-tag at position 161 in 'T = K14cre>>>ER^T...<<<g/+ Rosa26'\n",
      "WARNING: token overlaps element boundary sd-tag at position 201 in 'A = K14cre>>>ER^T...<<<g/+ Rosa26'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 38851/48771 [01:28<00:22, 435.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 125 in 'or mb1‐Cre>>>ER^T...<<<2;Sykfl/fl'\n",
      "WARNING: token overlaps element boundary sd-tag at position 125 in 'or mb1‐Cre>>>ER^T...<<<2;Sykfl/fl'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 44079/48771 [01:40<00:11, 401.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 12 in 'hanges in >>>H^D...<<<X behavior'\n",
      "WARNING: token overlaps element boundary sd-tag at position 358 in 'tion. All >>>H^D...<<<X MS data '\n",
      "WARNING: token overlaps element boundary sd-tag at position 12 in 'hanges in >>>H^D...<<<X behavior'\n",
      "WARNING: token overlaps element boundary sd-tag at position 358 in 'tion. All >>>H^D...<<<X MS data '\n",
      "WARNING: token overlaps element boundary sd-tag at position 457 in 'f GMPPCP. >>>H^D...<<<X data are'\n",
      "WARNING: token overlaps element boundary sd-tag at position 457 in 'f GMPPCP. >>>H^D...<<<X data are'\n",
      "WARNING: token overlaps element boundary sd-tag at position 179 in 'crease in >>>H^D...<<<X. Quantit'\n",
      "WARNING: token overlaps element boundary sd-tag at position 179 in 'crease in >>>H^D...<<<X. Quantit'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 94%|█████████▍| 45972/48771 [01:44<00:05, 470.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 109 in '−folate + >>>A^G...<<<CT (n = 75'\n",
      "WARNING: token overlaps element boundary sd-tag at position 111 in 'olate + AG>>>C^T...<<< (n = 75).'\n",
      "WARNING: token overlaps element boundary sd-tag at position 109 in '−folate + >>>A^G...<<<CT (n = 75'\n",
      "WARNING: token overlaps element boundary sd-tag at position 111 in 'olate + AG>>>C^T...<<< (n = 75).'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▉| 48351/48771 [01:49<00:00, 454.70it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 257 in ' (E), the >>>neuron^s...<<< were anal'\n",
      "WARNING: token overlaps element boundary sd-tag at position 257 in ' (E), the >>>neuron^s...<<< were anal'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████▉| 48597/48771 [01:50<00:00, 463.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 101 in 'l/fl, Cre->>>ER^T...<<<2) cells t'\n",
      "WARNING: token overlaps element boundary sd-tag at position 101 in 'l/fl, Cre->>>ER^T...<<<2) cells t'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 48771/48771 [01:50<00:00, 441.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 101 (min=22, max=512) tokens\n",
      "longest example: <s>(d-f) The percentage of EGFP-positive cells with EGFP-HDQ74 aggregates (above) and cell death (below) in COS-7 cells, as in Figure 1c-treated with DMSO (control), or with 0.2 μM rapamycin alone, SMER alone (140 μM SMER10 (d), 43 μM SMER18 (e) or 47 μM SMER28 (f)) or both for 24 h-were expressed as odds ratios. Error bars: 95% confidence interval. Aggregation (top panels): P = 0.248 (Rap), P = 0.217 (SMER10), P 0.0001 (SMER10 + Rap), P 0.001 (Rap or SMER10 versus SMER10 + Rap) (d); P = 0.248 (Rap), P = 0.543 (SMER18), P 0.0001 (SMER18 + Rap), P = 0.008 (Rap versus SMER18 + Rap), P = 0.002 (SMER18 versus SMER18 + Rap) (e); P = 0.248 (Rap), P = 0.002 (SMER28), P 0.0001 (SMER28 + Rap), P 0.0001 (Rap versus SMER28 + Rap), P = 0.012 (SMER28 versus SMER28 + Rap) (f). Cell death (bottom panels): P = 0.002 (Rap), P 0.0001 (SMER10, SMER10 + Rap, Rap or SMER10 versus SMER10 + Rap) (d); P = 0.002 (Rap), P = 0.948 (SMER18), P 0.0001 (SMER18 + Rap), P = 0.015 (Rap versus SMER18 + Rap), P 0.0001 (SMER18 versus SMER18 + Rap) (e); P = 0.002 (Rap), P 0.0001 (SMER28, SMER28 + Rap, Rap or SMER28 versus SMER28 + Rap) (f). Note that we have treated cells for a shorter time in this experiment (24 h), compared with Figure 1c (48 h). This probably accounts for the failure of the protective trends of rapamycin and some of the SMERs to reach significance for aggregation on their own in some of the experiments. ***P 0.001; **P 0.</s>\n",
      "shortest example: <s>Gene ontology enrichment analysis of the upregulated genes indicates male-specific or preferential biological processes. </s>\n",
      "Preparing: eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 787/13801 [00:02<00:35, 365.80it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 434 in 'diate and >>>mitochondria^l...<<<). The sco'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 1223/13801 [00:03<00:26, 473.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 53 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 121 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 53 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 121 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 70 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 134 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 70 in ' Prox1-Cre>>>ER^T...<<<2;Ilk+/+ m'\n",
      "WARNING: token overlaps element boundary sd-tag at position 134 in ' Prox1-Cre>>>ER^T...<<<2;Ilk∆/∆ m'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 5547/13801 [00:12<00:17, 468.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 14 in ') Braf-/-;>>>ER^T...<<<mHRasG12V '\n",
      "WARNING: token overlaps element boundary sd-tag at position 14 in ') Braf-/-;>>>ER^T...<<<mHRasG12V '\n",
      "WARNING: token overlaps element boundary sd-tag at position 19 in ': Braf-/-;>>>ER^T...<<<mHRasG12V '\n",
      "WARNING: token overlaps element boundary sd-tag at position 19 in ': Braf-/-;>>>ER^T...<<<mHRasG12V '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 6068/13801 [00:14<00:18, 422.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 49 in 'P-IRES-Cre>>>ER^T...<<<2 mice wer'\n",
      "WARNING: token overlaps element boundary sd-tag at position 49 in 'P-IRES-Cre>>>ER^T...<<<2 mice wer'\n",
      "WARNING: token overlaps element boundary sd-tag at position 49 in 'P-IRES-Cre>>>ER^T...<<<2 mice wer'\n",
      "WARNING: token overlaps element boundary sd-tag at position 49 in 'P-IRES-Cre>>>ER^T...<<<2 mice wer'\n",
      "WARNING: token overlaps element boundary sd-tag at position 115 in 'gr5-GFPCre>>>ER^T...<<<2 X Tomato'\n",
      "WARNING: token overlaps element boundary sd-tag at position 176 in 'gr5-GFPCre>>>ER^T...<<<2 X Tomato'\n",
      "WARNING: token overlaps element boundary sd-tag at position 362 in '(CDX2P-Cre>>>ER^T...<<<2 X Tomato'\n",
      "WARNING: token overlaps element boundary sd-tag at position 115 in 'gr5-GFPCre>>>ER^T...<<<2 X Tomato'\n",
      "WARNING: token overlaps element boundary sd-tag at position 176 in 'gr5-GFPCre>>>ER^T...<<<2 X Tomato'\n",
      "WARNING: token overlaps element boundary sd-tag at position 362 in '(CDX2P-Cre>>>ER^T...<<<2 X Tomato'\n",
      "WARNING: token overlaps element boundary sd-tag at position 158 in 'P-IRES-Cre>>>ER^T...<<<2 mice. '\n",
      "WARNING: token overlaps element boundary sd-tag at position 158 in 'P-IRES-Cre>>>ER^T...<<<2 mice. '\n",
      "WARNING: token overlaps element boundary sd-tag at position 143 in 'gr5-GFPCre>>>ER^T...<<<2 X CDX2P-'\n",
      "WARNING: token overlaps element boundary sd-tag at position 159 in ' CDX2P-Cre>>>ER^T...<<<2 [GC]) an'\n",
      "WARNING: token overlaps element boundary sd-tag at position 203 in 'gr5-GFPCre>>>ER^T...<<<2 X CDX2P-'\n",
      "WARNING: token overlaps element boundary sd-tag at position 219 in ' CDX2P-Cre>>>ER^T...<<<2 [HGC]), '\n",
      "WARNING: token overlaps element boundary sd-tag at position 143 in 'gr5-GFPCre>>>ER^T...<<<2 X CDX2P-'\n",
      "WARNING: token overlaps element boundary sd-tag at position 159 in ' CDX2P-Cre>>>ER^T...<<<2 [GC]) an'\n",
      "WARNING: token overlaps element boundary sd-tag at position 203 in 'gr5-GFPCre>>>ER^T...<<<2 X CDX2P-'\n",
      "WARNING: token overlaps element boundary sd-tag at position 219 in ' CDX2P-Cre>>>ER^T...<<<2 [HGC]), '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 10128/13801 [00:23<00:08, 445.17it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 74 in 'red in S(->>>N^C...<<<) for 4 h '\n",
      "WARNING: token overlaps element boundary sd-tag at position 74 in 'red in S(->>>N^C...<<<) for 4 h '\n",
      "WARNING: token overlaps element boundary sd-tag at position 37 in 'red in S(->>>N^C...<<<) for 4 h.'\n",
      "WARNING: token overlaps element boundary sd-tag at position 37 in 'red in S(->>>N^C...<<<) for 4 h.'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 10421/13801 [00:24<00:07, 450.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 22 in 'ctions of >>>CA^N...<<<BD- and Ps'\n",
      "WARNING: token overlaps element boundary sd-tag at position 22 in 'ctions of >>>CA^N...<<<BD- and Ps'\n",
      "WARNING: token overlaps element boundary sd-tag at position 4 in '>>>CA^D...<<<MAC-incorp'\n",
      "WARNING: token overlaps element boundary sd-tag at position 4 in '>>>CA^D...<<<MAC-incorp'\n",
      "WARNING: token overlaps element boundary sd-tag at position 4 in '>>>CA^N...<<<BD- and CA'\n",
      "WARNING: token overlaps element boundary sd-tag at position 15 in 'ANBD- and >>>CA^D...<<<MAC-incorp'\n",
      "WARNING: token overlaps element boundary sd-tag at position 58 in 'rization. >>>CA^N...<<<BD (green)'\n",
      "WARNING: token overlaps element boundary sd-tag at position 76 in 'reen) and >>>CA^D...<<<MAC (blue)'\n",
      "WARNING: token overlaps element boundary sd-tag at position 4 in '>>>CA^N...<<<BD- and CA'\n",
      "WARNING: token overlaps element boundary sd-tag at position 15 in 'ANBD- and >>>CA^D...<<<MAC-incorp'\n",
      "WARNING: token overlaps element boundary sd-tag at position 58 in 'rization. >>>CA^N...<<<BD (green)'\n",
      "WARNING: token overlaps element boundary sd-tag at position 76 in 'reen) and >>>CA^D...<<<MAC (blue)'\n",
      "WARNING: token overlaps element boundary sd-tag at position 28 in 'vation of >>>CA^D...<<<MAC-incorp'\n",
      "WARNING: token overlaps element boundary sd-tag at position 28 in 'vation of >>>CA^D...<<<MAC-incorp'\n",
      "WARNING: token overlaps element boundary sd-tag at position 16 in ' image of >>>CA^N...<<<BD-polymer'\n",
      "WARNING: token overlaps element boundary sd-tag at position 16 in ' image of >>>CA^N...<<<BD-polymer'\n",
      "WARNING: token overlaps element boundary sd-tag at position 65 in 'herry and >>>CA^D...<<<MAC fluore'\n",
      "WARNING: token overlaps element boundary sd-tag at position 160 in 'ated with >>>CA^D...<<<MAC and th'\n",
      "WARNING: token overlaps element boundary sd-tag at position 65 in 'herry and >>>CA^D...<<<MAC fluore'\n",
      "WARNING: token overlaps element boundary sd-tag at position 160 in 'ated with >>>CA^D...<<<MAC and th'\n",
      "WARNING: token overlaps element boundary sd-tag at position 204 in 'ated with >>>CA^D...<<<MAC and th'\n",
      "WARNING: token overlaps element boundary sd-tag at position 204 in 'ated with >>>CA^D...<<<MAC and th'\n",
      "WARNING: token overlaps element boundary sd-tag at position 237 in 'ated with >>>CA^D...<<<MAC and th'\n",
      "WARNING: token overlaps element boundary sd-tag at position 237 in 'ated with >>>CA^D...<<<MAC and th'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 12731/13801 [00:29<00:02, 472.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 86 in '-nCoV RBD->>>S^D...<<<1. Binding'\n",
      "WARNING: token overlaps element boundary sd-tag at position 86 in '-nCoV RBD->>>S^D...<<<1. Binding'\n",
      "WARNING: token overlaps element boundary sd-tag at position 200 in '-nCoV RBD->>>S^D...<<<1 and the '\n",
      "WARNING: token overlaps element boundary sd-tag at position 200 in '-nCoV RBD->>>S^D...<<<1 and the '\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 13801/13801 [00:32<00:00, 431.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 101 (min=22, max=512) tokens\n",
      "longest example: <s> A1) Representative WBs showing DRD2 and RGS9-2 downregulation in adult (P60-P90) Tor1a+/- (+/-) striata, characterized by a reduced torsinA protein level with respect to Tor1a+/+ (+/+) littermates. The striatal level of RGS7 is unchanged. The dot plot shows Tor1a+/- data, normalized to Tor1a+/+ controls of the same experiment. TorsinA: Tor1a+/+ N=7, Tor1a+/- N=6, t test ***P=0.0003; DRD2: Tor1a+/+ N=18, Tor1a+/- N=16, t test **P=0.0029; RGS9-2: Tor1a+/+ N=32, Tor1a+/- N=33, t test *P=0.0115). RGS7: Tor1a+/+ N=7, Tor1a+/- N=7, t test P=0.8721). WB quantification data, expressed as the ratio of protein vs. loading control intensity level, are normalized to the wild-type samples of the same experiment. A2,A3,A4) Time-course of changes in torsinA, DRD2 and RGS9-2 striatal levels along postnatal development. Summary plot data are normalized to the Tor1a+/+ P60 sample of each independent experiment. A2) TorsinA level is significantly reduced in mutants throughout the developmental period considered (P7 N=3; P14-P60 N=4; one-way ANOVA P<0.0001 and Bonferroni's Multiple Comparison Test **P<0.01 at P7, P14 and P60). A3,A4) DRD2 and RGS9-2 levels show parallel courses, with a similar increase from P7 to P21 in Tor1a+/+ as well as Tor1a+/- striatal lysates (P7: DRD2 N=3, RGS9-2 N=4; P14-P21 N=4; one-way ANOVA with Bonferroni's Multiple Comparison Test P>0.05). At P60, a simultaneous reduction of DRD2 and RGS9-2 levels is observed in Tor1a+/- striatal</s>\n",
      "shortest example: <s>I) Correlation circle representing the correlation between physical tests and their corresponding first two principal components. </s>\n",
      "Preparing: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 1301/7178 [00:03<00:13, 433.86it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: token overlaps element boundary sd-tag at position 274 in 'lation of >>>mitochondria^l...<<<ow cells. '\n",
      "WARNING: token overlaps element boundary sd-tag at position 310 in 'entage of >>>mitochondria^l...<<<ow cells/S'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 7178/7178 [00:16<00:00, 424.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 103 (min=25, max=512) tokens\n",
      "longest example: <s>Either young WT (A, B) or old APPPS1 (C-E) tissue was treated with clodronate (Clo) to remove CD68 positive cells or vehicle Ctr from 1 until 7 DIV. Treatment was stopped and subsequently old (A, B) or young (C-E) tissue was added to the culture as schematically indicated in A and C. and analyzed 14 days after. Removal of CD68 positive cells in either young WT or old APPPS1 tissue prevents amyloid plaque clearance in the co-culture model.(A) Immunofluorescence analysis of the old APPPS1 slice co-cultured with the young WT slice pre-treated with Clo and Ctr and immunostained with CD68 (red) and M3.2 (green). Scale bar: 50 µm.(B) Quantitative analysis of core-only plaques in the old APPPS1 tissue co-cultured with the young WT tissue pre-treated with Clo and Ctr as indicated in A reveals a decreased number of core-only plaques upon Clo treatment. The values are expressed as percentages of core-only plaques from the total number of amyloid plaques and represent mean ± SEM from 3 independent experiments, including total of 6 independent slice culture dishes (***P < 0.001).(C) Immunofluorescence analysis of the old APPPS1 slice treated with Clo and Ctr and subsequently co-cultured with the young WT slice and immunostained with CD68 (red) and M3.2 (green). Scale bar: 50 µm.(D) Area of CD68 positive cells (CD68 coverage) in the old APPPS1 tissue treated with Clo and Ctr and subsequently co-cultured with the young WT tissue as indicated in C. CD68 coverage is reduced upon Clo treatment. The values are normalized to CD68 coverage of the Ctr and represent mean ± SEM from 3 independent experiments, including total of 6 independent slice culture dishes (***P < 0.001).(E) Quantitative analysis of core-only plaques in the old APPPS1 tissue treated with Clo and Ctr and subsequently co-cultured with the young WT tissue as indicated in C reveals a decreased number of core-only plaques upon Clo treatment. The values are expressed as percentages of core-only plaques from the total number of amyloid plaques and represent mean ± SEM from 3 independent experiments, including total of 6 independent slice</s>\n",
      "shortest example: <s>B Model of rhomboid-mediated quality control by selectively targeting orphan components of multi-protein respiratory complexes. </s>\n"
     ]
    }
   ],
   "source": [
    "prep_tokcl.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53e9c5d3",
   "metadata": {},
   "source": [
    "same vie CLI:\n",
    "    \n",
    "```bash\n",
    "python -m smtag.cli.tokcl.dataprep /data/text/sd_test /data/json/sd_test\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86159135",
   "metadata": {},
   "source": [
    "#### Tokenize figures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c0dc3d7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenized_figure_examples = \"/data/json/220304_sd_fig\"\n",
    "code_maps: code_maps = [\n",
    "    sd.PANELIZATION\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4154b89d",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr /data/json/220304_sd_fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "838093e7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/data/json/220304_sd_fig created\n"
     ]
    }
   ],
   "source": [
    "prep_tokcl_2 = PreparatorTOKCL(\n",
    "    xml_figure_examples,\n",
    "    tokenized_figure_examples,\n",
    "    code_maps,\n",
    "    max_length=config.max_length\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "25685c7d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preparing: train\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 24%|██▍       | 2961/12108 [00:08<00:25, 361.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: emtpy element sd-panel? at position (547, 548) in >>> E) TE binning according to increasing 22G siRNA d...<<<\n",
      "WARNING: emtpy element sd-panel? at position (1170, 1171) in >>> H) Distribution of normalized reads mapping over ...<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 4145/12108 [00:11<00:24, 320.91it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: emtpy element sd-panel? at position (9, 10) in >>> A schematic illustration of the proposed model de...<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 6674/12108 [00:19<00:14, 365.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: emtpy element sd-panel? at position (443, 444) in >>>   ...<<<\n",
      "WARNING: emtpy element sd-panel? at position (444, 445) in >>>  ...<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 12108/12108 [00:35<00:00, 338.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 367 (min=26, max=512) tokens\n",
      "longest example: <s>: The combination of γ-radiation and inducible deletion of BCL-XL causes neither inflammation, hematopoietic malignancy nor liver damage.Figure 2Bcl-xfl/fl;RosaCreERT2+/Ki (n=8) or, as controls, Bcl-xfl/fl (n=6) and RosaCreERT2+/Ki (n=12) mice as well as Bcl-xfl/fl;RosaCreERT2+/Ki;GFP-Chimeras (n=21), or as controls, Bcl-xfl/fl;GFP-Chimeras (n=6) and RosaCreERT2+/Ki;GFP-Chimeras (n=6) (age 8-14 weeks, males and females) were treated with tamoxifen (200 mg/kg/body weight administered in 3 daily doses by oral gavage) to induce CreERT2-mediated deletion of the floxed Bcl-x alleles. (A) Total white blood cell counts (WBC) were analyzed by ADVIA in sick mice or at the termination of the experiment (healthy control mice). Data are presented as mean ±SEM. Each data point represents an individual mouse and n numbers are indicated above. Statistical significance was assessed using the Student's t-test. No statistically significant differences were observed. (B) The neutrophil/lymphocyte ratio (NLR) is presented as mean ±SEM for sick Bcl-xfl/fl;RosaCreERT2+/Ki;GFP-Chimeras (n=21) or healthy control RosaCreERT2+/Ki;GFP-Chimeras (n=6) at the termination of the experiment. Data are presented as mean ±SEM. Each data point represents an individual mouse. Statistical significance was assessed using the Student's t-test; *p<0.05. (C) Histological analysis of H&E-stained sections of the sternum of sick Bcl-xfl/fl;RosaCreERT2+/Ki;GFP-Chimeras or healthy wild-type and RosaCreERT2+/Ki;GFP-Chimera control mice at the indicated time points post-treatment with tamoxifen (dpt=days post-treatment). (D) Hist</s>\n",
      "shortest example: <s>.Figure 8A model for the increased level of body fat storage by intestinal microbial alteration in the castrated cattle. </s>\n",
      "Preparing: eval\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|████▉     | 1714/3439 [00:05<00:04, 371.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING: emtpy element sd-panel? at position (72, 73) in >>> (B) The activations of macroautophagy induced by ...<<<\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3439/3439 [00:10<00:00, 321.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 367 (min=26, max=512) tokens\n",
      "longest example: <s>.Figure 4(A) Cryo-electron tomogram of P. tetraurelia centriole. Blue arrow denotes cartwheel, orange arrow denotes inner scaffold. White dashed box delimits the inset represented in (D, E). Red lines and arrows indicate the position and the direction of the cross-sections made in (B). Scale bar, 100 nm. (B) Nine-fold symmetrizations of serial cross-sections taken along the proximal to distal axis in P. tetraurelia. Each section is a z-projection of 20.7 nm. White dashed circles delineate the structures highlighted in C. Scale bar, 60 nm. (C) Zoomed images of proximal centriole substructures from nine-fold symmetrizations of P. tetraurelia along the proximal-distal axis. Each panel corresponds to the above image from panel B. Purple arrow, pinhead; light green arrow, triplet base; turquoise arrow, A-C linker; orange arrow, inner scaffold. (D) Side view showing the transition from pinhead to inner scaffold in P. tetraurelia. (E) Cartoon representation of panel D. (F) Representative model of a cross section of a centriole's proximal region. Colored arrows indicate the different structural features identified. (G) Cryo-electron tomogram of C. reinhardtii centriole. Blue arrow denotes cartwheel, orange arrow denotes inner scaffold. White dashed box delimits the inset represented in (J, K). Red lines and arrows indicate the position and the direction of the cross-sections made in (H). Scale bar, 100 nm. (H) Nine-fold symmetrizations of serial cross-sections taken along the proximal to distal axis in C. reinhardtii. Each section is a z-projection of 20.7 nm. White dashed circles delineate the structures highlighted in I. Scale bar, 60 nm. (I) Zoomed images of proximal centriole substructures from nine-fold symmetrizations of C. reinhardtii along the proximal-distal axis. Each panel corresponds to the above image from panel H. Purple arrow, pinhead; light green arrow, triplet base; turquoise arrow, A-C linker; orange arrow, inner scaffold. (J, K) Side views showing the</s>\n",
      "shortest example: <s>: Schematic of pipeline developed, validated and applied.Figure 5Schematic of pipeline developed, validated and applied. </s>\n",
      "Preparing: test\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1802/1802 [00:05<00:00, 323.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Length verification: OK!\n",
      "\n",
      "average input_ids length = 369 (min=30, max=512) tokens\n",
      "longest example: <s>: eIF4A is required for complete TORC1 inactivation upon amino acid removal.Figure 1(a-b) eIF4A knockdown in either S2 (a) or Kc167 (b) cells blunts the inactivation of TORC1 upon amino acid removal. Cells were treated with dsRNA targeting GFP as a negative control, or three independent, non-overlapping dsRNAs targeting eIF4A for 5 days and then incubated with complete medium or medium lacking only amino acids for 30 minutes. Representative of 3 biological replicates. (c) Only knockdown of eIF4A, but not of other genes involved in translation, causes elevated TORC1 upon amino acid withdrawal. S2 cells were treated with dsRNAs for 5 days and then incubated with medium containing or lacking amino acids for 30 minutes. After cell lysis, levels of S6K phosphorylation (T398) were measured by dot blot analysis and normalized to total S6K levels. Results are summarized here for all genes involved in translation, and provided in Dataset EV1. (d) Impaired inactivation of TORC1 in response to eIF4A knockdown is most apparent upon partial depletion of amino acids, caused by removal of amino acid subsets. After 5 days of knockdown, S2 cells were treated for 30 min with either complete Schneider's medium (+aa), Schneider's medium lacking all amino acids (-aa) or various subsets of amino acids, as indicated (where EAA \"essential amino acids\" = H,I,L,K,M,T,W,V). Error bars: std dev. n=3 biological replicates. (e) Time course of amino-acid removal reveals that eIF4A knockdown Kc167 cells maintain elevated S6K phosphorylation up to the maximum possible timepoint of 60 minutes when the cells start dying (see drop in S6K and tubulin levels). Representative of two biological replicates. (f) eIF4A mutant larvae have impaired TORC1 inactivation upon shifting to food lacking amino acids. Control (w1118) or eIF4A1006/1013 1st instar larvae were transferred from standard food to plates containing either standard fly food or PBS/1% agarose+2%sucrose for 1h prior to lysis and immunoblot analysis. Two biological replicates are shown.</s>\n",
      "shortest example: <s>.Figure 8Figure 8. Model of p53 binding and local histone modification as a form of genome protection to DNA damage stress. </s>\n"
     ]
    }
   ],
   "source": [
    "prep_tokcl_2.run()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37c47466",
   "metadata": {},
   "source": [
    "## Train model for TOKCL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "011ffcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.config import config\n",
    "from smtag.train.train_tokcl import (\n",
    "    train as train_tokcl,\n",
    "    TrainingArgumentsTOKCL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a39776ac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "training_args = TrainingArgumentsTOKCL(\n",
    "    logging_steps=50,\n",
    "    per_device_train_batch_size=16,\n",
    "    per_device_eval_batch_size=16,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9065ceeb",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader_path = \"./smtag/loader/loader_tokcl.py\"\n",
    "tokenizer = config.tokenizer\n",
    "model_type = \"Autoencoder\"\n",
    "from_pretrained = \"EMBO/bio-lm\"  # \"roberta-base\" # specialized model from huggingface.co/embo #  \"roberta-base\" # general lm model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9017dc03",
   "metadata": {},
   "source": [
    "Reload the datasets afresh (to prevent this behavior, set `no_cache` to `False`):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a94a46d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "no_cache = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "7adafa56",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr /runs/*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b0757689",
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -fr /tokcl_models/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6c88c9",
   "metadata": {},
   "source": [
    "### Train NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3613e4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_args.overwrite_output_dir=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e1f555c8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsTOKCL(output_dir='/tokcl_models', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=0.6, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/tokcl_models/runs/Mar06_14-19-46_5aebd0ba4077', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=20, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=50, dataloader_num_workers=0, past_index=-1, run_name='/tokcl_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', masking_probability=0.0, replacement_probability=0.0, select_labels=False)"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.num_train_epochs=0.6\n",
    "training_args.prediction_loss_only=True\n",
    "training_args.masking_probability=.0\n",
    "training_args.replacement_probability=.0\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "1be0f242",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Using custom data configuration NER-ff39ee0af78a5a25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /tokcl_models/NER.\n",
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading and tokenizing datasets found in /data/json/220304_sd_panels.\n",
      "using ./smtag/loader/loader_tokcl.py as dataset loader.\n",
      "Downloading and preparing dataset source_data_nlp/NER (download: Unknown size, generated: 88.01 MiB, post-processed: Unknown size, total: 88.01 MiB) to /cache/source_data_nlp/NER-ff39ee0af78a5a25/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset source_data_nlp downloaded and prepared to /cache/source_data_nlp/NER-ff39ee0af78a5a25/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "018ec08b1bc9452985ada7bb115211eb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 48771 examples.\n",
      "Evaluating on 13801 examples.\n",
      "\n",
      "Training on 15 features:\n",
      "O, I-SMALL_MOLECULE, B-SMALL_MOLECULE, I-GENEPROD, B-GENEPROD, I-SUBCELLULAR, B-SUBCELLULAR, I-CELL, B-CELL, I-TISSUE, B-TISSUE, I-ORGANISM, B-ORGANISM, I-EXP_ASSAY, B-EXP_ASSAY\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/EMBO/bio-lm/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/09fed88b4a07fe6baced126e3cdb14f2764c1bc57f62d1026a75b3ffdb3ec5f8.c781727f43e25ac5b298f775b2dd4f32f53c9890a2367bbd99ffdbd856251b85\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/EMBO/bio-lm/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/f61ee36e7d211df88e7eb67c937348fbd256ab3a970d6b3c9848181ed0330c27.12bb7cf77356bf912ed8598fb9a17becaa7e7c5406692af7264c45956cde2cf3\n",
      "Some weights of the model checkpoint at EMBO/bio-lm were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at EMBO/bio-lm and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 48771\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 458\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training arguments for model type Autoencoder:\n",
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\",\n",
      "    \"5\": \"LABEL_5\",\n",
      "    \"6\": \"LABEL_6\",\n",
      "    \"7\": \"LABEL_7\",\n",
      "    \"8\": \"LABEL_8\",\n",
      "    \"9\": \"LABEL_9\",\n",
      "    \"10\": \"LABEL_10\",\n",
      "    \"11\": \"LABEL_11\",\n",
      "    \"12\": \"LABEL_12\",\n",
      "    \"13\": \"LABEL_13\",\n",
      "    \"14\": \"LABEL_14\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_10\": 10,\n",
      "    \"LABEL_11\": 11,\n",
      "    \"LABEL_12\": 12,\n",
      "    \"LABEL_13\": 13,\n",
      "    \"LABEL_14\": 14,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4,\n",
      "    \"LABEL_5\": 5,\n",
      "    \"LABEL_6\": 6,\n",
      "    \"LABEL_7\": 7,\n",
      "    \"LABEL_8\": 8,\n",
      "    \"LABEL_9\": 9\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "TrainingArgumentsTOKCL(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/runs/tokcl-NER-2022-03-06T16-04-39.011396,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "masking_probability=0.0,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=0.6,\n",
      "output_dir=/tokcl_models/NER,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=True,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=False,\n",
      "replacement_probability=0.0,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tokcl_models,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "select_labels=False,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "CUDA available: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='458' max='458' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [458/458 12:02, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.349900</td>\n",
       "      <td>0.245450</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.228500</td>\n",
       "      <td>0.213546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.207000</td>\n",
       "      <td>0.207850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.186200</td>\n",
       "      <td>0.200047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.199300</td>\n",
       "      <td>0.194376</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.184000</td>\n",
       "      <td>0.193005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.176600</td>\n",
       "      <td>0.187639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.171400</td>\n",
       "      <td>0.183608</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.163600</td>\n",
       "      <td>0.182390</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>C Dynamic exchange of a misfolded model protein between\u001b[1m\u001b[4m\u001b[38;5;6m cyt\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;5mos\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;5mol\u001b[0m and\u001b[1m\u001b[4m\u001b[38;5;6m nucleus\u001b[0m.\u001b[1m\u001b[4m\u001b[38;5;14m FL\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mIP\u001b[0m measurements of\u001b[1m\u001b[4m\u001b[38;5;4m m\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mC\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mherry\u001b[0m‐\u001b[1m\u001b[4m\u001b[38;5;4mV\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mHL\u001b[0m were performed in\u001b[1m\u001b[4m\u001b[38;5;12m S\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;11m.\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;11m cere\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;11mvis\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;11miae\u001b[0m wild‐type cells at 30°C.\u001b[1m\u001b[38;5;6m Nuclear\u001b[0m or\u001b[1m\u001b[38;5;6m cyt\u001b[0m\u001b[1m\u001b[38;5;5mos\u001b[0m\u001b[1m\u001b[38;5;5molic\u001b[0m areas were bleached, and loss of fluorescence intensities in non‐bleached compartments was determined. Bleaching and acquisition controls are given. Error bars: SEM. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(L) Inhibition of\u001b[1m\u001b[38;5;4m my\u001b[0m\u001b[1m\u001b[38;5;3mos\u001b[0m\u001b[1m\u001b[38;5;3min\u001b[0m\u001b[1m\u001b[38;5;3m II\u001b[0m activity increased sensitivity to starvation.\u001b[1m\u001b[38;5;12m Fl\u001b[0m\u001b[1m\u001b[38;5;11mies\u001b[0m carrying transgenes under the control of\u001b[1m\u001b[4m\u001b[38;5;10m fat\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9m body\u001b[0m‐specific Cg-\u001b[1m\u001b[4m\u001b[38;5;4mG\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mAL\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m4\u001b[0m driver were used for further analysis. Histogram illustrating the\u001b[1m\u001b[4m\u001b[38;5;14m survival\u001b[0m curve of adult female\u001b[1m\u001b[4m\u001b[38;5;12m flies\u001b[0m of denoted genotypes when placed under starved conditions. Data are mean±s.e. from triplicate experiments (n=100\u001b[1m\u001b[4m\u001b[38;5;12m flies\u001b[0m/genotype/treatment). *P0.05, **P0.01, ***P0.001. See Supplementary data for genotypes. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(B) Quantified hist\u001b[1m\u001b[38;5;5mone\u001b[0m\u001b[1m\u001b[38;5;14m acet\u001b[0m\u001b[1m\u001b[38;5;13myl\u001b[0m\u001b[1m\u001b[38;5;13mation\u001b[0m\u001b[1m\u001b[38;5;13m levels\u001b[0m, normalized against\u001b[1m\u001b[38;5;4m hist\u001b[0m\u001b[1m\u001b[38;5;3mone\u001b[0m\u001b[1m\u001b[38;5;3m H\u001b[0m\u001b[1m\u001b[38;5;3m4\u001b[0m levels for quantification. Average of at least 3 experiments. Error bars represent SEM. Significant differences between UV-irradiated and inhibitor treated conditions are indicated with * (p<0.1) </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>\u001b[1m\u001b[4m\u001b[38;5;4mG\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m trap\u001b[1m\u001b[4m\u001b[38;5;14m IP\u001b[0m of WT, Q78L and T33N\u001b[1m\u001b[4m\u001b[38;5;4m R\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mAB\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m21\u001b[0m variants in\u001b[1m\u001b[4m\u001b[38;5;8m He\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mLa\u001b[0m cells followed by\u001b[1m\u001b[4m\u001b[38;5;4m G\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;14m immun\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mob\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mlot\u001b[0m and (C)\u001b[1m\u001b[4m\u001b[38;5;4m FAM\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m21\u001b[0m,\u001b[1m\u001b[4m\u001b[38;5;4m Str\u001b[0m\u001b[1m\u001b[38;5;1mum\u001b[0m\u001b[1m\u001b[38;5;1mpell\u001b[0m\u001b[1m\u001b[38;5;1min\u001b[0m and\u001b[1m\u001b[4m\u001b[38;5;4m V\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mPS\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m35\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;14m immun\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mobl\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mots\u001b[0m. Lysates correspond to 5% of input, n�� 3 independent experiments. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(D) The\u001b[1m\u001b[4m\u001b[38;5;6m spine\u001b[0m head width distribution7differed significantly between the genotypes (n= 467\u001b[1m\u001b[4m\u001b[38;5;6m sp\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;5mines\u001b[0m from WT and n = 421\u001b[1m\u001b[4m\u001b[38;5;6m sp\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;5mines\u001b[0m from\u001b[1m\u001b[4m\u001b[38;5;4m CA\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m7\u001b[0m KO animals, 15\u001b[1m\u001b[4m\u001b[38;5;8m neurons\u001b[0m analyzed from both genotypes, Wilcoxon rank sum test with continuity correction, W = 134540, P < 0.001). </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>A, The CBS-pair domain (yellow) forms a dimer and binds two molecules of PRL2 via an extended loop. The positions of the PRL2 C-terminal CAAX prenylation motif [42] and CNNM3 N-terminus suggest that the membrane would sit above the complex. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(G) Peak values of\u001b[1m\u001b[4m\u001b[38;5;2m Ca\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m2\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m+\u001b[0m transients in\u001b[1m\u001b[4m\u001b[38;5;8m ME\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mFs\u001b[0m transfected with synthetic tethering protein (\u001b[1m\u001b[4m\u001b[38;5;4mT\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mOM\u001b[0m-\u001b[1m\u001b[4m\u001b[38;5;4mm\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mR\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m-\u001b[1m\u001b[38;5;4mER\u001b[0m) to induce artificial tethering of the\u001b[1m\u001b[4m\u001b[38;5;6m ER\u001b[0m and\u001b[1m\u001b[4m\u001b[38;5;6m mitochond\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;5mria\u001b[0m. Error bars represent ±SD from six independent experiments. Data information: For graph the P values was determined by a Mann-Whitney U test. ns = not significant, *P < 0.05, **P < 0.01 </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>B\u001b[1m\u001b[38;5;14m Immun\u001b[0m\u001b[1m\u001b[38;5;13most\u001b[0m\u001b[1m\u001b[38;5;13maining\u001b[0m of\u001b[1m\u001b[4m\u001b[38;5;4m PP\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mAR\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m-\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mα\u001b[0m\u001b[1m\u001b[38;5;14m expression\u001b[0m in\u001b[1m\u001b[4m\u001b[38;5;10m W\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9mAT\u001b[0m from WT and\u001b[1m\u001b[4m\u001b[38;5;4m F\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mADD\u001b[0m-D\u001b[1m\u001b[4m\u001b[38;5;12m mice\u001b[0m (Scale bars = 50 μm). Shown are typical results from four different fields and three different experiments. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>\u001b[1m\u001b[4m\u001b[38;5;14mMicro\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mgraph\u001b[0m of coronal sections of E17\u001b[1m\u001b[4m\u001b[38;5;12m mouse\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;10m cerebral\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9m cort\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9mices\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;14m elect\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mrop\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mor\u001b[0mated at E14 co-elect\u001b[1m\u001b[4m\u001b[38;5;13mrop\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mor\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mated\u001b[0m with\u001b[1m\u001b[4m\u001b[38;5;4m m\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mC\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mherry\u001b[0m expressing vector and\u001b[1m\u001b[4m\u001b[38;5;4m HA\u001b[0m-\u001b[1m\u001b[4m\u001b[38;5;4mC\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mst\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mb\u001b[0m or R68X, and analyzed 3 dpe.\u001b[1m\u001b[4m\u001b[38;5;14m Immun\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13most\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13maining\u001b[0m with\u001b[1m\u001b[4m\u001b[38;5;4m R\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m to identify\u001b[1m\u001b[4m\u001b[38;5;14m elect\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mrop\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mor\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;13mated\u001b[0m cells and\u001b[1m\u001b[4m\u001b[38;5;4m G\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m to identify migrating\u001b[1m\u001b[4m\u001b[38;5;8m inter\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mne\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mur\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mons\u001b[0m in the\u001b[1m\u001b[4m\u001b[38;5;4m G\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mAD\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m65\u001b[0m-\u001b[1m\u001b[4m\u001b[38;5;4mG\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m transgenic\u001b[1m\u001b[4m\u001b[38;5;12m mouse\u001b[0m line.\u001b[1m\u001b[4m\u001b[38;5;10m Vent\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9mric\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9mle\u001b[0m (\u001b[1m\u001b[38;5;10mV\u001b[0m) is indicated. The dashed lines represent the apical surface of the\u001b[1m\u001b[4m\u001b[38;5;10m vent\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9mric\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;9mles\u001b[0m. Quantification of the total number of\u001b[1m\u001b[4m\u001b[38;5;4m G\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mAD\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m65\u001b[0m-\u001b[1m\u001b[4m\u001b[38;5;4mG\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;8m inter\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mne\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mur\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;7mons\u001b[0m/\u001b[1m\u001b[4m\u001b[38;5;10m cortical\u001b[0m area (��m2) in (N). Data shown as Z-scores relative to the mean of\u001b[1m\u001b[4m\u001b[38;5;4m G\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3mFP\u001b[0m control vector.\u001b[1m\u001b[4m\u001b[38;5;6m N\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;5mucle\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;5mi\u001b[0m (blue) are\u001b[1m\u001b[4m\u001b[38;5;14m stained\u001b[0m with\u001b[1m\u001b[4m\u001b[38;5;2m D\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1mAPI\u001b[0m. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /tokcl_models/NER\n",
      "Configuration saved in /tokcl_models/NER/config.json\n",
      "Model weights saved in /tokcl_models/NER/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7178\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 7178.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "          CELL       0.69      0.81      0.74      5245\n",
      "     EXP_ASSAY       0.56      0.57      0.56     10067\n",
      "      GENEPROD       0.77      0.89      0.82     23587\n",
      "      ORGANISM       0.72      0.82      0.77      3623\n",
      "SMALL_MOLECULE       0.70      0.80      0.75      6187\n",
      "   SUBCELLULAR       0.65      0.72      0.69      3700\n",
      "        TISSUE       0.62      0.73      0.67      3207\n",
      "\n",
      "     micro avg       0.70      0.79      0.74     55616\n",
      "     macro avg       0.67      0.77      0.72     55616\n",
      "  weighted avg       0.70      0.79      0.74     55616\n",
      "\n",
      "{'test_loss': 0.1830928772687912, 'test_accuracy_score': 0.9334821000160841, 'test_precision': 0.6987463009514112, 'test_recall': 0.789682825086306, 'test_f1': 0.7414366506288511, 'test_runtime': 61.0547, 'test_samples_per_second': 117.567, 'test_steps_per_second': 1.851}\n"
     ]
    }
   ],
   "source": [
    "train_tokcl(\n",
    "    training_args,\n",
    "    loader_path,\n",
    "    \"NER\",\n",
    "    tokenized_panel_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1064788f",
   "metadata": {},
   "source": [
    "#### Train GENEPROD ROLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "c4323e6c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsTOKCL(output_dir='/tokcl_models', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=0.9, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/tokcl_models/runs/Mar06_14-19-46_5aebd0ba4077', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=20, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=50, dataloader_num_workers=0, past_index=-1, run_name='/tokcl_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', masking_probability=1.0, replacement_probability=0.0, select_labels=False)"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.num_train_epochs = 0.9\n",
    "training_args.prediction_loss_only=True\n",
    "training_args.masking_probability=1.\n",
    "training_args.replacement_probability=.0\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "39ec90dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/tokcl_models'"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.output_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4dbc93fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Using custom data configuration GENEPROD_ROLES-ff39ee0af78a5a25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /tokcl_models/GENEPROD_ROLES.\n",
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading and tokenizing datasets found in /data/json/220304_sd_panels.\n",
      "using ./smtag/loader/loader_tokcl.py as dataset loader.\n",
      "Downloading and preparing dataset source_data_nlp/GENEPROD_ROLES (download: Unknown size, generated: 88.01 MiB, post-processed: Unknown size, total: 88.01 MiB) to /cache/source_data_nlp/GENEPROD_ROLES-ff39ee0af78a5a25/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset source_data_nlp downloaded and prepared to /cache/source_data_nlp/GENEPROD_ROLES-ff39ee0af78a5a25/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5ceb90c546234d6b8f36b870ce404ce2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 48771 examples.\n",
      "Evaluating on 13801 examples.\n",
      "\n",
      "Training on 5 features:\n",
      "O, I-CONTROLLED_VAR, B-CONTROLLED_VAR, I-MEASURED_VAR, B-MEASURED_VAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/EMBO/bio-lm/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/09fed88b4a07fe6baced126e3cdb14f2764c1bc57f62d1026a75b3ffdb3ec5f8.c781727f43e25ac5b298f775b2dd4f32f53c9890a2367bbd99ffdbd856251b85\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/EMBO/bio-lm/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/f61ee36e7d211df88e7eb67c937348fbd256ab3a970d6b3c9848181ed0330c27.12bb7cf77356bf912ed8598fb9a17becaa7e7c5406692af7264c45956cde2cf3\n",
      "Some weights of the model checkpoint at EMBO/bio-lm were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at EMBO/bio-lm and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 48771\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 687\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training arguments for model type Autoencoder:\n",
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "TrainingArgumentsTOKCL(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/runs/tokcl-GENEPROD_ROLES-2022-03-06T16-18-57.844509,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "masking_probability=1.0,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=0.9,\n",
      "output_dir=/tokcl_models/GENEPROD_ROLES,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=True,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=False,\n",
      "replacement_probability=0.0,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tokcl_models,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "select_labels=False,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "CUDA available: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='687' max='687' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [687/687 17:46, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.067200</td>\n",
       "      <td>0.051036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.047600</td>\n",
       "      <td>0.049618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.051100</td>\n",
       "      <td>0.048770</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.044700</td>\n",
       "      <td>0.048524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.044200</td>\n",
       "      <td>0.043310</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>300</td>\n",
       "      <td>0.046500</td>\n",
       "      <td>0.042613</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>350</td>\n",
       "      <td>0.044400</td>\n",
       "      <td>0.043183</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>400</td>\n",
       "      <td>0.042200</td>\n",
       "      <td>0.040875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>450</td>\n",
       "      <td>0.035300</td>\n",
       "      <td>0.041622</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>500</td>\n",
       "      <td>0.038400</td>\n",
       "      <td>0.040560</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>550</td>\n",
       "      <td>0.038500</td>\n",
       "      <td>0.040352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>600</td>\n",
       "      <td>0.038200</td>\n",
       "      <td>0.040379</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>650</td>\n",
       "      <td>0.037300</td>\n",
       "      <td>0.039998</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>C Dynamic exchange of a misfolded model protein between cytosol and nucleus. FLIP measurements of\u001b[1m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[38;5;3m<mask>\u001b[0m‐\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m were performed in S. cerevisiae wild‐type cells at 30°C. Nuclear or cytosolic areas were bleached, and loss of fluorescence intensities in non‐bleached compartments was determined. Bleaching and acquisition controls are given. Error bars: SEM. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(L) Inhibition of myosin II activity increased sensitivity to starvation. Flies carrying transgenes under the control of fat body‐specific<mask><mask>-\u001b[1m\u001b[38;5;2m<mask>\u001b[0m\u001b[1m\u001b[38;5;1m<mask>\u001b[0m\u001b[1m\u001b[38;5;1m<mask>\u001b[0m driver were used for further analysis. Histogram illustrating the survival curve of adult female flies of denoted genotypes when placed under starved conditions. Data are mean±s.e. from triplicate experiments (n=100 flies/genotype/treatment). *P0.05, **P0.01, ***P0.001. See Supplementary data for genotypes. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(B) Quantified histone acetylation levels, normalized against histone H4 levels for quantification. Average of at least 3 experiments. Error bars represent SEM. Significant differences between UV-irradiated and inhibitor treated conditions are indicated with * (p<0.1) </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s><mask><mask> trap IP of WT, Q78L and T33N\u001b[1m\u001b[4m\u001b[38;5;2m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m<mask>\u001b[0m variants in HeLa cells followed by\u001b[1m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[38;5;3m<mask>\u001b[0m immunoblot and (C)\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m,\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m and\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m immunoblots. Lysates correspond to 5% of input, n�� 3 independent experiments. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(D) The spine head width distribution7differed significantly between the genotypes (n= 467 spines from WT and n = 421 spines from\u001b[1m\u001b[4m\u001b[38;5;2m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m<mask>\u001b[0m KO animals, 15 neurons analyzed from both genotypes, Wilcoxon rank sum test with continuity correction, W = 134540, P < 0.001). </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>A, The CBS-pair domain (yellow) forms a dimer and binds two molecules of\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m via an extended loop. The positions of the\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m C-terminal CAAX prenylation motif [42] and\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m N-terminus suggest that the membrane would sit above the complex. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(G) Peak values of Ca2+ transients in MEFs transfected with synthetic tethering protein (<mask><mask>-\u001b[1m\u001b[38;5;2m<mask>\u001b[0m\u001b[1m\u001b[38;5;1m<mask>\u001b[0m\u001b[1m\u001b[38;5;1m<mask>\u001b[0m-ER) to induce artificial tethering of the ER and mitochondria. Error bars represent ±SD from six independent experiments. Data information: For graph the P values was determined by a Mann-Whitney U test. ns = not significant, *P < 0.05, **P < 0.01 </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>B Immunostaining of\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m expression in WAT from WT and\u001b[1m\u001b[4m\u001b[38;5;2m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m<mask>\u001b[0m-D mice (Scale bars = 50 μm). Shown are typical results from four different fields and three different experiments. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>Micrograph of coronal sections of E17 mouse cerebral cortices electroporated at E14 co-electroporated with<mask><mask><mask> expressing vector and<mask>-\u001b[1m\u001b[4m\u001b[38;5;2m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m<mask>\u001b[0m or R68X, and analyzed 3 dpe. Immunostaining with\u001b[1m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[38;5;3m<mask>\u001b[0m to identify electroporated cells and\u001b[1m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[38;5;3m<mask>\u001b[0m to identify migrating interneurons in the\u001b[1m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[38;5;3m<mask>\u001b[0m-<mask><mask> transgenic mouse line. Ventricle (V) is indicated. The dashed lines represent the apical surface of the ventricles. Quantification of the total number of\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m-<mask><mask> interneurons/ cortical area (��m2) in (N). Data shown as Z-scores relative to the mean of<mask><mask> control vector. Nuclei (blue) are stained with DAPI. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>A. Condensin binding assessed by ChIP against\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m-<mask><mask>. Mitotic indexes are indicated in parentheses. %IP are averages and s.d. calculated from 12 ChIPs on 6 biological replicates. For repeated\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m and\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m genes, qPCR primers were designed within adjacent, unique 5' intergenic sequences. Note the use of different scales in the arm: high-occupancy and arm: low-occupancy panels. *** P<0.001, ** P<0.01, ° P>0.05. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving model checkpoint to /tokcl_models/GENEPROD_ROLES/checkpoint-500\n",
      "Configuration saved in /tokcl_models/GENEPROD_ROLES/checkpoint-500/config.json\n",
      "Model weights saved in /tokcl_models/GENEPROD_ROLES/checkpoint-500/pytorch_model.bin\n",
      "/opt/conda/lib/python3.8/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n",
      "  warnings.warn('Was asked to gather along dimension 0, but all '\n",
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(L) Inhibition of myosin II activity increased sensitivity to starvation. Flies carrying transgenes under the control of fat body‐specific<mask><mask>-<mask><mask><mask> driver were used for further analysis. Histogram illustrating the survival curve of adult female flies of denoted genotypes when placed under starved conditions. Data are mean±s.e. from triplicate experiments (n=100 flies/genotype/treatment). *P0.05, **P0.01, ***P0.001. See Supplementary data for genotypes. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>B Immunostaining of\u001b[1m\u001b[4m\u001b[38;5;4m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;3m<mask>\u001b[0m expression in WAT from WT and\u001b[1m\u001b[4m\u001b[38;5;2m<mask>\u001b[0m\u001b[1m\u001b[4m\u001b[38;5;1m<mask>\u001b[0m-D mice (Scale bars = 50 μm). Shown are typical results from four different fields and three different experiments. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>We suggest that H3.3-containing nucleosome cores (pink) are more likely to be dynamically exchanged than canonical H3-containing cores (blue) resulting in a greater probability that DNA can become single stranded either as a result of pausing of RNAPII or of transcription-induced negative supercoiling generating transient denaturation bubbles. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /tokcl_models/GENEPROD_ROLES\n",
      "Configuration saved in /tokcl_models/GENEPROD_ROLES/config.json\n",
      "Model weights saved in /tokcl_models/GENEPROD_ROLES/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7178\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 7178.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 00:25]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "CONTROLLED_VAR       0.81      0.86      0.83      7835\n",
      "  MEASURED_VAR       0.82      0.85      0.84      9330\n",
      "\n",
      "     micro avg       0.82      0.85      0.83     17165\n",
      "     macro avg       0.82      0.85      0.83     17165\n",
      "  weighted avg       0.82      0.85      0.83     17165\n",
      "\n",
      "{'test_loss': 0.03846803680062294, 'test_accuracy_score': 0.9854472664459946, 'test_precision': 0.8156312625250501, 'test_recall': 0.8535974366443344, 'test_f1': 0.8341825841897008, 'test_runtime': 58.7369, 'test_samples_per_second': 122.206, 'test_steps_per_second': 1.924}\n"
     ]
    }
   ],
   "source": [
    "train_tokcl(\n",
    "    training_args,\n",
    "    loader_path,\n",
    "    \"GENEPROD_ROLES\",\n",
    "    tokenized_panel_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f3a6f5",
   "metadata": {},
   "source": [
    "### Train SMALL MOL ROLES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "95a88724",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsTOKCL(output_dir='/tokcl_models', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=0.33, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/tokcl_models/runs/Mar06_14-19-46_5aebd0ba4077', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=20, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=50, dataloader_num_workers=0, past_index=-1, run_name='/tokcl_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', masking_probability=1.0, replacement_probability=0.0, select_labels=False)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.num_train_epochs = 0.33\n",
    "training_args.prediction_loss_only=True\n",
    "training_args.masking_probability=1.0\n",
    "training_args.replacement_probability=.0\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "eee8b746",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/datasets/load.py:1650: FutureWarning: 'script_version' was renamed to 'revision' in version 1.13 and will be removed in 1.15.\n",
      "  warnings.warn(\n",
      "WARNING:Using custom data configuration SMALL_MOL_ROLES-ff39ee0af78a5a25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /tokcl_models/SMALL_MOL_ROLES.\n",
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading and tokenizing datasets found in /data/json/220304_sd_panels.\n",
      "using ./smtag/loader/loader_tokcl.py as dataset loader.\n",
      "Downloading and preparing dataset source_data_nlp/SMALL_MOL_ROLES (download: Unknown size, generated: 88.01 MiB, post-processed: Unknown size, total: 88.01 MiB) to /cache/source_data_nlp/SMALL_MOL_ROLES-ff39ee0af78a5a25/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset source_data_nlp downloaded and prepared to /cache/source_data_nlp/SMALL_MOL_ROLES-ff39ee0af78a5a25/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f714e377dc64443ba6ea9c371a6ad7cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 48771 examples.\n",
      "Evaluating on 13801 examples.\n",
      "\n",
      "Training on 5 features:\n",
      "O, I-CONTROLLED_VAR, B-CONTROLLED_VAR, I-MEASURED_VAR, B-MEASURED_VAR\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/EMBO/bio-lm/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/09fed88b4a07fe6baced126e3cdb14f2764c1bc57f62d1026a75b3ffdb3ec5f8.c781727f43e25ac5b298f775b2dd4f32f53c9890a2367bbd99ffdbd856251b85\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/EMBO/bio-lm/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/f61ee36e7d211df88e7eb67c937348fbd256ab3a970d6b3c9848181ed0330c27.12bb7cf77356bf912ed8598fb9a17becaa7e7c5406692af7264c45956cde2cf3\n",
      "Some weights of the model checkpoint at EMBO/bio-lm were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at EMBO/bio-lm and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 48771\n",
      "  Num Epochs = 1\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 252\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training arguments for model type Autoencoder:\n",
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"LABEL_0\",\n",
      "    \"1\": \"LABEL_1\",\n",
      "    \"2\": \"LABEL_2\",\n",
      "    \"3\": \"LABEL_3\",\n",
      "    \"4\": \"LABEL_4\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"LABEL_0\": 0,\n",
      "    \"LABEL_1\": 1,\n",
      "    \"LABEL_2\": 2,\n",
      "    \"LABEL_3\": 3,\n",
      "    \"LABEL_4\": 4\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "TrainingArgumentsTOKCL(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/runs/tokcl-SMALL_MOL_ROLES-2022-03-06T16-38-59.212302,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "masking_probability=1.0,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=0.33,\n",
      "output_dir=/tokcl_models/SMALL_MOL_ROLES,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=True,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=False,\n",
      "replacement_probability=0.0,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tokcl_models,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "select_labels=False,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "CUDA available: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='252' max='252' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [252/252 06:41, Epoch 0/1]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.020300</td>\n",
       "      <td>0.018082</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.015700</td>\n",
       "      <td>0.015909</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.013400</td>\n",
       "      <td>0.013600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.012700</td>\n",
       "      <td>0.012641</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>250</td>\n",
       "      <td>0.012100</td>\n",
       "      <td>0.012329</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>C Dynamic exchange of a misfolded model protein between cytosol and nucleus. FLIP measurements of mCherry‐VHL were performed in S. cerevisiae wild‐type cells at 30°C. Nuclear or cytosolic areas were bleached, and loss of fluorescence intensities in non‐bleached compartments was determined. Bleaching and acquisition controls are given. Error bars: SEM. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(L) Inhibition of myosin II activity increased sensitivity to starvation. Flies carrying transgenes under the control of fat body‐specific Cg-GAL4 driver were used for further analysis. Histogram illustrating the survival curve of adult female flies of denoted genotypes when placed under starved conditions. Data are mean±s.e. from triplicate experiments (n=100 flies/genotype/treatment). *P0.05, **P0.01, ***P0.001. See Supplementary data for genotypes. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(B) Quantified histone acetylation levels, normalized against histone H4 levels for quantification. Average of at least 3 experiments. Error bars represent SEM. Significant differences between UV-irradiated and inhibitor treated conditions are indicated with * (p<0.1) </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>GFP trap IP of WT, Q78L and T33N RAB21 variants in HeLa cells followed by GFP immunoblot and (C) FAM21, Strumpellin and VPS35 immunoblots. Lysates correspond to 5% of input, n�� 3 independent experiments. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 13801\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>(D) The spine head width distribution7differed significantly between the genotypes (n= 467 spines from WT and n = 421 spines from CA7 KO animals, 15 neurons analyzed from both genotypes, Wilcoxon rank sum test with continuity correction, W = 134540, P < 0.001). </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /tokcl_models/SMALL_MOL_ROLES\n",
      "Configuration saved in /tokcl_models/SMALL_MOL_ROLES/config.json\n",
      "Model weights saved in /tokcl_models/SMALL_MOL_ROLES/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 7178\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 7178.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='113' max='113' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [113/113 00:26]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                \n",
      "                precision    recall  f1-score   support\n",
      "\n",
      "CONTROLLED_VAR       0.76      0.90      0.83      2946\n",
      "  MEASURED_VAR       0.60      0.71      0.65       852\n",
      "\n",
      "     micro avg       0.73      0.86      0.79      3798\n",
      "     macro avg       0.68      0.80      0.74      3798\n",
      "  weighted avg       0.73      0.86      0.79      3798\n",
      "\n",
      "{'test_loss': 0.011743436567485332, 'test_accuracy_score': 0.9951612532624371, 'test_precision': 0.7261345852895149, 'test_recall': 0.8551869404949973, 'test_f1': 0.7853947527505744, 'test_runtime': 58.0378, 'test_samples_per_second': 123.678, 'test_steps_per_second': 1.947}\n"
     ]
    }
   ],
   "source": [
    "train_tokcl(\n",
    "    training_args,\n",
    "    loader_path,\n",
    "    \"SMALL_MOL_ROLES\",\n",
    "    tokenized_panel_examples,\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4265fb44",
   "metadata": {},
   "source": [
    "### Train PANELIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "6b63bae1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TrainingArgumentsTOKCL(output_dir='/tokcl_models', overwrite_output_dir=False, do_train=False, do_eval=True, do_predict=False, evaluation_strategy=<IntervalStrategy.STEPS: 'steps'>, prediction_loss_only=True, per_device_train_batch_size=16, per_device_eval_batch_size=16, per_gpu_train_batch_size=None, per_gpu_eval_batch_size=None, gradient_accumulation_steps=1, eval_accumulation_steps=None, learning_rate=0.0001, weight_decay=0.0, adam_beta1=0.9, adam_beta2=0.999, adam_epsilon=1e-08, max_grad_norm=1.0, num_train_epochs=1.3, max_steps=-1, lr_scheduler_type=<SchedulerType.LINEAR: 'linear'>, warmup_ratio=0.0, warmup_steps=0, log_level=-1, log_level_replica=-1, log_on_each_node=True, logging_dir='/tokcl_models/runs/Mar06_14-19-46_5aebd0ba4077', logging_strategy=<IntervalStrategy.STEPS: 'steps'>, logging_first_step=False, logging_steps=20, logging_nan_inf_filter=True, save_strategy=<IntervalStrategy.STEPS: 'steps'>, save_steps=500, save_total_limit=5, save_on_each_node=False, no_cuda=False, seed=42, bf16=False, fp16=False, fp16_opt_level='O1', half_precision_backend='auto', bf16_full_eval=False, fp16_full_eval=False, tf32=None, local_rank=-1, xpu_backend=None, tpu_num_cores=None, tpu_metrics_debug=False, debug=[], dataloader_drop_last=False, eval_steps=50, dataloader_num_workers=0, past_index=-1, run_name='/tokcl_models', disable_tqdm=False, remove_unused_columns=True, label_names=None, load_best_model_at_end=False, metric_for_best_model=None, greater_is_better=None, ignore_data_skip=False, sharded_ddp=[], deepspeed=None, label_smoothing_factor=0.0, adafactor=False, group_by_length=False, length_column_name='length', report_to=['tensorboard'], ddp_find_unused_parameters=None, ddp_bucket_cap_mb=None, dataloader_pin_memory=True, skip_memory_metrics=True, use_legacy_prediction_loop=False, push_to_hub=False, resume_from_checkpoint=None, hub_model_id=None, hub_strategy=<HubStrategy.EVERY_SAVE: 'every_save'>, hub_token=None, gradient_checkpointing=False, fp16_backend='auto', push_to_hub_model_id=None, push_to_hub_organization=None, push_to_hub_token=None, mp_parameters='', masking_probability=0.0, replacement_probability=0.0, select_labels=False)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_args.num_train_epochs = 1.3\n",
    "training_args.prediction_loss_only=True\n",
    "training_args.masking_probability=.0\n",
    "training_args.replacement_probability=.0\n",
    "training_args.logging_steps=20\n",
    "training_args"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3660eb7b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:Using custom data configuration PANELIZATION-3c1c867cbe013e60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created /tokcl_models/PANELIZATION.\n",
      "tokenizer vocab size: 50265\n",
      "\n",
      "Loading and tokenizing datasets found in /data/json/220304_sd_fig.\n",
      "using ./smtag/loader/loader_tokcl.py as dataset loader.\n",
      "Downloading and preparing dataset source_data_nlp/PANELIZATION (download: Unknown size, generated: 79.20 MiB, post-processed: Unknown size, total: 79.20 MiB) to /cache/source_data_nlp/PANELIZATION-3c1c867cbe013e60/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "0 examples [00:00, ? examples/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset source_data_nlp downloaded and prepared to /cache/source_data_nlp/PANELIZATION-3c1c867cbe013e60/0.0.1/be20c29bc25cb738f99d32581855842b36617d57e5a36ca1d6b98499db149e83. Subsequent calls will reuse this data.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e6b526323016480db24816ce91a0d0c9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/3 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training with 12108 examples.\n",
      "Evaluating on 3439 examples.\n",
      "\n",
      "Training on 2 features:\n",
      "O, B-PANEL_START\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loading configuration file https://huggingface.co/EMBO/bio-lm/resolve/main/config.json from cache at /root/.cache/huggingface/transformers/09fed88b4a07fe6baced126e3cdb14f2764c1bc57f62d1026a75b3ffdb3ec5f8.c781727f43e25ac5b298f775b2dd4f32f53c9890a2367bbd99ffdbd856251b85\n",
      "Model config RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "loading weights file https://huggingface.co/EMBO/bio-lm/resolve/main/pytorch_model.bin from cache at /root/.cache/huggingface/transformers/f61ee36e7d211df88e7eb67c937348fbd256ab3a970d6b3c9848181ed0330c27.12bb7cf77356bf912ed8598fb9a17becaa7e7c5406692af7264c45956cde2cf3\n",
      "Some weights of the model checkpoint at EMBO/bio-lm were not used when initializing RobertaForTokenClassification: ['lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.decoder.weight', 'lm_head.decoder.bias', 'lm_head.bias', 'lm_head.dense.bias', 'lm_head.dense.weight']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at EMBO/bio-lm and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
      "***** Running training *****\n",
      "  Num examples = 12108\n",
      "  Num Epochs = 2\n",
      "  Instantaneous batch size per device = 16\n",
      "  Total train batch size (w. parallel, distributed & accumulation) = 64\n",
      "  Gradient Accumulation steps = 1\n",
      "  Total optimization steps = 247\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training arguments for model type Autoencoder:\n",
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"EMBO/bio-lm\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"gradient_checkpointing\": false,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.15.0\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n",
      "TrainingArgumentsTOKCL(\n",
      "_n_gpu=4,\n",
      "adafactor=False,\n",
      "adam_beta1=0.9,\n",
      "adam_beta2=0.999,\n",
      "adam_epsilon=1e-08,\n",
      "bf16=False,\n",
      "bf16_full_eval=False,\n",
      "dataloader_drop_last=False,\n",
      "dataloader_num_workers=0,\n",
      "dataloader_pin_memory=True,\n",
      "ddp_bucket_cap_mb=None,\n",
      "ddp_find_unused_parameters=None,\n",
      "debug=[],\n",
      "deepspeed=None,\n",
      "disable_tqdm=False,\n",
      "do_eval=True,\n",
      "do_predict=False,\n",
      "do_train=False,\n",
      "eval_accumulation_steps=None,\n",
      "eval_steps=50,\n",
      "evaluation_strategy=IntervalStrategy.STEPS,\n",
      "fp16=False,\n",
      "fp16_backend=auto,\n",
      "fp16_full_eval=False,\n",
      "fp16_opt_level=O1,\n",
      "gradient_accumulation_steps=1,\n",
      "gradient_checkpointing=False,\n",
      "greater_is_better=None,\n",
      "group_by_length=False,\n",
      "half_precision_backend=auto,\n",
      "hub_model_id=None,\n",
      "hub_strategy=HubStrategy.EVERY_SAVE,\n",
      "hub_token=<HUB_TOKEN>,\n",
      "ignore_data_skip=False,\n",
      "label_names=None,\n",
      "label_smoothing_factor=0.0,\n",
      "learning_rate=0.0001,\n",
      "length_column_name=length,\n",
      "load_best_model_at_end=False,\n",
      "local_rank=-1,\n",
      "log_level=-1,\n",
      "log_level_replica=-1,\n",
      "log_on_each_node=True,\n",
      "logging_dir=/runs/tokcl-PANELIZATION-2022-03-06T16-47-54.381053,\n",
      "logging_first_step=False,\n",
      "logging_nan_inf_filter=True,\n",
      "logging_steps=20,\n",
      "logging_strategy=IntervalStrategy.STEPS,\n",
      "lr_scheduler_type=SchedulerType.LINEAR,\n",
      "masking_probability=0.0,\n",
      "max_grad_norm=1.0,\n",
      "max_steps=-1,\n",
      "metric_for_best_model=None,\n",
      "mp_parameters=,\n",
      "no_cuda=False,\n",
      "num_train_epochs=1.3,\n",
      "output_dir=/tokcl_models/PANELIZATION,\n",
      "overwrite_output_dir=False,\n",
      "past_index=-1,\n",
      "per_device_eval_batch_size=16,\n",
      "per_device_train_batch_size=16,\n",
      "prediction_loss_only=True,\n",
      "push_to_hub=False,\n",
      "push_to_hub_model_id=None,\n",
      "push_to_hub_organization=None,\n",
      "push_to_hub_token=<PUSH_TO_HUB_TOKEN>,\n",
      "remove_unused_columns=False,\n",
      "replacement_probability=0.0,\n",
      "report_to=['tensorboard'],\n",
      "resume_from_checkpoint=None,\n",
      "run_name=/tokcl_models,\n",
      "save_on_each_node=False,\n",
      "save_steps=500,\n",
      "save_strategy=IntervalStrategy.STEPS,\n",
      "save_total_limit=5,\n",
      "seed=42,\n",
      "select_labels=False,\n",
      "sharded_ddp=[],\n",
      "skip_memory_metrics=True,\n",
      "tf32=None,\n",
      "tpu_metrics_debug=False,\n",
      "tpu_num_cores=None,\n",
      "use_legacy_prediction_loop=False,\n",
      "warmup_ratio=0.0,\n",
      "warmup_steps=0,\n",
      "weight_decay=0.0,\n",
      "xpu_backend=None,\n",
      ")\n",
      "CUDA available: True\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='247' max='247' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [247/247 03:35, Epoch 1/2]\n",
       "    </div>\n",
       "    <table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>Step</th>\n",
       "      <th>Training Loss</th>\n",
       "      <th>Validation Loss</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>50</td>\n",
       "      <td>0.008100</td>\n",
       "      <td>0.005786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>100</td>\n",
       "      <td>0.005000</td>\n",
       "      <td>0.005296</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>150</td>\n",
       "      <td>0.004100</td>\n",
       "      <td>0.003879</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>200</td>\n",
       "      <td>0.003700</td>\n",
       "      <td>0.003628</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table><p>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>.Figure 1\u001b[1m\u001b[4m\u001b[38;5;1m(\u001b[0mA) Topo II activity on random juxtapositions of DNA segments (*) produces steady-state fractions of DNA knots in intracellular chromatin.\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mB) DNA knotting probability (Pkn) of intracellular chromatin (observed) does not scale proportionally to the length of DNA (expected). The slope of Pkn is reduced in chromatin stretches larger than 20 nucleosomes. Data from (Valdes et al., 2018).\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mC) Three-gate mechanism of topo II to pass one segment of DNA (T-segment) through another (G-segment). Upon ATP binding, the T-segment is captured by the entrance gate (N-gate) and passed through the transiently cleaved G-segment (DNA-gate). Upon re-ligation of the G-segment, the T-segment is released through the exit gate (C-gate).\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mD) Topo II activity reduces the fractions of DNA supercoils, knots and catenates to below the topological equilibrium values (see details in Fig EV1).\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mE) Architecture of the SMC complexes of S. cerevisiae. The Smc heterodimers (Smc1-Smc3, Smc2-Smc4, Smc5-Smc6) and kleisin (Scc1, Brn1, Nse4) subunits of cohesin, condensin and the Smc5/6 complex are indicated. (F) SMC complexes entrap segments of DNA to form chromatin loops and/or bridge nearby chromatin domains. Their loop extrusion activity (LE) ensures the co-entrapment of contiguously oriented intramolecular DNA segments. </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>.Figure 6\u001b[1m\u001b[4m\u001b[38;5;1m(\u001b[0mA) Percentage of regenerating axons after laser axotomy of DIV 14-17 rat cortical neurons expressing either GFP (control) or GFP and p110�� in the presence of the indicated inhibitors, 14h after laser injury. Numbers on bars are injured axons per group.\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mB) Single confocal section through a DIV 16 neuron expressing p110�� and GFP (upper panels). Green colour is GFP, red is overexpressed p110��, detected with anti-p110��. Lower panels show p110�� and GFP in a distal axon section, and at the growth cone. Arrow indicates the axon.\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mC) Active ARF and total ARF6 (red) in axons of DIV 16 rat cortical neurons expressing GFP or GFP and p110��, as indicated. Arrows indicate axons.\u001b[1m\u001b[38;5;1m (\u001b[0mD) Quantification of mean axonal ARF activity and total (mean) ARF6 in DIV 16 neurons expressing GFP or GFP and p110�� n=60 axons for each condition.\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mE) Kymographs showing dynamics of α9 integrin-GFP in the distal axons of DIV 14-16 neurons, control or co-transfected with p110��.\u001b[1m\u001b[38;5;1m (\u001b[0mF) Quantification of α9 integrin-GFP dynamics in the distal axons of DIV 14-16 neurons, control or co-transfected with p110��. n numbers are axon sections analysed for each condition.\u001b[1m\u001b[38;5;1m (\u001b[0mG) Quantification of total α9 integrin-GFP number in the distal axons of DIV 14-16 neurons, control or co-transfected with p110��. n=43 for control, 47 for co-transfected with p110��. n numbers are axon sections analysed for each condition.\u001b[1m\u001b[38;5;1m (\u001b[0mH) Kymographs showing dynamics of Rab11-GFP in the distal axons of DIV 14-16 neurons, control or co-transfected with p110��.\u001b[1m\u001b[38;5;1m (\u001b[0mI) Quantification of Rab11-GFP dynamics in the distal axons of DIV 14-16 neurons, control or co-transfected with p110��. n numbers are axon sections analysed for each condition. (J) Quantification of total Rab11-GFP in the distal axons of</s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>a) p35 interacts with EndoB1 in a GST pulldown assay.figf1\u001b[1m\u001b[4m\u001b[38;5;1m(\u001b[0ma) p35 interacts with EndoB1 in a GST pulldown assay.\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mb,c) EndoB1 co-immunoprecipitates (IP) with p35 in COS-7 cell lysates expressing p35 and full-length EndoB1 (b) and adult rat brain lysate (c).\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0md) Putative Cdk5 phosphorylation site(s) in the EndoB1 sequence. Two proline-directed threonine residues (arrows) are present with a Cdk5 consensus site found at Thr 145 (underlined).\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0me) Dose-dependent phosphorylation of EndoB1 by Cdk5/p35 in an in vitro kinase assay.\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mf) Cdk5/p35 phosphorylates EndoB1 at Thr 145 in an in vitro kinase assay.\u001b[1m\u001b[4m\u001b[38;5;1m (\u001b[0mg) Cdk5/p35 phosphorylates EndoB1 at Thr 145 in COS-7 cells. (h) Cdk5 phosphorylates EndoB1 at Thr 145 in Cdk5+/+, but not Cdk5-/- mouse brains. Quantification of p-Thr145-EndoB1 level is shown in the right panel. Data are means ± s.e.m.; n=3. Uncropped images of blots are shown in Supplementary Fig. S8 </s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "***** Running Evaluation *****\n",
      "  Num examples = 3439\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "<s>.Figure 5\u001b[1m\u001b[4m\u001b[38;5;1mA\u001b[0m. Fold change (FC) and significance for transcripts in Kdm6apKO vs. control pancreas. Genes significant at q<0.05 are shown as colored dots above the horizontal line.\u001b[1m\u001b[4m\u001b[38;5;1m B\u001b[0m. GSEA showing that genes specific to differentiated acinar cells were downregulated in KDM6A-deficient pancreas, but not genes specific to islets or duct cells. Upregulated genes were enriched in genes specific to mesenchymal cells. Lineage-enriched genes were obtained from (Muraro et al., 2016).\u001b[1m\u001b[4m\u001b[38;5;1m C\u001b[0m. Most enriched functional annotations in genes differentially expressed in Kdm6apKO.\u001b[1m\u001b[4m\u001b[38;5;1m D\u001b[0m. GSEA showed increased expression of indicated oncogenic pathway genes in Kdm6apKO pancreas.\u001b[1m\u001b[4m\u001b[38;5;1m E\u001b[0m. KDM6A functions as a transcriptional activator of direct target genes in pancreatic cells. Left: Downregulated, but not upregulated, genes in Kdm6apKO pancreas were enriched for KDM6A binding. P-values and odds ratios (O.R.) were calculated by Fisher's exact test. Right: Venn diagrams showing overlap of down and upregulated genes with KDM6A binding.\u001b[1m\u001b[4m\u001b[38;5;1m F\u001b[0m. KDM6A-bound enhancers and promoters showed increased H3K27me3 and decreased H3K27ac in Kdm6apKO pancreas.\u001b[1m\u001b[4m\u001b[38;5;1m G\u001b[0m. Genes that were downregulated in Kdm6apKO pancreas (KDM6A-dependent genes) showed greatest changes in histone marks. Box plots show fold-changes of H3K27me3 (left) and H3K27ac (right) signals in Kdm6apKO compared to control. Signals were analyzed in KDM6A bound regions in promoters and enhancers of genes that were KDM6A dependent (grey; n=420 regions) and independent (white; n=8035 regions). The signals are average values from ChIP-seq experiments in two biological replicates. The horizontal central line marks the median. Box limits indicate the first and third quartiles and whiskers extend to highest and lowest data points within 1.5 x IQR outside box limits. P-values were determined by two-tailed Mann-Whitney U test. H. Changes in KDM6A, H3K27me3 and H3K27ac ChIP-seq profiles in the Ppp4r4-Serpina10 loc</s>\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Training completed. Do not forget to share your model on huggingface.co/models =)\n",
      "\n",
      "\n",
      "Saving model checkpoint to /tokcl_models/PANELIZATION\n",
      "Configuration saved in /tokcl_models/PANELIZATION/config.json\n",
      "Model weights saved in /tokcl_models/PANELIZATION/pytorch_model.bin\n",
      "***** Running Prediction *****\n",
      "  Num examples = 1802\n",
      "  Batch size = 64\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing on 1802.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <div>\n",
       "      \n",
       "      <progress value='29' max='29' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
       "      [29/29 00:07]\n",
       "    </div>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                                                                                \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " PANEL_START       0.89      0.95      0.92      5427\n",
      "\n",
      "   micro avg       0.89      0.95      0.92      5427\n",
      "   macro avg       0.89      0.95      0.92      5427\n",
      "weighted avg       0.89      0.95      0.92      5427\n",
      "\n",
      "{'test_loss': 0.0037643597461283207, 'test_accuracy_score': 0.9986864826439872, 'test_precision': 0.8946091176980413, 'test_recall': 0.9509858116823291, 'test_f1': 0.9219364058592354, 'test_runtime': 33.4943, 'test_samples_per_second': 53.8, 'test_steps_per_second': 0.866}\n"
     ]
    }
   ],
   "source": [
    "train_tokcl(\n",
    "    training_args,\n",
    "    loader_path,\n",
    "    \"PANELIZATION\",\n",
    "    tokenized_figure_examples,  # Use Figure-level data here!\n",
    "    no_cache,\n",
    "    tokenizer,\n",
    "    model_type,\n",
    "    from_pretrained\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "64cd7ff6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GENEPROD_ROLES\tNER  PANELIZATION  SMALL_MOL_ROLES\r\n"
     ]
    }
   ],
   "source": [
    "! ls /tokcl_models/"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89f29c96",
   "metadata": {},
   "source": [
    "### Alternative via CLI:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10d0101d",
   "metadata": {},
   "source": [
    "Useful for testing and debugging from within `tmux` session and `docker-compose exec nlp bash`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2992d00",
   "metadata": {},
   "source": [
    "```bash\n",
    "python -m smtag.cli.tokcl.train \\\n",
    "./smtag/loader/loader_tokcl.py \\\n",
    "PANELIZATION \\\n",
    "--data_dir /data/json/sd_test \\\n",
    "--num_train_epochs=1 \\\n",
    "--logging_steps=50 \\\n",
    "--per_device_train_batch_size=16 \\\n",
    "--per_device_eval_batch_size=16 \\\n",
    "--replacement_probability=0 \\\n",
    "--masking_probability=0 \\\n",
    "--model_type=Autoencoder \\\n",
    "--from_pretrained=\"EMBO/bio-lm\"\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57edf69c",
   "metadata": {},
   "source": [
    "## Try it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f554d12d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from smtag.pipeline import SmartTagger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f59cae2e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "smarttagger = SmartTagger(\n",
    "    tokenizer_source=\"roberta-base\",\n",
    "    panelizer_source=\"/tokcl_models/PANELIZATION\",\n",
    "    ner_source=\"/tokcl_models/NER\",\n",
    "    geneprod_roles_source=\"/tokcl_models/GENEPROD_ROLES\",\n",
    "    small_mol_roles_source=\"/tokcl_models/SMALL_MOL_ROLES\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "67d131a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"smtag\": [\n",
      "    {\n",
      "      \"panel_group\": [\n",
      "        [\n",
      "          {\n",
      "            \"text\": \"creb1\",\n",
      "            \"entity_type\": \"geneprod\"\n",
      "          },\n",
      "          {\n",
      "            \"text\": \"mouse\",\n",
      "            \"entity_type\": \"organism\"\n",
      "          },\n",
      "          {\n",
      "            \"text\": \"brain\",\n",
      "            \"entity_type\": \"tissue\"\n",
      "          },\n",
      "          {\n",
      "            \"text\": \"aspirin\",\n",
      "            \"entity_type\": \"molecule\",\n",
      "            \"role\": \"intervention\"\n",
      "          }\n",
      "        ]\n",
      "      ]\n",
      "    }\n",
      "  ]\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "tags = smarttagger(\"This creb1-/- mutant mouse has a strange brain after aspirin treatment.\")\n",
    "print(tags)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8f0fc7",
   "metadata": {},
   "source": [
    "With CLI:\n",
    "\n",
    "    python -m smtag.cli.inference.tag --local_model_dir /tokcl_models \"This creb1-/- mutant mouse has a strange brain after aspirin treatment.\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69f21963",
   "metadata": {},
   "source": [
    "# Before sharing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d6c4b21",
   "metadata": {},
   "source": [
    "Save the tokenizer in the respective model directories to enable inference "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b14b413a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('/tokcl_models/PANELIZATION/tokenizer_config.json',\n",
       " '/tokcl_models/PANELIZATION/special_tokens_map.json',\n",
       " '/tokcl_models/PANELIZATION/vocab.json',\n",
       " '/tokcl_models/PANELIZATION/merges.txt',\n",
       " '/tokcl_models/PANELIZATION/added_tokens.json',\n",
       " '/tokcl_models/PANELIZATION/tokenizer.json')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.save_pretrained(\"/tokcl_models/NER\")\n",
    "tokenizer.save_pretrained(\"/tokcl_models/GENEPROD_ROLES\")\n",
    "tokenizer.save_pretrained(\"/tokcl_models/SMALL_MOL_ROLES\")\n",
    "tokenizer.save_pretrained(\"/tokcl_models/PANELIZATION\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6c7d64ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "config.json\t   special_tokens_map.json  tokenizer_config.json\n",
      "merges.txt\t   tokenizer\t\t    training_args.bin\n",
      "pytorch_model.bin  tokenizer.json\t    vocab.json\n"
     ]
    }
   ],
   "source": [
    "!ls tokcl_models/NER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1bbc395b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['SPECIAL_TOKENS_ATTRIBUTES',\n",
       " '__annotations__',\n",
       " '__call__',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_add_tokens',\n",
       " '_additional_special_tokens',\n",
       " '_batch_encode_plus',\n",
       " '_bos_token',\n",
       " '_build_conversation_input_ids',\n",
       " '_cls_token',\n",
       " '_convert_encoding',\n",
       " '_convert_id_to_token',\n",
       " '_convert_token_to_id_with_added_voc',\n",
       " '_create_or_get_repo',\n",
       " '_decode',\n",
       " '_decode_use_source_tokenizer',\n",
       " '_encode_plus',\n",
       " '_eos_token',\n",
       " '_eventual_warn_about_too_long_sequence',\n",
       " '_from_pretrained',\n",
       " '_get_padding_truncation_strategies',\n",
       " '_get_repo_url_from_name',\n",
       " '_mask_token',\n",
       " '_pad',\n",
       " '_pad_token',\n",
       " '_pad_token_type_id',\n",
       " '_push_to_hub',\n",
       " '_save_pretrained',\n",
       " '_sep_token',\n",
       " '_tokenizer',\n",
       " '_unk_token',\n",
       " 'add_prefix_space',\n",
       " 'add_special_tokens',\n",
       " 'add_tokens',\n",
       " 'additional_special_tokens',\n",
       " 'additional_special_tokens_ids',\n",
       " 'all_special_ids',\n",
       " 'all_special_tokens',\n",
       " 'all_special_tokens_extended',\n",
       " 'as_target_tokenizer',\n",
       " 'backend_tokenizer',\n",
       " 'batch_decode',\n",
       " 'batch_encode_plus',\n",
       " 'bos_token',\n",
       " 'bos_token_id',\n",
       " 'build_inputs_with_special_tokens',\n",
       " 'can_save_slow_tokenizer',\n",
       " 'clean_up_tokenization',\n",
       " 'cls_token',\n",
       " 'cls_token_id',\n",
       " 'convert_ids_to_tokens',\n",
       " 'convert_tokens_to_ids',\n",
       " 'convert_tokens_to_string',\n",
       " 'create_token_type_ids_from_sequences',\n",
       " 'decode',\n",
       " 'decoder',\n",
       " 'deprecation_warnings',\n",
       " 'encode',\n",
       " 'encode_plus',\n",
       " 'eos_token',\n",
       " 'eos_token_id',\n",
       " 'from_pretrained',\n",
       " 'get_added_vocab',\n",
       " 'get_special_tokens_mask',\n",
       " 'get_vocab',\n",
       " 'init_inputs',\n",
       " 'init_kwargs',\n",
       " 'is_fast',\n",
       " 'mask_token',\n",
       " 'mask_token_id',\n",
       " 'max_len_sentences_pair',\n",
       " 'max_len_single_sentence',\n",
       " 'max_model_input_sizes',\n",
       " 'model_input_names',\n",
       " 'model_max_length',\n",
       " 'name_or_path',\n",
       " 'num_special_tokens_to_add',\n",
       " 'pad',\n",
       " 'pad_token',\n",
       " 'pad_token_id',\n",
       " 'pad_token_type_id',\n",
       " 'padding_side',\n",
       " 'prepare_for_model',\n",
       " 'prepare_seq2seq_batch',\n",
       " 'pretrained_init_configuration',\n",
       " 'pretrained_vocab_files_map',\n",
       " 'push_to_hub',\n",
       " 'sanitize_special_tokens',\n",
       " 'save_pretrained',\n",
       " 'save_vocabulary',\n",
       " 'sep_token',\n",
       " 'sep_token_id',\n",
       " 'set_truncation_and_padding',\n",
       " 'slow_tokenizer_class',\n",
       " 'special_tokens_map',\n",
       " 'special_tokens_map_extended',\n",
       " 'tokenize',\n",
       " 'train_new_from_iterator',\n",
       " 'truncate_sequences',\n",
       " 'unk_token',\n",
       " 'unk_token_id',\n",
       " 'verbose',\n",
       " 'vocab',\n",
       " 'vocab_files_names',\n",
       " 'vocab_size']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e626960",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
